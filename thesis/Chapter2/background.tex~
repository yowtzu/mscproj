\chapter{Sequential Monte Carlo}
\label{ch:mcmethods}
Since the pioneering work of applying modern sequential Monte Carlo (SMC) \cite{} to tracking and vision problem, these techniques are applied to wide range of domains. This chapter presents an introduction to SMC algorithms

 which a particular focus on how it can 

on applications to tracking, 

It has been more than two decades sin
 two decades since the pioneer 

This chapter presents a brief introduction to Sequential Monte Carlo, a class of general class of techniques

The application of Monte Carlo methods in the Statistics domain is increasing popular. In the Bayesian framework, unknown parameters are assumed to be random variables and admit prior distribution that characterises the initial belief. The belief is updated with new observable evidence using Bayes theorem.

More formally, let specify the initial belief of a Bayesian model, $M$ as the prior disitribution $p(\theta \mid M)$, the probability of observing an observation $x$ given the model (likelihood) as $p(x \mid \theta, M)$. Using Bayesin Theorem, the updated belief (posterior distribution) $p(\theta \mid M)$ is given as follows:
\begin{align}
  p(\theta \mid x , M) &= \frac{p(x \mid \theta , M) p(\theta \mid M)}{p(x \mid M)} \nonumber \\
                   &\propto p(x \mid \theta , M) p(\theta \mid M) \label{eq:bayes} \\
  \text{posterior} &\propto \text{likelihood} \times \text{prior}
\end{align}
Whilst the problem formulation is elegant, there remains some subtle issues, e.g., the calculation of normalising constant, the choice of prior, etc. Refer \cite{BD12} for details. The discussion only focuses on how Monte Carlo integration techniques is used to solve some of the issues involved in Bayesian framework.

To calculate the normalisation constant in $p(x \mid M)$ in \eqref{eq:bayes}, we would need to be able integrate the following
\begin{equation}
  p(x \mid M) = \int p (x \mid \theta, M)p(\theta \mid M) d\theta
\end{equation}
analytically which is often not feasible. The Method Carlo integration methods allow one to compute an estimate of this quantity using samples generated from simulation\footnote{Traditionally, the need of normalisation constant is often circumvented by making use of conjugate prior (the choices of certain prior distributions that yield posterior distributions from the same family) in an analytical fashion.}.

The need of calculate the integral of an espression also arise in the marginalisation of nuisance parameter. For example, let $y$ be an nuisance parameter, the marginal density of $x$ can be obtained from the joint density as follows:
\begin{equation}
  p(x \mid y, M) = \int p(x, y \mid M) dy
\end{equation}
If the integral cannot be computed analytically, Monte Carlo integration methods can be used to estimate the quantity of interest.

Another related problem is to calculate the expectation. This often arise when one attempts to summarise the posterior distribution in some way. For example, the expected value of a function of the parameter:
\begin{equation}
  I = E[f(x)] = \int f(x)p(x)dx
\label{eq:int}
\end{equation}
where $f(\cdot)$ is some function of interest, $p(\cdot)$ is the probabilty density function of $x$. Again, this may not have an analytic solution. We may use Monte Carlo integration methods to compute an estimate for this integral.

\section{Perfect Monte Carlo}
In the simplest setting, assuming we are able to sample $N$ independent and identically distributed (i.i.d.) points of $x$ from $p(\cdot)$, denote these as $\{x^i\}$ where $i$ is from $1 \ldots N$, a Monte Carlo estimate of $I$ using the the point masses of the samples is:
\begin{equation}
  \hat{I} = \frac{1}{N} \sum^N_{i=1} f(x^i)
\end{equation}
Informally, this estimate approximates the continous distribution with a discrete distribution with random support. It can be shown that this estimate is unbiased and converge almost surely to $I$ as $N \rightarrow \infty$ (Law of Large number).

If the variance of $f(\cdot)$ is bounded ($\sigma^2_f < \infty$), then the following central limit theorem holds:
\begin{equation}
  \sqrt{N}(\hat{I} - I) \Longrightarrow N(0, \sigma^2_f) \text{ as } N \rightarrow \infty
\end{equation}
where $\Longrightarrow$ denotes convergence in distribution. It is important to note that the converengece rate of $\frac{1}{\sqrt{N}}$ is independent of the dimensions of $x$. This is in constrast with any determinstic method that has a rate that decreases a the integral dimension increases \cite{RCP05}. This is the main advantage of Monte Carlo integration.

\section{Rejection sampling}
However, it is not always possible to sample directly from the distribution $p$. Suppose we can find an instrumental distribution $q$ that is easy to sample from such that $cq(x)$ that dominates $p$ such that $cq(x) \geq p(x) \geq 0$ for all $x$. then to get a random sample from $p$, we can first sample from $q$ instead and accept the sample with acceptance probability $\alpha(x)=\dfrac{p(x)}{cq(x)}$. If the sample is rejected, repeat the process until success. The algorithm is summarised in Algorithm \ref{algo:rejectionsampling}.

\begin{algorithm}
\caption{Rejection Sampling}\label{algo:rejectionsampling}
\begin{algorithmic}[1]
\Function{RejectionSampling}{n}
\State $r = [\ ]$
\Repeat
  \State sample $x \sim q$
  \State sample $u \sim {\cal U}(0,1)$
  \If {$u \leq \dfrac{p(x)}{cq(x)}$}
    \State $r \gets [r,x]$
  \EndIf
\Until{len(r)=n}
\EndFunction
\end{algorithmic}
\end{algorithm}

One could easily see that the optimal choice of proposal distribution $q*$ is that one minimize the area subject to the constraint that it dominates the target density $p$. Unfortunately, in practice a rejection sampling is only feasible in low dimension and then it becomes very ineffective as the dimension increases as lots of samples generated samples woud rejected.

\section{Importance sampling}
Instead of making a binary accept-reject decision on each sample, the main idea behinds important sampling is to weight each sample based on how well the sample from the proposal distribution $q$ resembles the target distribution $p$. More formally, assume we have an instrumental distribution $q$ that is easy to sample from which has support that includes $p$, we can write \eqref{eq:int} as:
\begin{align}
  I &= \int f(x)\dfrac{p(x)}{q(x)}q(x) dx \nonumber \\
    &= \int f(x)w(x)q(x) dx
\end{align}
where $w=\dfrac{p(x)}{q(x)}$, which is commonly known as the importance weight. Based on this reformulation, a possible Monte Carlo estimate of $I$ is given as follows:
\begin{equation}
  \hat{I} = \dfrac{\frac{1}{N} \sum^N_{i=1} w(x^i)f(x^i)}{\frac{1}{N} \sum^N_{j=1} w^j} = \sum^N_{i=1} \tilde{w}^i f(x^i)
\label{eq:is}
\end{equation}
where $\tilde{w}^i=\displaystyle\sum^N_{i=1}\dfrac{w^i}{\sum^N_{j=1}w^j}$ is the normalised importance weight. This estimate is biased as it uses the ratio of two estimator but it is still asymtoptically consistent.

\section{Markov chain Monte Carlo (MCMC)}
%The rejection and importance algorithms scale badly with dimensionality. In some problems, it may still possible to decompose the probability distribution of interest, $P(x_{1:N})$ into low dimensional conditional distributions and proceed from there. However, this is not often feasible in practice.

Markov chain Monte Carlo (MCMC) are a set of algorithms that allows ones to draw random samples from the target probability distribution by constructing a ergotic Markov chain process which has its stationary distribution set to be target desired distribution. 

\subsection{Markov Chain}
Conceptually, Markov chain is a stochastic process in which the past and future states of the process are independent given the current state. A Markov chain can be viewed as an \emph{ordered} sequence of states $\{x_{1:N}\}$, in which state $x_t$ only depends on state $x_{t-1}$, i.e., the state at time $t$ is determined based on some trasition distribution of the form $p(x_t \mid x_{t-1})$, which is independent of all previous states $x_{t-2}, x_{t-3}, \ldots$. 

To ensure the Markov chain converges to a steady state (stationary distribution), the chain needs to satisfy the following properties:
\begin{enumerate}
\item irreducible --- no matter where it starts a chain, it is possible to reach all other states in finite amount time steps.
\item aperiodic --- 	for all the states $i$, the chain can  return to state $i$ at irregular time.
\item positive recurrent --- for all the state $i$, the chain will definitely revisit the state in finite amount time stpes.
\end{enumerate}

In practice, it is usually not difficult to construct the required Markov Chain, the more difficult problem is to determine how many steps it takes to converge, often known as mixing. Various visual diagnostic have been developed, yet it is often a matter of art. Refer \cite{RCP05} for details.

In the following sections, we present two basic MCMC algorithms: Metropolis Hastings algorithms, Gibbs algorithms and a third algorithm in which these two basic algorithms are ``mixed and matched'' in a hierarchical fashion to form a more advanced samplers to fit application needs.

\subsection{Metropolis-Hastings sampling}
The first major MCMC algorithm was devised by Metropolis in \cite{MN53}. The algorithm constructs a Markov Chain by proposing a random walk step based a proposal distribution is symmetric, i.e., the probability of moving from state $t$ to state $t-1$ is the same as the probability of moving from state $t-1$ to state $t$ ($q(x_{t} \mid x_{t-1}) = q(x_{t-1} \mid x_{t}$). The proposed step is then either accepted or rejected according to an acceptance probability, $\alpha(x)= \min\left(1, \dfrac{p(x_t)}{p(x_{t-1})}\right)$, where $p(x)$ is the target probability density evaluated at $x$.

This algorithm was generalised by Hastings \cite{WKH70} to allow the use of non-symmetric proposal density, with an adjustment to the accenptance probability $\alpha(x) = \min\left(1, \dfrac{p(x_t)q(x_t \mid x_{t-1})}{p(x_{t-1})q(x_{t-1} \mid x_{t})}\right)$ and hence the name, Metropolis-Hastings sampling. This algorithm is summarised in Algorithm \ref{algo:metropolishastings}.

\begin{algorithm}
\caption{MetropolisHastings}\label{algo:metropolishastings}
\begin{algorithmic}[1]
\Function{MetropolisHastings}{n}
\State $r = [\ ]$
\Repeat
  \State sample $x_t \sim q(x_{t-1})$
  \State sample $u \sim {\cal U}(0,1)$
  \If {$u \leq \min\left(1, \dfrac{p(x_t)q(x_t \mid x_{t-1})}{p(x_{t-1})q(x_{t-1} \mid x_{t})}\right)$}
    \State $x_{t-1} \gets x_{t}$
    \State $r \gets [r,x_{t-1}]$
  \EndIf
\Until{len(r)=n}
\EndFunction
\end{algorithmic}
\end{algorithm}

It is not hard to see that the algorithm works best if the density $q$ matches the shape as density $p$, which is often unknown. Assuming a Gaussian proposal density $q$ is used, there is also an addtional parameter, namely the variance $\sigma^2$ is required to be tuned. There is a trade-off to be made in the tuning process. If the $\sigma^2$ is set too be too small, the chain is likely to mix slowly (i.e., the proposed step is likely to be accepted yet each successive move is very slow and therefore the chain will converge to target distribution $p$ at a slow rate). On the other hand, if $\sigma^2$ is too large, the proposed step is likely to be rejected as it is likely to hand in a region of much lower probability density and the chain will converge slowly again. Again, refer \cite{RCP05} for details on convergence dianogstic.

\subsection{Gibbs sampling}
Gibbs sampling \cite{GS84} is a special form of the Metropolis–Hastings sampling. The key idea in Gibbs sampling is to re-write the target multivariate distribution of interest as a product of conditional probability distributions of lesser number of parameters. A Markov Chain is then constructed to generate samples for each parameter \emph{in turn} from the conditional distributions with an acceptance rate $\alpha(x)=1$, i.e., accept all the samples.

More formally, suppose we would like to have obtain $k$ samples of $\mathbf{x}=(x_1,x_2,\ldots, x_n)$ from $p(x_1, \ldots, x_n)$, assuming we start with an initial value $\mathbf{x}^{0}$. For each sample $(\mathbf{x}^{i}: i \in \{1 \dots n\})$, sample $x_j^{(i)}$ from the conditional distribution $p(x_j|x_1^{(i)},\dots,x_{j-1}^{(i)},x_{j+1}^{(i-1)},\dots,x_n^{(i-1)})$. In other words, sample each variable from the distribution of that variable conditioned on all other variables, making use of the most recent values and updating the variable with its new value as soon as it has been sampled. The algorithm is summarised in Algorithm \ref{algo:gibbs}.

\begin{algorithm}
\caption{Gibbs}\label{algo:gibbs}
\begin{algorithmic}[1]
\Function{Gibbs}{n}
\State $r = [\ ]$
\State sample $x^{(0)}$
\Repeat
  \State sample $x^{(t)} \sim p(x_j|x_1^{(i)},\dots,x_{j-1}^{(i)},x_{j+1}^{(i-1)},\dots,x_n^{(i-1)})$
  \State $r \gets [r,^{t}]$
\Until{len(r)=k}	
\EndFunction
\end{algorithmic}
\end{algorithm}

There are variations of Gibbs sampling techniques. For examples, a blocked Gibbs sampling groups more than one variables and sample from the joint distribution conditioning on other variables. Refer \cite{RCP05} for details. 

\section{Hidden Markov Models}
Hidden Markov Models (HMMs) is a class of models that have been applied to many different problems in statistics, signal processing and engineering. Many Monte Carlo techniques have been developed to deal with inference in HMMs, one of which that we have paricular interest in is the Sequential Monte Carlo (SMC). This section provides a brief background on HMMs that is essentially to understand SMC. Refer \cite{CO05} for further details of inference techniques for HMMs in general.

HMMs can be viewed as a class of models that consist of two related process: an underlying Markov process, $X_t$, which is the target process of interest, and a observable process, $Y_t$, which its state can be measured and therefore provides some information about $X_t$. Moreover, it is assumed that these two processes also have conditional independence properties as shown using the graphical model representation in Figure \ref{fig:HMM}. More formally, these properties can be summarised as follows:
\begin{align}
   \Pr(X_n \mid X_{1:n}) &= \Pr(X_{n-1})   \nonumber \\
   \Pr(Y_n \mid X_{1:n}  &= Y_{1:n}) = \Pr(Y_n \mid X_{1:n}) 
	1 + 1 conditional indepednent
\end{align}

\begin{figure}
\includegraphics[scale=1]{figures/hmm.png} 
\caption{Hidden Markov Models}
\label{fig:HMM}
\end{figure}

It is worth emphasizing here that this model is designed to capture systems that evolve from one state to another over time, generating observation after each state move. The inference problem is typically about estimating the state(s) in \emph{real-time} given the observations. This imposes an implicit requirement from the computation perspective that the estimate calculation cost should remain constant over time (i.e., the calculation cost does not increase with the increasing number of states).

Arguably, the most common inference problem in HMMs is the smoothing distribution, $p(x_{1:t} \mid y_{1:t})$, that is estimating the states $x_{1:t}$ based on the sequence of observations up to time $t$, $y_{1:t}$. Using Bayes rules, we can write the density of the distribution of interest as follows:
\begin{align}
    p(x_{1:t} \mid y_{1:t}) \propto p(x_{1:t} \mid y_{1:t-1}) g(y_t \mid x_t) \nonumber \\
    p(x_{1:t} \mid y_{1:t-1})f(x_t \mid x_{t-1})g(y_t \mid x_t)
\end{align}
where $f(x_t \mid x_t=1)$ is the transition density and $g(y_t \mid x_t)$ is the likelihood. This recursion is often re-written into two separate steps: prediction (the estimation of distribution of $t$ states given only $t-1$ states) and update steps (the correction of the predicted distribution taking into account the new observation as follows:
\begin{align}
  p(x_{1:t} \mid y_{1:t-1}) &= p(x_{1:t-1} \mid y_{1:t-1})f(x_t \mid x_{t-1}) \nonumber \\
  p(x_{1:t} \mid y_{1:t})   &= \dfrac{p(x_{1:t} \mid y_{1:t-1}) g(y_t \mid x_t)}{\int p(x_{1:t} \mid y_{1:t-1}) g(y_t \mid x_t) dx_{1:t}}
\end{align}
Moreover, the estimate of any smoothing distribution $p(x_{j:k} \mid y_{1:t})$ where $j \leq k \leq l)$ can be obtained by integrating out $x$ that are not interested in as follows:
\begin{equation}
  p(x_{j:l} \mid y_{1:t}) = \int p(x_{1:t} \mid y_{1:t}) dx_{1:j, l+1:t}
\label{eq:smoothing}
\end{equation}
One particular smoothing distribution of interest is the final marginal distribution $p(x_t \mid y_{1:t})$, which is often referred to as the filtering distribution.

Another distribution of interest is  the prediction distribution, that is the estimation of the distribution of any unseen \emph{future} state based on the sequence of observations up to time. Referring to \eqref{eq:smoothing}, if we let $j = 1$ and $l \geq n$ in , we have:
\begin{equation}
  p(x_{j:l} \mid y_{1:t}) = p(x_{j:t} \mid y_{1:t}) \prod^k_{i=t+1} f(x_i \mid x_{i-1})
\end{equation}
Therefore, any prediction density can be obtained by integrating out the variables of not interest from the above equation.

The problem of distribution estimation as discussed appears to be simple, but the problem is in fact far from being resolved in practice. The integral appear in the above equations are often intractable and can only be estimated.

\subsection{Kalman Filter}
In a special case setting, in which the transition distribution of $X_t \mid X_{t-1}$ and the likelihood are Gaussian distributions centred at a point of a linear combination of the conditional variables of the following form:
\begin{align}
  f_n(x_n \mid x_{n-1}, u_n) &= N(A_n x_{n-1} + F_n(u_n), B_n B^T_n) \nonumber \\
  g_n(y+n \mid x_n, u_n)    &= N(C_n x_n{n-1}, D_nD^T_n)
\end{align}

Using the properties of Gaussian distribution, the integral can be resolved analytically. This leads the widely used \emph{Kalman Filter} \cite{KGE60}, which has the following recursion forms:
\begin{align}
  1+1
\end{align}
There are various extensions to this approach. For example, the Extended Kalman Filtre (EKF) which uses Taylor Series expansion to linearise at the conditional variables locally, Unscentend Kalman Filter, etc.. Refer \cite{WG95} for further details on Kalman Filter.

\section{Sequential Monte Carlo}
As mentioned, there is however no analytical solution for this estimation problem in a general settings for this model. A common  technique to dealing with this problem is Sequential Monte Carlo (SMC). Conceptually, the distribution of a state at any point of time is represented using a set of weighted samples (a.k.a. particles). These particles are propagate from one state to another through time by proper re-weighting and re-sampling as necessary to track the changes of the distribution. To estimate the smoothing/filtering/prediction distribution, the integrals are performed on these samples using Monte Carlo technique in a recursion fashion, i.e., the estimation problem at step $t$ is calculated with the estimate obtained at time $t-1$, hence the name.

\subsection{Sequential Important Sampling (SIS)}
Recalled that importance sampling allows one to calculation the expectation with respect to a distribution $\pi$, $E_{\pi}[f(X)]$ using samples from a different proposal distribution $q$ as $E_{q}[\pi(X)f(X)/q(X)]$. 

Sequential importace sampling extends this idea further. 

The basis of sequential important sampling technique

As with all seq

The basis of sequential importa
\subsection{Sequential Important Resampling (SIR)}

\subsection{Parameter estimation}


The stochastic regulation problem is transformed into a parameter estimation problem given the reference data $y_{1:n}$.

The algorithm is summarised here.

\section{Conclusion}
In this chapter, 
\chapter{Monte Carlo Methods}
\graphicspath{{Chapter2/figures/}}
\label{Monte Carlo Methods}
Security is about the protection of assets against
threats~\cite{CPP02}. This definition implies that we need to know
what assets require protection. As computer systems have evolved, the
nature of specific assets and threats has changed~\cite{RL06}. Prior
to the invention of the personal computer, computer security was
mainly concerned with the protection of computer mainframes. Here,
particular threats could be countered by simple physical controls. For
example, storing a mainframe in a room with effective physical access
controls to prevent unauthorised access.

In recent years, computer and network hardware has grown cheaper;
using a computer has now become commonplace. Individuals use computers
to store their private information, e.g., credit card numbers, bank
account passwords, private diaries. Organisations use computers to
increase their operational efficiency. There is an increasing amount
of valuable information stored in computers. The sheer ubiquity of
valuable information signifies the importance of security as an issue
for us all.

This chapter presents the fundamental computer security concepts
related to this thesis. It begins with a brief introduction to common
security objectives and security risk analysis. It then presents the
concept of dynamic coalitions, with an emphasis placed on MANETs and
the challenges they impose on current security mechanisms.

\section{Computer security objectives}
\label{ComputerSecurityObjectives}
Traditionally, the objectives of computer security are commonly
summarised as confidentiality, integrity and availability; often
collectively known as the C-I-A triad~\cite{RL06}. Over time, many
security practitioners have realised the incompleteness of the triad
and attempted to augment it with new objectives. These objectives
include authenticity, accountability and
non-repudiation. In~\cite{DBP98}, Donn B. Parker introduced the
Parkerian hexad, which adds three more objectives to the C-I-A triad:
possession~(control); authenticity; and utility.

The following sections briefly summarise each of these objectives and
their established scopes respectively. For extensive discussion, refer
to~\cite{DG05,RJA01,MB02}.

\subsection{Confidentiality}
\label{Confidentiality}
Confidentiality is concerned with the protection of information from
unauthorised \emph{disclosure}. In computer systems, confidentiality
is about preventing unauthorised subjects from \emph{reading}
information. Confidentiality is often confused with the
terms~``secrecy'' and~``privacy''. Gollmann clarifies these terms
in~\cite{DG05}. He views both secrecy and privacy as forms of
confidentiality. Whilst privacy is concerned with the confidentiality
of personal data, secrecy is concerned with the confidentiality of
organisational data. For example, a privacy violation happens when an
organisation shares the personal information of its customers with
other organisations without the knowledge of the customers.

Sometimes, it is necessary to protect the confidentiality of subject
identities. This objective is often known as anonymity. More formally,
anonymity is the state in which a subject's true identity remains
unknown by other subjects~\cite{AP01}. An example to show why
anonymity is necessary is the traffic analysis attack~\cite{DG05}. The
attackers can derive information such as the relationship between the
parties from patterns in communication, even when messages are
encrypted. In order to preserve the anonymity of the subject
identities, there needs to be a property of unlinkability between
identities of the participants and the communication.

\subsection{Integrity}
\label{Integrity}
In computer security, integrity is concerned with the protection of
assets from unauthorised \emph{modification}~\cite{DG05}, as opposed
to~``the quality of having strong moral principles'' defined in the
Oxford Dictionary of English~\cite{CS05}. In computer systems,
integrity is typically about preventing unauthorised subjects from
\emph{writing} information. For this reason, integrity is sometimes
perceived as the dual of confidentiality and similar techniques can be
expected to be used in achieving this objective, e.g., the Biba model
~\cite{KJB77} has the mirror properties of the Bell-LaPadula
model~\cite{DEB73}.

Further interpretations and constraints on what integrity implies have
also been made in the literature. Clark and Wilson argued that the
usage of a data modification method, which causes data loss or
corruption, should not be permitted even by an authorised
subject~\cite{DDC87}. The integrity requirement is split into two
parts: internal and external consistency. Internal consistency is
concerned with ensuring the consistency of data representation and
modification within the computer systems; external consistency is
concerned with ensuring that the data reflect the real-world objects
that they represent. The Clark-Wilson definition is more sophisticated
and reflects the subtleties present in commercial environments. On the
other hand, the definition of integrity given in the Trusted Computer
System Evaluation Criteria~(TCSEC) is concerned only with external
consistency; integrity is defined as~``the state that exists when
computerised data is the same as the source documents and has not been
exposed to accidental or malicious alteration or
destruction''~\cite{DOD85}.

\subsection{Availability}
\label{Availability}
Availability is concerned with the likelihood of a system is able to
provide some services. In particular, the availability at time~$t$,
usually denoted by~$A(t)$, is the probability that the system can
provide a specific service at time~$t$ under stated
conditions~\cite{REB75}.

Availability may be compromised by a variety of mechanisms. A simple
example is hardware failure. Traditionally, the threat from such
failure is countered by the use of redundancy~\cite{AB01}. Redundancy
can be made in two forms: either the redundant components act as
backups that are activated should one component fail, or all duplicate
components run concurrently and form a voting system, in which the
consensus output is the majority vote. Denial of service~(DoS)
attacks, which aim to make a system unavailable to the authorised
users, may take many forms. At one extreme, an army of compromised
hosts may be used to clog up a large network by wide-scale consumption
of resources. At the other, a smart attacker may target a specific
server aiming only to issue service requests at the rate they are
dispatched but in a manner that keeps the service request queue full,
and hence unavailable. This is usually known as a low-rate DoS attack.

\subsection{Authenticity}
\label{Authenticity}
Authenticity is concerned with the genuineness of the identity a
subject claims to be.  Something is said to be authentic when it
really is what it claims to be. Authentication is the verification of
such claims~\cite{MB02}. We may be interested in verifying that the
user at a terminal is who he claims to be. This is personal identity
authentication. Authentication is clearly a prerequisite for many
other aspects of security. Access control is used to dictate the
access given to subjects with regard to specific objects. However, it
makes the assumption that the subject in question really is the person
concerned or acts legitimately on that person's behalf, e.g., a
process started by that user.

There are a great many means of authenticating the identity of a
person. These can be loosely categorised into three groups as follows:
\begin{enumerate}
 \item Something the user has, e.g., a token card.
 \item Something the user knows, e.g., a password, a pin, a
   signature.
 \item Something the user is~(giving rise to biometrics such as
   fingerprints, iris patterns, and various behavioural
   characteristics such as dynamic signature properties).
\end{enumerate}
An example of authenticity violation is an attacker logging in as an
ordinary user using a stolen password.

In many security protocols, received messages may seem to be recently
created. However, we know that messages can be recorded and replayed
and thus it is often required to verify any such claims to
recency. This is a form of message authentication. Often, we may also
wish to verify the sender identity of a received message, e.g., the
sender of an email that requests a bank statement.


\subsection{Accountability and non-repudiation}
\label{AccountabilityAndNonrepudiation}
The security objectives discussed so far have sought to prevent
unwanted events from happening. What if these preventions fail?
Accountability attempts to answer this by ensuring the actions that
affect security can be traced to the responsible subject~\cite{DG05}.
In other words, accountability attempts to establish the links between
the subjects and the actions made. This often conflicts with anonymity
that strives to unlink them. A common way to achieve accountability is
to keep a secure audit trail on the systems. Illicit modification or
deletion of an audit trail would clearly compromise accountability. A
DoS attack on the audit server provides an alternative and possibly
easier way to achieve the same goal.

Non-repudiation is a stronger form of accountability. Non-repudiation
is concerned with the ability to ensure that a subject is unable to
deny carrying out the action~\cite{DG05}. This objective is commonly
achieved with the use of digital signatures. In signing a piece of
data with a private key, an unforgettable binding is established
between the subject and the data. Disclosure of a private key would
clearly compromise any claims to legitimacy of
binding~\cite{DG05}. Thus, users must keep their private keys secure.

\subsection{Summary}
\label{ComputerSecurityObjectives.SectionSummary}
The security objectives discussed in the section can be summarised as
follows:
\begin{enumerate}
\item Confidentiality --- Prevention of unauthorised disclosure of
  information.
\item Integrity --- Prevention of unauthorised modification of
  information.
\item Availability --- Prevention of the DoS.
\item Authenticity --- Verification of identity one claims to be.
\item Accountability and non-repudiation --- Prevention of the denial
  of actions made.
\end{enumerate}

\section{Security risk analysis}
\label{SecurityRiskAnalysis}
Security risk analysis is the process of ensuring that the security of
a system is commensurate with the risk it is exposed to. All
protection measures come at a price. Security risk analysis provides a
means to justify the tradeoff between cost and benefit for the
security controls implemented. Despite the various methodologies in
conducting security risk analysis and some of them being tailored to a
particular discussion, they all share a common framework composed of
the following steps: assets, vulnerabilities and threats
identification, risk assessment, selection of control, and
re-evaluation.

\subsection{Assets, vulnerabilities and threats identification}
\label{AssetVulnerabilitiesAndThreatsIdentification}
Assets are resources that have values in a system~\cite{RL06}. Assets
in a computer system can be mainly categorised into three groups:
hardware, software and information. At times, the workforce and the
reputation of a company are considered as part of the
assets~\cite{DG05}. To do risk assessment, all assets are first
identified with their values evaluated. Whilst the values of tangible
assets are easy to quantify by considering the monetary replacement
cost, the values of intangible assets are difficult to estimate. For
example, the loss of confidential information on suppliers and clients
may affect the reputation of the company. In addition, any damage to
the assets in the above categories can cause damage to the quality of
service. One possible way to estimate the values of these assets is
based upon their importance~\cite{HRC06}.

Vulnerabilities are the weaknesses of a system. Attackers attempt to
discover the vulnerabilities of a system in order to cause damage to
assets, either accidentally or
intentionally~\cite{DG05}. Vulnerabilities can exist at different
levels and places in a computer system, e.g., operational
environments, operating systems, application software, networks,
communication media and operational practices.

Threats are the potential actions that can be used by attackers to
exploit vulnerabilities in order to cause damage to
assets~\cite{CC05}. Threats are caused by threat agents, which can be
both internal and external to the system. Examples of threat agents
may be hackers, system administrators or viruses that exploit bugs in
a software to launch attacks on a system. In the literature, the term
~``threat'' is often used where the term~``threat agent'' should
be. An extreme example is the definition of threat as~``the party with
the capabilities and intentions to exploit a vulnerability in an
asset''~\cite{RB06}.

The relationship between these terms is best illustrated by the
following example. In a computer network, a possible vulnerability is
the use of a default password at the network router~(asset). A hacker
(threat agent) can exploit this vulnerability to take control over the
router and launch a DoS attack to prevent authorised computers from
connecting to the network.

\subsection{Risk assessment}
\label{RiskAssessment}
The definition of risk varies considerably in the literature depending
on the domain in which it is considered for. For example, risk can be
the standard deviation on the return of an investment in
finance~\cite{CRH06}, or a function on the amount of loss and the
probability of the loss~\cite{PCC07,PCC07A}. Nevertheless, there is a
common theme behind these definitions. Risk is always related to
expected loss, which can be caused by an action and the estimated
probability of such loss arising.

In security, risk is defined as a function of assets, vulnerabilities
and threats~\cite{DG05}. This definition is coherent with the
engineering definition of risk by considering the amount of loss as
a function of the assets and vulnerabilities in the system. Based on
this definition, the risk assessment of a computer system can be
carried out quantitatively or qualitatively~\cite{DG05}.

In a quantitative assessment, the values are calculated using various
mathematical theories and formulae~\cite{CA05}. For example, risk can
be calculated based on the monetary replacement values of assets and
the probabilities of threats happening. The advantage of this analysis
is that it provides a precise numerical risk value, which is useful
for cost-benefit analysis of recommended
controls~\cite{CA05}. However, the precise meaning that a given
numerical risk value represents can become unclear, e.g., a high risk
value can be due to the high value of the asset, the high probability
of threats happening, or both factors. This may cause problems in
selecting suitable controls to protect the system assets because
different assets may require different protection mechanisms.

In contrast, a qualitative assessment uses descriptive variables to
represent risk~\cite{CA05}. For example, each asset is given a value
on a scale of cheap, medium and expensive; criticality of
vulnerabilities is given a value on a scale of very low, low, medium,
high and very high; and each threat is given a value on a scale of
very low chance, low chance, medium chance, high chance and very high
chance. The mapping of these values to the risk can be obtained by
using a mapping table based on the advices of security
experts~\cite{HRC06}. There are also other qualitative analysis
techniques, including scenario analysis and
questionnaires~\cite{DG05}. The advantages and disadvantages of using
a qualitative analysis are more or less the mirror of using a
quantitative approach. This analysis provides a means to identify the
vulnerabilities of the systems in a relatively short
time~\cite{DG05}. However, the cost-benefit analysis of recommended
controls becomes difficult in the absence of a precise numerical risk
value~\cite{DG05}.

\subsection{Selection of controls}
\label{SelectionOfControls}
Controls, also known as countermeasures, are the ways to protect a
system against threats. The controls selected must be commensurate
with the risk identified. Controls for the computer systems can be
categorised into three types: administrative, physical and logical.

Administrative controls are concerned with the relationship between
security and human factors~\cite{RHL02}. Administrative controls
specify how a system can be used. Examples of administrative controls
include organisational security policies, user registration processes,
business continuity plans and disaster recovery plans. For example,
the computing service in a university defines the security policy that
students must agree and abide by. It is often that this high level
security policy, defined in administrative control documents, lends
itself to form the basis of the selection of logical and physical
controls. In other words, the logical and physical controls implement
and manifest the administrative controls.

Physical controls protect the physical hardware of computer systems
from physical and environmental threats. Some examples include locks,
closed circuit surveillance cameras~(CCTV) or security
guards~(protection from unauthorised accesses), cooling
systems~(protection from heat) and backup sites~(protection from
natural disasters).

Logical controls protect computer systems using software and data
measures. Some examples include data encryptions, access controls,
firewalls and intrusion detection systems. In recent years, logical
controls have received much attention from the security community and
have achieved significant advancement. Consequently, the knowledge
gained in logical controls has also been transferred to protect and to
improve physical controls, e.g., the use of PINs in conjunction with
door entry cards.

Security is only as strong as the weakest link~\cite{BS00}. In
practice, all three types of controls have to be implemented and
balanced in order to achieve security objectives of concern. For
example, for availability, strong physical controls such as a reliable
cooling system and backup site are needed to protect the physical
hardware of a computer system from physical threats. At the same time,
strong logical controls such as a strong user authentication process
and a good access control policy are also needed to protect the system
from unauthorised accesses to the services provided. The lack of
either control can easily result in the system becoming unavailable.

% All three controls have to be implemented and balanced in order to
% achieve the security objective. For example, one can store data in
% $256$ bits encryption format in a public computer, yet the lack of
% physical security can easily nullify the strong logical security
% implemented. Attackers can destroy the data by simply destroying or
% taking away the data storage.

\subsection{Re-evaluation}
\label{Re-evaluation}
A detailed security risk analysis on large computer systems is not
feasible for every organisation as it requires significant
resources~(time and cost)~\cite{CC05}. Furthermore, new threats and
vulnerabilities emerge each day because the operational environment is
constantly changing. Therefore, security risk analysis is an ongoing
iterative process and must be indefinitely repeated.

\subsection{Summary}
\label{SecurityRiskAnalysis.SectionSummary}
A conceptual model that summarises a security risk analysis process is
shown in Figure~\ref{fig:securityriskanalysisprocess}. In a security
risk analysis process, the system owners attempt to quantify the risk
of the system exposed to by analysing vulnerabilities of the system
and identifying the threats to system. Based on the risk, appropriate
security controls are then selected to protect the system. The
ultimate objective of the process is to ensure that the security
controls of a system implemented are commensurate with the risk that
the system is exposed to.

\begin{figure}[htbp]
 \centering
 \includegraphics[width=0.8\textwidth]{SecurityRiskAnalysisProcess}
 \caption{The conceptual model of a security risk analysis
   process~\cite{CC05}.}
 \label{fig:securityriskanalysisprocess}
\end{figure}

\section{Dynamic coalitions and MANETs}
\label{DynamicCoalitionAndMANET}
A coalition is defined as a~``temporary alliance for combined action,
especially of political parties forming a government'' in the Oxford
Dictionary of English~\cite{CS05}. This definition underpins two
important characteristics of a coalition.  Firstly, a coalition is
temporary; the alliance between parties is not permanent and will
cease to exist in the future. How long the coalition lasts depends on
the type of coalition. Secondly, an alliance is formed to achieve a
common objective, which may be difficult or even impossible to achieve
alone by each individual party. This implies that sharing of resources
such as objects, applications and services is an integral part of a
coalition. Without common objectives, each party may not be willing to
share their resources~\cite{HK02}.

A dynamic coalition is a coalition that allows parties to join or
leave during the lifetime of the coalition. Some examples of dynamic
coalitions are as follows~\cite{HK02,CEP02}:
\begin{enumerate}
\item In a war, two or more countries may come together in an alliance
  to strengthen their forces. These countries may decide to share some
  classified information such as locations of forces and bases to
  increase the efficiency of the operation. However, a friend today
  might become a foe tomorrow; an alliance member can change sides and
  become an opponent at any point in time. The opposite can also
  occur.
\item A real-time systems research group in a university discovers a
  new highly efficient scheduling algorithm and wishes to form an
  alliance with a private automobile manufacturer and an embedded chip
  company for evaluating the performance of the algorithm in the real
  world. Given the interest, all three parties come together, form an
  alliance and share all research data generated. After the coalition
  is set up, other organisations may decide to join in or some of the
  initial members may decide to leave.
%X change department to council
\item In the aftermath of an earthquake, the police department, the
  military forces as well as voluntary organisations such as the Red
  Cross come together and form a rescue operation alliance. The police
  moves refugees to a safe place, whilst the Red Cross provides the
  medical and food aid. The military forces provide transport to make
  the rescue operation more efficient. Eventually, there is a recovery
  phase and basic infrastructure is rebuilt to get the region back to
  normality.
\item MANETs are a type of network that can be rapidly deployed
  without relying on existing infrastructure. The nodes in MANETs can
  dynamically join and leave the network, often without warning, and
  possibly without disruption to communication of other nodes, refer
  to Section~\ref{MANET}.
\end{enumerate}

Resource sharing is at the heart of every dynamic coalition. Each
party in a coalition hesitates to share its resources including
information with other parties in order to minimise its risk, yet
sharing is necessary to achieve the common objective of the
coalition. This problem is commonly known as the Dynamic Coalition
Problem~\cite{SCS00}; having well designed access control policies and
mechanisms are vital in solving this problem.

% , they alone are not sufficient. There is an interdependent relation
% between access control and other security services \cite{RSS94},
% e.g., access control mechanisms depend on authentication services to
% establish the true identity of a user. Hence, it is vital to have
% balanced security control measures for a system.

\subsection{MANETs}
\label{MANET}
Wireless networks have grown and changed rapidly in the last
decade. Wireless networks can be categorised into two groups:
infrastructure based networks and ad-hoc networks. In infrastructure
based networks, there are some prefixed equipments, i.e., base
stations to which all the mobile nodes are connected. All
communication between the nodes passes through the base stations. A
base station may also serve as the gateway of a wireless network to a
wired network. When a mobile node moves out of the range of a base
station into the range of another, a hand off process is executed
automatically and the mobile node continues its connection seamlessly
with the network~\cite{EMR99}. Mobile phone service networks are good
examples of this type of network.

In ad-hoc~(infrastructureless) networks, there is no prefixed
infrastructure that the nodes can rely on to connect to each
other. The nodes in an ad-hoc network dynamically connect to form a
multi-hop network. Each node plays the role of a router; discovering
the route and forwarding the data for other nodes
dynamically~\cite{EMR99}. Ad-hoc networks are also self-configuring
and self-organising networks.  Self-configuring in the sense that an
ad-hoc network can be formed on the fly; self-organising in the sense
that the network can change based on its needs, either by partitioning
or merging the network with few administrative actions. The two common
types of ad-hoc networks are MANETs and sensor networks.

MANETs are a subset of ad-hoc networks with highly dynamic network
topologies~\cite{IC03}. Historically, MANETs were used for military
purposes. The first two projects on MANETs were the Public Radio
Network~(PRNet)~\cite{JJ87} and its follow up project, Survivable
Radio Networks~(SURAN)~\cite{DAB90}, both funded by Defence Advanced
Research Projects Agency~(DARPA)\footnote{DARPA is an agency of the US
  Department of Defence that is responsible for the development of new
  technology for use by the military.}. Most of the existing
non-military MANETs have been developed in academic environments. The
notion of MANETs in the commercial world can be traced to the
emergence and success of the IEEE 802.11 Wireless Local Area
Networks~(WLANs) and Bluetooth technologies in the 1990s. Due to the
popularity of MANETs, the term~``ad-hoc networks'' is often used
interchangeably with~``mobile ad-hoc networks'' in the literature.

Sensor networks are high density networks with a large number of
sensor nodes deployed in an area to monitor some phenomenon. The
discussion on sensor networks is beyond the scope of this thesis. For a
comprehensive survey on sensor networks, refer to~\cite{IFA02}.

\subsection{Security challenges of MANETs}
\label{B.DynamicCoalitionAndMANET.TheSecurityChallegesOfMANET}
The flexibility that MANETs offer comes at a price. The
infrastructureless nature presents many security challenges that are
specific to MANETs as follows~\cite{IC03,SC99,RR02}:
\begin{enumerate}
\item Lack of trusted entities --- Infrastructureless is a fundamental
  characteristic of MANETs. The lack of a trusted, centralised entity
  in MANETs requires the network administrative tasks to be
  distributed among the nodes in the networks. This results in
  increased security risk as there are more possible access points for
  intrusion. Moreover, many of the existing security protocols,
  authentication and access control mechanisms rely on the existence
  of a trusted, centralised entity, e.g., the public key
  infrastructure~(PKI) requires a centralised trusted certification
  authority~(CA).
\item Routing attacks --- Nodes in MANETs organise themselves to
  communicate with their neighbours in such a way as to provide
  connectivity across the networks. As the nodes are mobile and have
  the freedom to move in an arbitrary manner, the network topology
  changes frequently in an unpredictable fashion. Consequently,
  communication routes between nodes also change and network
  partitioning may happen if there is no overlap in network coverage
  of two or more sets of nodes. Therefore, the routing algorithm has
  to be highly adaptive and robust to accommodate these frequent
  changes. There are many possible attacks on routing identified in
  the literature. In the simplest case, the routing table in the nodes
  can be directly modified once they are captured by
  adversaries. Packets can also be maliciously created, modified or
  dropped to change the routing table. Additionally, attacks on
  routing can be launched by making the nodes inactive or by making
  them behave selfishly~(only use services but do not cooperate in
  routing tasks).
\item Resource attacks --- Mobile nodes have constraints on their
  resources, in terms of power sources, processing power and network
  bandwidth. The efficiency in using these resources is an important
  factor in designing MANETs. Often, the nodes in MANETs are allowed
  to switch themselves into a sleep mode to conserve energy. However,
  this in turn leads to the routing problem mentioned earlier. In
  contrast, sleep deprivation is another type of attack that aims to
  exhaust the power resource of the nodes by keeping the nodes active
  at all times. Furthermore, the bandwidth of wireless links is
  significantly less compared to wired links due to noise and
  interference. Consequently, there is a constraint on the amount of
  data that can be trasmitted at one time in the networks.
\item Incompatibility of traditional cryptography techniques --- Many
  traditional cryptography techniques cannot be directly implemented
  in MANETs for two main reasons. Firstly, many of these techniques
  require a centralised entity, which is not present in
  MANETs. Indeed, it is often the case that no node in the network may
  be assumed to be fully trustworthy because of the hostile
  operational environment. Secondly, traditional techniques constantly
  strive for more computational resources, yet the nodes in MANETs
  often only have limited computational and power resources.
\item Inherent problems in wireless communication --- MANETs inherit
  all the security problems of wireless networks. The wireless
  communication medium is less reliable than the wired medium. It is
  necessary for the networks to be able to distinguish the variation
  in physical link performance and the possible forms of malicious
  attacks, e.g., DoS attacks. These attacks can happen at various
  network layers. Additionally, wireless communication is broadcast in
  open air and no physical security protection can be used to protect
  the communication channels. It is necessary to assume that
  adversaries can eavesdrop and possibly perform some interpretations
  on the transmitted signals, e.g., traffic analysis. The broadcast
  signal can also be used by adversaries to disclose the location of
  the networks/nodes.
\item Operational environments --- MANETs are often deployed in risky
  and hostile environments such as battlefields. Therefore, it is safe
  to assume that the networks may face more challenging security
  attacks than conventional networks. Attackers can, for example,
  capture the nodes in MANETs and use them to launch internal attacks.
% \item Scalability --- Whilst current existing network management
%   algorithms are designed to work with a relatively stable and small
%   number of nodes, MANETs often consist of a huge number of nodes. This
%   is especially true in millitary applications. The distribution of
%   administrative tasks among nodes in MANETs, due to the lack of a
%   centralised server, increases security risk as there is an increased
%   number of possible access points for intrusion. The complexity
%   introduced by distributed systems also makes development and
%   maintenance difficult.
%X
\item Security policy issues --- There is no single trusted entity in
  MANETs. This causes the policy enforcement process to be very
  difficult. The dynamic nature of the networks also cause the risk
  factors to be constantly changing. Current static security policies
  that consist of static rules are unable to cope with this. For
  example, the risk that a node is exposed to may change depending on
  the operational environment~(e.g., time and location) and the
  remaining resources~(e.g., network bandwidth and battery power) of
  the node.

\end{enumerate}

%\subsection{Trust and Risk Management in MANET}
%\label{TrustAndManagementInMANET}
%As a result of these challenges, MANET security has become an
%increasingly active research domain. We are particularly interested in
%the trust and risk management aspect. Security is inherently related
%to trust and risk; security risk management is an important process in
%ensuring that the security controls implemented in a system are fully
%commensurate with the risk it is exposed to. Risk factors are first
%identified and then estimated, quantified and aggregated. Due to the
%dynamic feature of MANET, it is necessary to do the risk estimation
%and quantification process dynamically during operational time. The
%estimated risk is then used to guide making decisions on the
%implementation of security controls.

\section{Conclusions}
\label{ComputerSecurity.Conclusion}
This chapter presents a brief overview of computer security. It
discusses security objectives, namely confidentiality, integrity,
availability, authenticity and accountability. It then discusses
security risk analysis, which involves the process of identifying
assets and their vulnerabilities to threats, the risk assessment
process, and the selection of security controls. Next, it presents the
concept of dynamic coalitions and MANETs. Lastly, it presents a review
on the limitations of current security mechanisms in relation to
MANETs.

% ------------------------------------------------------------------------


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../thesis"
%%% End: 
