\chapter{Security Policy Models}
\graphicspath{{Chapter3/figures/}}
\label{SecurityPolicyModels}
A security policy is
\begin{quote}
  a set of policy rules (or principles) that direct how a system (or
  an organization) provides security services to protect sensitive and
  critical system resources \cite{RS07}.
\end{quote}
A security policy must therefore specify \emph{all} necessary control
measures for ensuring the system security, including how
authentication should be done and what responses should be made to a
security violation, etc.

Access control specification is typically a major component of a
security policy. Access control protects the resources of a system
(objects) against unauthorised access by restricting the use of system
resources only to the authorised users (subjects) according to the
security policy of the system \cite{RS07}. Access can be in many
modes; the common ones include read, write, append and execute. The
access mode that a subject has on the objects in the system is known
as the ``privilege'' the subject has. The set of high-level rules that
specifies which accesses are to be authorised and which are not is
known as the access control policy \cite{PS01}. The study of access
control policy has resulted in various useful models. Most of these
models are formal, i.e., formal analysis can be carried out to prove
the models are secure with respect to the security objectives
concerned. There are also some models consisting of a few informal,
high-level principles, e.g., the Clark-Wilson model \cite{DDC87}.
 
This chapter first reviews some traditionally influential security
policy models in the literature. It then presents two recently
proposed risk based models which aim to provide more
flexibility. Lastly, it presents the top-down policy development model
which enables policy composition and refinement, with an emphasis on
the problems encountered in the refinement and conflict analysis
processes.

\section{Mandatory Access Control Policy Models}
\label{MAC}
The Multi-Level Security (MLS) system was first developed in the
defence community as a means to manage information with different
sensitivities. In the system, each object (e.g., a file) is given a
classification label that represents its sensitivity and each user is
assigned a clearance level which is on the same scale as the
classification. The clearance level a user has depends on the user's
background, e.g., rank, previous position, etc. Essentially, these
factors are used to establish the trustworthiness of the user and the
information the user needs to know. The clearance level of the user is
then subsequently determined and granted. Mandatory Access Control
(MAC) policies enforce access control to objects by comparing the
classification labels of the information (objects) with the clearance
levels of the users (subjects) \cite{DOD85}. This is typified by the
Bell-LaPadula Model \cite{DEB73}.

\subsection{The Bell-LaPadula Model}
\label{BellLaPadulaModel}
The Bell-LaPadula model is concerned with the confidentiality of
objects in an information system. In this model, each entity in the
system is either a subject or an object. Each entity is associated
with a security label of the form $\langle\text{classification level},
\text{category set}\rangle$. The set of classification levels consists
of names that form a $>$ relation based on the sensitivity or the
clearance. An example of classification levels can be $\{$top secret,
secret, confidential, unclassified$\}$, where top secret $>$ secret
$>$ confidential $>$ unclassified. The set of categories contains
names that form compartments which provide a means to the creators of
the objects to control and restrict the distribution of the
objects. An example of categories can be $\{$investment banking,
equity, technology$\}$ in a financial institute.

With such setting, a dominance, $\succeq$ relation can be defined on
security labels as follows: \newtheorem*{theorem}{Dominance,
  $\succeq$}
\begin{theorem}
  Let $\langle s_{a}, c_{a} \rangle$ and $\langle s_{b}, c_{b}
  \rangle$ be the security label of $a$ and $b$, $a \succeq b
  \Leftrightarrow s_a \geq s_b \wedge c_a \supseteq c_b$.
\end{theorem}
This relation form a partial order set (poset) on the security
labels. Two properties are defined using this relation to ensure the
system remains secure with respect to confidentiality of the objects
in a system:
\begin{enumerate}
\item The simple security property (no read up) --- no subject can
  read any object with a higher security label than its own security
  label. This can be rewritten in a non-negated form as $\forall s \in
  \textit{Subject}, o \in \textit{Object}: s \text{ can read } o
  \Leftrightarrow \operatorname{label}(s) \succeq
  \operatorname{label}(o)$.
\item The *-property (no write down) --- no subject can write to an
  object with a lower security label than its own. Formally, this can
  be written as $\forall s \in \textit{Subject}, o \in
  \textit{Object}: s \text{ can write } o \Leftrightarrow
  \operatorname{label}(s) \preceq \operatorname{label}(o)$.
\end{enumerate}
In other words, the Bell-LaPadula model restricts information to flow
from low confidentiality to high confidentiality, but not vice
versa. Later, a tranquillity property is added to explicitly state that
security labels of the entities in the system cannot change during
system operation to rebut some criticisms received in \cite{JM85,
  JM90}. (If security labels can change arbitrarily under system
operation, then clearly security can be compromised. Consider a system
in which the security labels of all subjects are changed to the
maximum possible levels allowing all files to be read by everyone).

Whilst MAC is often associated with the Bell-LaPadula model, they are
not the same. MAC really means that the security policy which governs
the system is enforced by the system itself, as implied by the term
``mandatory''. The subjects cannot manipulate access control
attributes of the objects they own at their own discretion. The
Bell-LaPadula model is just an instance of MAC.

\subsection{The Biba Model}
\label{BibaModel}
A closely related model is the Biba model \cite{KJB77}, which is
concerned with the integrity of an object in the system. It is
essentially the inverse model of the Bell-LaPadula Model, i.e., the
information is restricted to flow from high integrity to
low integrity, but not vice versa. The two properties defined to
ensure integrity of the system are:
\begin{enumerate}
\item The simple security property (no write up) --- $\forall s \in
  \textit{Subject}, o \in \textit{Object}: s \text{ can write } o
  \Leftrightarrow \operatorname{label}(s) \succeq
  \operatorname{label}(o)$.
\item The *-property (no read down) --- $\forall s \in
  \textit{Subject}, o \in \textit{Object}: s \text{ can read } o
  \Leftrightarrow \operatorname{label}(s) \preceq
  \operatorname{label}(o)$. %Often, this implication is taken as the
                            %property because of its simplicity and
                            %symetricity with the *-property in the
                            %Bell-LaPadula model.
\end{enumerate}

The Biba model also introduced two new concepts: dynamic security
label and invocation operation. The dynamic security label relaxes the
constrain of static security classification in the Bell-LaPadula
model. An access that violates the two properties are permitted with
the condition that the security label of the subject and object which
are involved in the contact are reclassified to the lower label of the
two after the access. The new invocation operation enables subjects to
invoke other subjects (probably software processes) to access
objects. To remain consistent, the invocation property is defined such
that subjects are allowed to invoke only subjects with lower or equal
security labels\footnote{The ring property is an alternative property
  defined such that there is no restriction is set for read access,
  i.e., any subject can read any object regardless of their security
  labels, but a subject $s_1$ can write an object $o_1$ only if
  $\operatorname{label}(s_1) \succeq \operatorname{label}(o_1)$ and a
  subject $s_1$ can invoke a subject $s_2$ iff
  $\operatorname{label}(s_1) \preceq
  \operatorname{label}(s_2)$. However this property is inconsistent
  with the other properties defined here. One must choose which is
  more appropriate to use depending on the application.}.

\subsection{The Chinese Wall Model}
\label{ChineseWallModel}
The security models introduced so far are inspired from the military
application. The Chinese Wall model \cite{DFCB89} is a commercially
inspired model which is concerned with confidentiality by ensuring
that information flow in the system does not have any conflict of
interest. A classic scenario example is the services offered by a
financial institute to different clients, some of which are
competitors to the others. A conflict of interest can arise when an
analyst in the institute is involved in two companies in the same
market because the insider knowledge that the analyst gains in one
company may result in an unfair treatment of the other and vice versa.

The Chinese Wall model groups all objects related to a company in a
company dataset, and datasets with conflicts of interest are grouped
under the same conflict class. If necessary, company datasets can be
``sanitised'' into a dataset containing no critical information. No
one should be authorised to access more than one ``unsanitised''
dataset from the same conflict class. As the conflict depends not only
on the current object to be accessed but also all other previously
accessed objects, the access history of each subject must be
kept. %This can be achieved by keeping a 2-D boolean matrix that
      %records whether a subject has ever accessed an object can be
      %used.

Two properties are defined to ensure valid access control:
\begin{enumerate}
\item The simple security property --- a subject can access an object
  only if the object is within a currently held dataset, or an
  entirely different conflict class. However, this property in itself
  does not prevent indirect information leakage. A subject can read
  information from one dataset and write in another dataset for other
  subjects to read. Therefore the *-property is defined to prevent
  this kind of violation.
\item The *-property --- a subject can write an object only if the
  subject does not have read access to any other company datasets
  which are not ``sanitised''. Dataset is said to be sanitised if the
  sensitive details within it has been removed. *-property ensures
  that the unsanitised information flow is restricted within its own
  company dataset whereas sanitised information flow is not restricted
  throughout the system.
\end{enumerate}


In contrast to the Bell-LaPadula model which assumes that access
rights are static, the Chinese Wall model assumes that access rights
are dynamic and therefore have to be reexamined during all state
transitions. The identification of the importance of access history
also proliferates the research into history based access control and
dynamic separation of duty.

\subsection{The Clark-Wilson Model}
\label{ClarkWilsonModel}
The Clark-Wilson model \cite{DDC87} is a commercially inspired model
which is concerned with integrity. The core of the model is based on
the two well established principles in commercial worlds: well-formed
transactions and separation of duty.

A well-formed transaction is a series of operations, which changes the
data in the system from one valid state to another. This is to
preserve the internal consistency of data in the system.  The
separation of duty principle requires that the entity that certifies a
transaction and the entity that executes the transaction to be
different. Provided that these entities do not conspire, this
principle should preserve the external consistency of the system,
i.e., the data in the system reflects the data it represents in the
real world.

The objects in the Clark-Wilson model is divided into either
constrained data items (CDI) or unconstrained data items (UDI). Nine
rules, five certification rules and four enforcement rules, are
defined to constrain how to validate integrity of CDI, how and who can
change CDI and how to change UDI to CDI.

\section{Discretionary Access Control Policy Models}
\label{DAC}
Most MAC policy models are formal. This allows them to be verifiable
for security purposes; but this also makes these models very
restrictive and not practical for many purposes. Unlike MAC,
Discretionary Access Control (DAC) policies restrict access to objects
based on the identity of the subjects and/or the groups to which the
subjects belong to. The resource owners can delegate the access
privileges to other subjects at their own discretion; hence the name.

DAC policies can be represented using the access control matrix
\cite{BWL71}. An access control matrix is a 2-D matrix, in which the
rows correspond to subjects and columns correspond to objects. An
element in the matrix specifies the privilege a subject has on an
object. Let r, w, x represent read, write, execute access
respectively; an access control matrix example is depicted in Figure
\ref{fig:AccessControlMatrix}.

\begin{figure}[htbp]
 \centering
 \begin{tabular}{ | l | l | l | l |} \hline
             & File 1 & File 2 & Device \\ \hline
   Alice     & rwx    & rwx    & rwx    \\ \hline
   Bob       & r      & r      & rwx    \\ \hline
   Charles   & rw     & rw     & -      \\ \hline
  \end{tabular}
 \caption{An access control matrix example.}
 \label{fig:AccessControlMatrix}
\end{figure}

Whilst the access matrix provides a convenient way of expressing DAC
policies, an access matrix is likely to be too large and also too
sparse to be stored efficiently in practice. Consequently, the access
matrix is usually stored either by columns or rows, resulting in
access control lists (ACLs) and capability lists respectively.

Access control lists (ACLs) are lists of ACL entries. Each entry
stores a column of the access matrix, along with the object which the
column corresponds to. Each entry specifies which subject is allowed
to access an object and in what ways. This object-centred decoupling
makes ACLs suitable for operating environments where the protection is
central to the objects, e.g., operating systems. Conversely, if the
number of subjects in an operating environment is large and constantly
changing, ACLs becomes less suitable. The way which ACLs store
information is inefficient when one needs to find all the objects that
a particular subject has permission to access. A check on the ACLs of
all objects in the system is required.

Capability lists store the access matrix by rows. The strengths and
weaknesses of capability lists are more or less the opposite of
ACLs. The decoupling is subject-centred; it is easy to check what
privileges a subject has but it is tedious to check the privileges
granted to a particular object.

\section{Role based Access Control Policy Models}
\label{RBAC}
DAC policy models however post several challenges on the privilege
administrations, especially when the information system becomes
large. An interesting observation is that the objects in the system
are often not owned by the users themselves, but the organizations
they work for. The access control decisions to the objects are often
determined by the responsibilities of the roles the users hold
\cite{DFF92}. This gives rise to a new type of access control model
--- Role based access control (RBAC) in which the access privileges in
the system are defined in terms of the role a subject has, rather the
the subject itself \cite{DFF92}.

The basic components in RBAC are: users, permissions, roles and
sessions. Two relations are defined: user assignment (UA) that
associates users with roles and permission assignment (PA) which
associates roles with permissions. Both relationships are many to many
mapping. Permissions are granted to users through roles. At any time,
a user can choose to activate a subset of roles that he has been
assigned; the permissions then available to the user are those
associated with the roles activated in that session.

There have been many extensions made to RBAC. The focus of discussion
here is on the American National Institute of Science and Technology
(NIST) RBAC reference model \cite{RS00} which has later been revised
to become the American National Standards Institute (ANSI) standard
(ANSI/INCITS 359-2004) \cite{ANSI04}.

The ANSI RBAC reference model consists of four components: Core RBAC,
Hierarchical RBAC, Static Separation of Duty Relations and Dynamic
Separation of Duty Relations. The Core RBAC defines the fundamental
elements in a RBAC system. These include all the functional
capabilities of RBAC presented so far, i.e., user assignment and
permission assignment relations, session as well as support for
user-role review (the ability to determining which role is given to a
user and vice versa).


Hierarchical RBAC introduces the concept of role hierarchies, which
allows roles to inherit the permissions of other roles, e.g., a senior
role inherits all the permissions of a junior role. This often
improves administrative efficiency through the reduction in the number
of permission mappings. However, the permission inheritance based on
the seniority hierarchy in the real world is not always suitable. In
\cite{JDM98}, Moffett presented some examples of how this can be in
conflict with some control principles such as the separation of duty
principle, decentralisation, supervision and review. Whilst various
ad-hoc methods such as the use of private roles \cite{RSS96} or
exceptions \cite{DJ96} can be introduced to overcome this problem,
these methods defeat the original intent of improving the
administrative efficiency.

Static Separation of Duty Relations introduces the concept of
constraints on user assignments. As this concept may conflict with the
concept of role hierarchies, this concept is specified in both the
presence and absence of the concept of role hierarchies. Dynamic
Separation of Duty Relations introduces the concept of constraints on
the role activation in a session for users.

A common alternative reviewed in the literature is the original NIST
standard which defines four conceptual models: Flat RBAC, Hierarchical
RBAC, Constrained RBAC and Symmetric RBAC. Flat RBAC is essentially
the same as the Core RBAC component; Hierarchical RBAC is Flat RBAC
with role hierarchy support; Constrained RBAC is Hierarchical RBAC
with constraints on the user assignments and role activation in a
session for users; Symmetric RBAC is Constrained RBAC with support for
permission-role review. In ANSI standard specification, the support
for permission-role review is left as an optional feature because it
is intrinsically difficult to be implemented in large distributed
systems \cite{RS00}.

The main advantage of RBAC is that it eases the administration task
\cite{DFF92, MN93}. Once the role-permission mapping is established,
it is likely to remain constant. The administrative task of assigning
role to user is remarkably easier and less prone to error as compared
to assigning permissions to the user directly.

There have been many other extensions proposed for RBAC. The extension
on the group or team concept is a common one. In the same way that
role is used to group privileges, users can be grouped based upon the
group or team they belong to. Each team then is associated with
roles. Team based Access Control \cite{RT97} and Coalition based
Access Control \cite{EC02} are examples of this. Temporal RBAC (TRBAC)
is proposed in \cite{EB00} to introduce the concept of temporal
constraint to RBAC. TRBAC allows the use of temporal constraints to
specify the periodic role activation and also the dependencies between
the role activation via role trigger mechanisms.

\section{Flexible  Access Control Policy Models}
\label{FlexibleAccessControlModels}
Whilst DAC and RBAC policy models provide better flexibility through
permission delegation and role abstraction, the permission assignments
to the users remain static. In practice, the permission assignments
and the protection requirements of the objects may change over
time. The task of administering the access control policy can easily
become unmanageable, especially when the operational environment is
highly dynamic.

Here we review some access control models that aim to provide more
flexibility, namely the Fuzzy MLS model \cite{PCC07, PCC07A} and JASON
economics based models \cite{JPO04}. The intuition of these models is
based upon the observation that access control is governed by the risk
incurred and the benefit an organization can gain from the access. An
access is authorised only if the benefit outweigh the risk
incurred. The risk-benefit tradeoff assessment of the models presented
so far is implicitly and statically encoded in the models. These two
models advocate the use of an explicit model to dynamically estimate
the risk to make more informed decisions.

\subsection{The Fuzzy MLS Model}
\label{FuzzyMLSModel}
The Fuzzy MLS model is an adaptive extension on the read access aspect
of the Bell-LaPadula model. In the Bell-LaPadula model, a subject can
read an object iff the security label of the subject $\succeq$ the
security label of the object, i.e., the sensitivity level of the
subject ($sl$) $\geq$ the sensitivity level of the object ($ol$) and
the category set of the subject ($sc$) $\supseteq$ the category set of
the object ($oc$). This can be interpreted informally as a subject can
read an object iff the subject is trustworthy enough and has the
legitimate ``need-to-know'' to access the object. The policy encoded
in this model essentially divides each access as either having an
acceptable amount of risk or an unacceptable amount of risk; only the
accesses with acceptable amount of risk are authorised \cite{PCC07}.

The Fuzzy MLS model continues to employ this risk based rationale, but
it changes the access control from a risk avoidance system (inherent
in the binary decision-making process) to a risk management system by
computing the ``quantified risk'' estimated by the ``gap'' between the
security labels of the subject and object.

The model consists of a risk scale that is divided into three parts:
top, middle and bottom as shown in Figure
\ref{fig:FuzzyMLSModel}. Each access is mapped to a point on the
scale. An access that is mapped to a point in the top region is denied
because the risk is too high; an access that is mapped to a point in
the bottom region is authorised. The middle region is further divided
into multiple risk bands such that each band is associated with a risk
mitigation measure; an access that is mapped to this region is
authorised only if the associated risk mitigation measure can be
applied to reduce the risk level to the bottom region. The change of
the binary decision model to this continuous model, which uses a risk
scale is very similar to the intution in fuzzy logic, thus the name
``Fuzzy MLS'' \cite{PCC07}.

\begin{figure}[htbp]
 \centering
 \includegraphics[width=0.8\textwidth]{RiskScale}
 \caption{The risk adaptive access control on a risk scale \cite{PCC07}.}
 \label{fig:FuzzyMLSModel}
\end{figure}

Two alternative risk management systems: the credit card system and
economics based system are also discussed in \cite{PCC07}. In the
credit card system, each subject is given a risk credit. When a
subject makes an exceptional access, the difference between the risk
and the soft boundary will be charged to the risk credit of the
user. Periodically, the return on investment (ROI) of each user is
evaluated to determine the future risk credit of the user, based on
the risk credit charged and the result delivered by the
user. Activities can also be logged to allow periodic refinement of
access control policy. This provides a way of governing the long-term
behaviours of users, yet still maintaining sufficient flexibility as
provided by the use of risk credit. In the economics based system, the
notion of pseudo currency is introduced in place of risk credit. Each
user is given an amount of pseudo currency which can be used to
purchase information access.  Higher risk access costs more. Similar
to the credit card system, the amount of pseudo currency allocated to
a user in the future depends on the ROI of the user. This is very
similar to the JASON economics based models presented in Section
\ref{JASONEconomicsBasedModel}.

\subsubsection{Risk Computation}
\label{RiskComputation}
The Fuzzy MLS model defines risk as the expected value of damage
caused by unauthorised disclosure of information:
\begin{equation}
  \text{risk} = \text{value of damage, } V \times \text{probability of incurring the damage, } P 
\label{eq:risk}
\end{equation}
The expected value of damage, $V$ can be derived from the sensitivity
level of the information object, $ol$. As $ol$ typically corresponds
to the order of damage, $V$ is defined as an exponential function of
$ol$:
\begin{equation}
  V =a^{ol} \text{, $a > 1$}
\end{equation}
The probability of unauthorised disclosure, $P$ can be estimated by
quantifying two ``gaps'': one between the sensitivity levels of the
subject and the object and the other between the category sets of the
subject and the object.

In the Bell-LaPadula model, $P$, can be viewed as the sum of two
probabilities, $P_1$ and $P_2$:
\begin{equation}
P = P_1 + P_2 - P_1P_2
\label{eq:P}
\end{equation}
where $P_1$ and $P_2$ are:
\begin{align*}
  & P_1=
  \begin{cases}
    0 & \text{if the sensitivity level of the subject $\geq$ the sensitivity level of the object} \\
    1 & \text{otherwise}
  \end{cases} \\
  & P_2=
  \begin{cases}
    0 & \text{if the category set of the subject $\supseteq$ the category set of the object} \\
    1 & \text{otherwise}
  \end{cases}
\end{align*}
The Fuzzy MLS model continues to use \eqref{eq:P} to estimate these
probabilities, but allows these probabilities to take real values in
$[0.0, 1.0]$ instead of only being expressed as binary values.

To determine the probabilities $P$, $P_1$ and $P_2$ precisely is
impossible as no one knows the future for certain. However, risk
indices can be formulated by having a qualitative assessment on the
likelihood of misuse in different access operations. The higher the
likelihood of misuse, the higher the risk index. Thereafter, these
risk indices can be mapped onto probabilities based on previous
experiences and intuitions. The use of risk indices is doubly
useful. Firstly, it removes the constraints imposed by the probability
theory, e.g., the sum of probabilities of all possible outcome must be
$1$. This provides a more fine-grained view on risk. Secondly, it
makes the fine tuning task easier in the future. Risk indices, once
determined, can be kept fixed; only the mapping function is required
to be tuned over time.

$P_1$ is defined as the probability of a subject failing to resist the
temptation of unauthorised information disclosure. The Bell-LaPadula
model can be viewed as taking a binary view on temptation:
temptation happens if the sensitivity level of subject ($sl$) $<$ the
sensitivity level of the object ($ol$) and information disclosure
always happens ($P_1 = 1$) if temptation exists. Therefore, the
Bell-LaPadula model only allows access when $sl \geq ol$.

To formulate $P_1$ for Fuzzy MLS Model, the temptation index $TI$ is
first derived. In the understanding that there are many different ways
to relate $TI$ to $sl$ and $ol$, the relation must satisfy the
following properties \cite{PCC07A}:
\begin{itemize}
\item As the sensitivity level of an object increases, the temptation
  increases.
\item As the sensitivity level of a subject increases, the
  temptation decreases.
\item Every subject faces temptation, i.e., there is no $100\%$
  trustworthy subject.
\item $TI$ is biased towards more sensitive objects.
\end{itemize}

A simple formula \cite{PCC07} that satisfies these properties is:
\begin{equation}
  TI(sl, ol) = \dfrac{\alpha^{-(sl - ol)}}{m - ol}
\label{eq:TI}
\end{equation}
where $\alpha$, $m \in \mathbb{R}$, $\alpha > 1.0$, $m > max\{ol \mid
ol \in OL\}$, where $OL$ is the set of all $ol$s. The $\alpha^{ol}$
represents the estimated value of an object and $\alpha^{sl}$
represents the trustworthiness of a subject. $TI$ approaches infinity
(temptation becomes very large and difficult to resist) as $ol$
approaches $m$.

To relate $P_1$ to $TI$, a sigmoid function:
\begin{equation}
 P_1 = \dfrac{1}{1 + exp((-k) \times (TI-mid))} 
\label{eq:P1}
\end{equation}
is derived. $mid$ is the value of $TI$ that makes $P_1 = 0.5$; $k$
controls the slope of $P_1$ curve with regard to $TI$. This function
is chosen because of its similarity with the step function in the
Bell-LaPadula model.

$P_2$ corresponds to the difference between the probability of
unintentional disclosure and the probability of disclosure which the
organization is willing to accept in as a subject accesses an
object. In the case that an object being accessed belongs to multiple
categories, a simplified assumption is made such that the object is a
monolithic entity, in which the differences among all the categories
are computed and the maximum difference is used as $P_2$. Instead of a
binary value, a fuzzy membership value is assigned to each subject to
represent the ``need-to-know'' level of a subject for the object in
each category.

The willingness index, $WI$ can be computed using \eqref{eq:TI} with
the fuzzy memberships in place of the sensitivity levels. Then the
willingness of acceptance for an organization when a subject accesses
an object, $W_c$ can be computed using \eqref{eq:P1} with $WI$ in
place of $TI$. Let $P_{id_c}$ be the probability of unintentional
disclosure for category $c$, $P_2$ is:
\begin{equation}
\label{eq:P2}
P_2 = max\{P_{id_c}(1 - W_c) \mid c \text{ is a category}\}
\end{equation}

Finally, the risk of a read access is computed using \eqref{eq:risk}.

\subsubsection{Review}
\label{FuzzyMLSModel.Review}
The Fuzzy MLS model draws inspiration from the fuzzy set theory to
estimate and quantify risk in the traditional Bell-LaPadula
model. This model continues to employ the risk based rationale, but it
changes the access control model from a risk avoidance system to a
risk management system by estimating the risk of each access with a
risk scale.

This risk scale allows the model to adapt to environmental changes in
several ways. Firstly, the boundaries between regions can be
dynamically adjusted to control the system's global risk
tolerance. Secondly, accesses that would have been denied under the
traditional model may now be allowed if the associated mitigation
measures can be provided. Thirdly, the risk function that maps each
access to a point on the risk scale can be updated periodically to
reflect the changes in the operational environment.

In practice, the security labels of the objects in a system are often
set with a tendency towards higher secrecy to minimise the operational
risk. Consequently, the information sharing becomes more
difficult. This over-classification problem can be addressed by making
the label to take uncertainty into account \cite{PCC07}. This is not
possible in the traditional Bell-LaPadula model.

The Fuzzy MLS model however has its shortcoming; it only uses the
security labels to estimate risk. As outlined in \cite{JPO04}, there
are many other factors that can affect the risk of an access, e.g.,
the access methods (softcopy vs hardcopy), the operational
environment and the risk mitigation measures employed, etc. The best
way to identify, quantify and aggregate these factors remains a
research topic. Risk aggregation on information can be tricky as the
sensitivity of a piece of information provided to a subject does not
solely depend on itself, but also on other information that the
subject can access \cite{PCC07}. Additionally, accesses to multiple
pieces of low sensitivity information may allow a subject to infer
information that is far more sensitive.

\subsubsection{Summary}
\label{FuzzyMLSModel.Summary}
Lofti A Zadeh, the father of fuzzy set theory, advocates the
fuzzification process as a methodology to generalise any discrete
theory to its continuous form \cite{GJK96}.  The Fuzzy MLS model uses
this concept to generalise the traditional Bell-LaPadula model in
estimating and quantifying the risk of each access with a risk
scale. This changes the access control model from a risk avoidance
system to a more flexible risk management system.

\subsection{The JASON Economics based Models}
\label{JASONEconomicsBasedModel}
The idea of managing risk in the access control using the economic
concept is proposed in \cite{JPO04}. Each user in an organisation is
allocated an amount of risk tokens, which can be spent for operational
needs.  The amount of risk tokens a user will get in the future
depends on the return of investment of the user. Essentially, risk is
viewed as a type of limited resource in an organization and the access
control problem is transformed into a resource allocation problem. Two
economics based models are introduced: a model based on command
economic system and a model based on market economic system.

% The proposal is done in three incremental phases. The first phase is
% the preparatory phase, where the necessary components in making the
% system work are discussed. The following two phases introduce two
% models: the command economy system (also known as the push economy
% system) and the market economy system (also known as the pull economy
% system).

\subsubsection{Definition of Risk, Damage and Harm}
\label{sec:ebsdefinitionofriskharmanddamage}
JASON introduced a new definition for risk and two new terms:
``damage'' and ``harm''. Risk is defined as the unnormalised
probability of an access which can cause a secret loss; damage is
defined as the cost of the lost secret; and harm is defined as the
expected cost of the lost secret. These terms are related as follows:
\begin{equation}
  \text{harm} = \text{damage} \times \text{risk} 
\label{eq:ebsharm}
\end{equation}
The definition of risk is different from the one defined in Fuzzy MLS
model \eqref{eq:risk}, which is restated as follows for ease of
referencing:
\begin{equation}
  \text{risk} = \text{value of damage, } V \times \text{probability of incurring the damage, } P 
\end{equation}

A careful examination of both equations allows us to establish a
mapping between the terms: the term ``harm'' in JASON models
corresponds to the term ``risk'' in Fuzzy MLS Model; the term
``damage'' hold the same meaning in both models; and the term ``risk''
in JASON models corresponds to the term ``probability'' of incurring a
damage in Fuzzy MLS Model. In this thesis, the terms are used in the
way they concur to the original report as to allow easy referencing.

\subsubsection{Three Guiding Principles}
\label{sec:ebsprinciples}
JASON suggests that the new information protection system should be
risk based and outlines three principles that should be followed in
building such a system. These principles are as follows:
\begin{description}
\item[Measure risk] --- The amount of risk associated with each
  access should be measured or at least estimated.
\item[Mark an acceptable risk level] --- Risk avoidance (setting the
  acceptable risk level to zero) effectively stops all the information
  accesses because every access has an inherent amount of risk
  associated with it. The acceptable risk level should be set to a
  value that optimises the long-term benefit, knowing the security
  leaks happen today may affect the future.
\item[Maximise the information flow up to the acceptable level] --- In
  contrast to the current systems which attempt to minimise the total
  risk, information in the system should flow to the greatest extent
  compatible with the acceptable risk level in order to optimise gain.
\end{description}

\subsubsection{Risk Model}
\label{sec:ebsriskmodel}
A risk model is required to estimate the risk of each access. The
following factors should be considered in building this model:
\begin{description}
\item [Individual factors] --- the role, security clearance, personal
  record, etc.
\item [Situational factors] --- the operational environment, security
  of the technology used to implement, etc.
\item [Technical factors] --- the software security, hardware
  security, etc.
\item [Types of accesses] --- the access method (softcopy
  vs. hardcopy), access duration, access is auditable, information can
  be redistributed, etc.
\item [Temporal effects of losses] --- leaking a news on the amount of
  budget allocated for a small project may result in short-term risk
  but leaking the information of national secret weapon information
  may result in a long-term risk.
\end{description}
These factors have to be combined in a mathematical way to yield a
formula that can be used to assign risk value to each information access.

\subsubsection{Model based on Command Economic System}
\label{sec:ebscommandeconomysystem}
In this model, the value of a token is pegged to risk
\cite{JPO04}. For example,
\begin{align}
  1 \text{ token} = & \text{ risk associated with softcopy access for a day to a document} \nonumber \\
  &\text{ by an individual who is cleared to the secret level.}
\label{def:ebstoken}
\end{align}
The value of the token is associated with the estimated risk incurred
in the access including the type and duration of the access and the
security clearance of the individual. Yet, it does not consider the
value of the document (the damage factor).

Using the risk model presented in Section \ref{sec:ebsriskmodel}, each
access can be associated with a certain amount of risk tokens. Higher
risk accesses cost more. For example,
\begin{itemize}
\item Softcopy access for a day to a document by an individual who is
  cleared to top secret level costs $0.2$ token.
\item Hardcopy access to a document by an individual who is cleared to
  secret level with a restriction on further distribution costs $50$
  tokens.
\end{itemize}
When a piece of information is being produced, the producer will
create the amount of tokens that is commensurate to the acceptable
risk level of the piece of information. For example, the production of
a document that may be viewed in softcopy for $500$ times by an
individual who is cleared to secret level is always accompanied by the
creation of $500$ tokens. If the $500$ tokens are spent by an
individual who is cleared to secret level to print the document in
hardcopy format for $10$ times with a restriction of no further
distribution, the acceptable risk level of the document would still be
considered reached.

Additionally, the use of different types of tokens is necessary for
different types of information. This is because all tokens are pegged
using the same baseline. More sensitive information have lesser
tolerable risk level and therefore have lesser amount of tokens
created with it.

To increase the liquidity of the market, a secondary market can be
introduced to allow token exchange. This does not require any change
on the model because the tolerable risk of the information has been
controlled by the amount of tokens created with it and other risk
factors have been taken care of in the cost associated to each
information access.

To distribute the risk tokens, the information producers create and
distribute the risk tokens to different organizations based on their
needs. Within an organization, risk tokens are pushed down through the
management hierarchy. Periodically, the distribution is reviewed based
on the return on investment function. Other metrics can also be used
to adjust the way to distribute the risk tokens. For example, a
utilisation function which measures the fraction of tokens that have
been used to purchase information accesses. The utilisation function
can also serve as a measure on the merits of the information
producers. If the utilisation fraction is near $100\%$, it means the
organization is almost reaping the full benefit of the information
produced and vice versa.

\subsubsection{Model based on Market Economic System}
\label{sec:ebsmarketeconomysystem}
The main aspect that differs this model from the previous model is the
collapse of many types of tokens to only two types. This removes the
controls that the producers have in setting the tolerable risk
associated with the information (via manipulation of the amount of
tokens created). The reason for having more than one type of tokens is
that different types of information require different protection
profiles over time. Some other changes include redefining the value
associated to a token and introducing the concept of a central bank.

In the previous model, the value of a token is pegged to risk.  In
such a setting, the accesses to information with different sensitivity
levels by individuals who are cleared to the same clerance level cost
the same. However, the expected damage from the unauthorised
disclosure of these information are likely to be different (more
sensitive information causes more damage). The amount of damage is
implicitly controlled via manipulation of the amount of
information-specific tokens created. The collapse of multiple
information-specific types of tokens into two generic types of tokens
makes this method no longer possible. To over this problem, the value
of a token in this new model is associated to harm ($\text{damage}
\times \text{risk}$) as defined in \eqref{eq:ebsharm}. This requires
an additional damage model.

In the distribution of risk tokens, a new central authority which
plays a similar role as the central bank in the real world is
introduced. This central authority is responsible for creating and
distributing risk tokens, monitoring the health of the tokens by
balancing demand and supply, and also controlling the inflation and
deflation rates.

\subsubsection{Review}
\label{sec:ebsreview}
The differences between the two models are summarised in Table
\ref{tbl:EBSComparison}.

\begin{table}[htbp]
\centering
\begin{tabular}{|p{0.4\textwidth}|p{0.4\textwidth}|}
  \hline
  Command economic system                   &Market economic system\\
  \hline
  The value of a token is associated with risk&The value of a token is associated with risk and damage\\
  \hline
  One type of tokens per information            &Two types of tokens: short-term and long-term\\
  \hline
  Tokens are created by the information producer&Tokens are created by a central authority (central bank)\\
  \hline
  Requires only a risk model                &Requires a risk model and a damage model\\
  \hline
  Risk management via controlling the amount of risk tokens&Risk management via controlling the demand and supply equilibrium of the information\\
  \hline
\end{tabular}
\caption{The difference between the model based on command economic system and the model based on market economic system.}
\label{tbl:EBSComparison}
\end{table}

Despite that JASON advocates the model based on market economic system
is better than the model based on command economic system, we think
that there are interesting features and tradeoffs in both models. As
shown in Table \ref{tbl:EBSComparison}, the value of a token is
defined in different ways. The model based on command economic system
has been deliberately simplified to introduce the new concept and to
make way for the model based on market economic system. This
advocation may also be compounded by an illusion that the market
economic is better than the command economic in the real world.

To have a fair comparison, the value of a token in the model based on
command economic system is associated with the amount of damage. The
only remaining difference now is the controls the producers have in
setting the tolerable damage associated with information in the model
based on command economic system. The information producers can be
dishonest in their claims if the sensitivity levels of information
produced by manipulating the amount of tokens created with them. This
may result in market dislocation. The model based on market economic
system is proposed to alleviate this problem by the introduction of a
central bank, thus making the credibility of the central bank a key
factor for this new model to operate properly. In other words, JASON
assumed that the risk of the central bank in being compromised is
smaller than the risk of market dislocation caused by the dishonest
behaviours of the information producers. This assumption may not hold
true in certain operational environments, e.g., MANETs do not have a
central trusted node and all nodes are exposed to security attacks.

Having said that, the three guiding principles in building a
protection system as outlined in Section \ref{sec:ebsprinciples} are
inspiring. Current protection systems always attempt to minimise the
risk incurred in each access in the hope that the total risk of all
accesses is below the acceptable risk threshold limit. These
principles recognise that risk is inevitably incurred in each access
and thus advocate managing the global risk. The acceptable risk
threshold limit is first determined and information flow is encouraged
all the way up to the acceptable limit to maximise the gain. This
provides greater short-term flexibility in the access
control. Information is made available to any user who is willing to
pay the cost, yet the long-term behaviours of users remain under
control as the token distribution are subjected to the return on
investment of each user.

The distribution of risk tokens based on the return on investment also
encourages each user to opt to access information in safer ways so as
to reduce expenses. A stricter enforcement on using safer access
methods can be achieved by reducing the amount of tokens given to the
individual. If the tokens are spent in the usage of a more risky
(expensive) way to access information, the individual may not have
sufficient tokens to accomplish other duties assigned.

There is a natural reluctance for human users to make decisions that
have far reaching consequences, e.g., revoking a clearance of an
user. The risk model helps by redefining the responsibilities of a
human user in terms of security and operational duties. The security
duty encompasses ensuring the integrity of the information entered to
the risk model. This incremental information input to the risk model,
which gradually changes the trust levels of a user, becomes less
daunting in comparison to the immediate revoke of the clearance of a
user. The operational duty is to ensure that the tokens are used or
distributed wisely in the organization/team, e.g., a manager may make
an economic decision in distributing the tasks to his employees.
However, the use of the risk model leads to an accountability issue:
who is going to be responsible when something goes wrong? The risk
model, the user or the higher level organization? There is no obvious
answer. Without accountability, the number of misuses is likely to
increase.

In economics based models, the availability of information access is
tightly linked to the risk tokens. Users who use up all their budgets
are rendered useless until the next token distribution cycle. This can
happen due to the use of an imperfect risk model, an imbalanced
distribution of risk tokens or misbehaviours of users. In the former
two cases, continual refinements have to be employed in a timely
manner to avoid causing market dislocation. If it is due to the
misbehaviours of users, simply denying the user's access request can
be a logical answer but inappropriate in certain scenarios. For
example, a commander who has used up his entire budget in a
battlefield needs an information access to ask for
reinforcement. Denying his access request may result in fatal
casualty.

Both models also assume that entities are rational and therefore will
make the best decision among given choices. However, psychological and
social research suggest otherwise; human decision-making process is
often suboptimal and irrational. For example, the ``heuristics and
biases'' programme was started to investigate the idea of whether the
decision-making process under uncertainty often rests on a limited
number of simplified heuristics\footnote{heuristics are the simple yet
  efficient rules which humans use to make decision} or on an
extensive algorithmic processing \cite{AT74}. One of the results was
the framing effect, which showed that the way a problem is formulated
can have influence on the decision-making process \cite{AT81}. A
problem can emphasize on a gain ($30\%$ of the people will pass the
examination) or as on loss ($70\%$ of the people will fail the
examination). The former case generally leads to risk aversion
behaviour while the latter case generally leads to risk seeking
behaviour. Relationship among people can also have effects on the
decision-making process. For example, a captain may choose not to
report the misuse of authority among his soldiers to protect his
soldiers from punishment or to preserve the reputation of his
team. Other factors such as emotion, bias, mistake or incapability in
judgement \cite{DK82} can also creep into the decision-making process
and cause chaos in the system.

Whilst the general view of the system architecture and factors to be
considered are outlined in \cite{JPO04}, it does not present any
example of core components --- the models to calculate risk and
damage. These models are inherently complicated to design and
build. The contributing factors are difficult to measure, quantify,
calculate and aggregate, e.g., how secure is an operation system?
Should an access to a secret document be considered a short-term risk,
a long-term risk or both? If both, what is the proportion of each
risk? Even if building such models is possible, the task of fine
tuning these models in a timely manner can be challenging. Other
security prerequisites on the infrastructures required to implement
the system, as discussed in \cite{JPO04}, ranging from network
protocol to technologies on tamper proof hardware, are difficult to be
promised. The security of a system is only as strong as its weakest
component; breaching just one requirement can easily lead to a
security breach of the system.

\subsubsection{Summary}
\label{JASONEconomybasedModel.Summary}
The use of economics concept provides greater flexibility to the
information protection system. However, there are doubts arising from
its implementation and regarding some practical issues of the
system. Indeed, the authors commented that ``[they] fully expect that
much of what [they] suggest can be proved unworkable, or no better
than some different approach'' and ``[this] model may seem too
extreme''. Further research is required to further investigate this
idea. Having said that, the $3$M principles of building an information
protection system: measure risk, mark the acceptable risk and maximise
the information distribution to the acceptable level are inspiring
thoughts.

\subsection{Top-down Hierarchical Models}
\label{TopDownHierarchicalPolicyModel}
The models presented so far have access control policies which are
specified in terms of the low-level corresponding enforcement
mechanisms, e.g., protection bits, capabilities, access control lists,
etc. Each model implements a single specified policy but does not
often capture all the protection requirements of a system.

In \cite{TYCW92}, Woo et al. proposed a logic based language that
allows access control policies be specified independently from the
implementation mechanisms and two composition operators that can be
used to combine multiple access control policies. Additionally, a list
of requirements for a language to be suitable for specifying access
control policy is outlined. The language should be:
\begin{enumerate}
\item declarative and semantically independent from the implementation
  mechanisms.
\item efficiently computable, hence allowing efficient authorisation
  evaluation.
\item able to easily express the intended security properties.
\item able to specify how to handle authorisation when policies are
  non-montonic, inconsistent, incomplete (coverage) or composition.
\end{enumerate}

Although it has been found later in \cite{SJ01} that the language
proposed does not impose sufficient constraints to ensure that the
specified policy is Turing decidable and therefore may not be
implementable, Woo et al.'s work has served as a proxy for using high
level languages to abstract policy from the implementation
mechanism. In \cite{SJ97, SJ97A}, the Authorisation Specification
Language (ASL) which is based on stratified first order logic became
the first complete and computable policy specification language. Other
policy specification languages also exist in the literature, e.g.,
Security Policy Language (SPL) \cite{CNR01}, XACML \cite{SD03},
etc. Refer \cite{MS02} for detail.

In network management research, policies have become increasing
popular as a means of managing distributed systems. Here the term
``policies'' carries a much broader meaning; policies are ``rules
governing the choices in behaviour of a system (in general)''
\cite{MS94}. Therefore policies encompass not only security-related
rules, but also management rules. For example, obligation policies
which have the form of event triggered condition-action rules can be
used to define adaptive management actions, e.g., change in the
quality of service provided, resource allocation, backup policy,
software installation, etc. This minor difference is not important in
the discussion of this thesis.

To cope with the growth in the size and complexity of a large
distributed system, there is a trend towards automating many aspects
of management into distributed components. The concepts of viewing
policy as an object and policy hierarchy are first proposed in
\cite{JDM91} and refined further in \cite{JDM93, JDM93A}. The concept
of viewing policy as an object is about decoupling the policy from the
components that are responsible for enforcing it (the implementation
mechanisms) and viewing the policy as an independent reusable
component \cite{JDM91}. This enables the behaviour of the system to
change by simply changing the rules in the policy.


The concept of policy hierarchy recognises that policies exist at
different levels of abstraction. It suggests that high-level policies
can be derived from business goals and form the basis of multiple
low-level policies \cite{JDM91, JDM93}. The ultimate objective is to
develop a mechanism that allows the specification of a high-level
policy to be analysed and translated automatically to low-level
policies which can then be executed by the system. The number of
policy hierarchy levels may vary among different models, yet the
intuition remains the same --- the high-level policies are refined to
form the low-level policies.

As an example, the policy model proposed in the International
Technology Alliance (ITA) project is shown in Figure
\ref{fig:ITAPolicyModel}. The ITA policy model \cite{KS08} consists of
four layers: specification layer, abstract policy layer, concrete
policy layer and executable policy layer. The policy specification
layer consists of policy authoring and policy analysis tools that
support the specification of high-level security policies in
constrained natural languages. These policies are then refined into
abstract policies. At the abstract policy layer, various formal
methods are used to check the correctness and consistency of the
abstract policies. The concrete policy layer is then responsible for
refining the analysed policies into concrete policies which are then
upheld by different components to meet policy goals. The executable
policy layer transforms the concrete policies into executable policies
and distributes them to the implementation devices that are
responsible for enforcing the policies. This bottom layer is also
responsible for reporting the status and device discovery information
back up to the concrete policy layer.

\begin{figure}[htbp]
 \centering
 \includegraphics[width=0.8\textwidth]{ITAPolicyModel}
 \caption{The ITA policy model \cite{KS08}.}
 \label{fig:ITAPolicyModel}
\end{figure}
% In the following sections, we will discuss some of the issues in the
% processes in refining high-level policies into lower-level policies
% and analysing policies. 

\subsubsection{Policy Refinement and Policy Conflict Analysis}
\label{PolicyRefinementAndPolicyConflictAnalysis}
Policy refinement is the process of transforming high-level security
goals into low-level policies that can be enforced by a system
\cite{JDM91}.  The refinement process involves the analysis of policy
conflict, policy coverage and the determination of resources required
to implement the policies \cite{JDM91}.


One widely accepted policy refinement approach is the goal refinement
approach proposed in \cite{RD97}. Goal refinement approach consists of
the process of identifying, recognising and instantiating refinement
patterns. Once a refinement pattern has been identified and analysed
for completeness and conflict, any policy that matches this pattern is
certain to be complete and correct. Whilst it is desirable to have a
fully automated refinement process, Moffett et al. argued that it is
often infeasible to do this in many situations other than the most
trivial scenarios \cite{JDM93A}.

Policy conflict analysis is the process of verifying whether the
security policy is \emph{consistent} and \emph{complete}
\cite{MS94}. By consistent we mean that there is no conflict between
the rules in the policies and with the capabilities of the underlying
system. By complete we mean the policy implements all the high-level
goals specified.

There are two categories of conflicts: modality conflicts and semantic
conflicts. Modality conflicts arise when the rules in the security
policies are inconsistent with one another. Modality conflicts can be
divided into the following three categories based on the types of
rules that are in conflict \cite{EL99}:
\begin{description}
\item [Authorisation conflicts] --- conflicts that arise because both
  positive and negative authorisation rules exist for the same action,
  subject and object tuple. In other words, a subject is authorised
  (by the positive authorisation rule) as well as forbidden (by the
  negative authorisation rule) to perform the same action on an
  object.
\item [Obligation conflicts] --- conflicts that arise because there is
  an obligation rule and a refrain (negative obligation) rule defined
  for an action that a subject is obligated to perform as well as
  refrained from performing on an object.
\item [Unauthorised obligation conflicts] --- conflicts that arise
  when there are an obligation rule and a negative authorisation rule
  defined for an action that a subject is obligated but forbidden to
  perform on an object.
\end{description}
Having a positive authorisation rule and a refrain rule defined for
the same action for a subject and an object is not considered as a
conflict.

Poor policy specification is not the only cause of policy
conflict. Organization goals may be ambiguous and conflicting in
nature, e.g., maximising resource utilisation vs. maximising resource
availability. This will inevitably result in conflicts among policies
that are derived from it.
 
To detect these conflicts, syntactic analysis can be applied to the
policies to determine the overlap of subjects, targets and actions
\cite{EL99}. However, the existence of overlap only reveals the
\emph{potential} modality conflict because other constraints, such as
time, might limit the applicability of the rules. Moreover, syntactic
analysis is unable to detect application specific conflicts, e.g., the
separation of duty principle (refer Section
\ref{ClarkWilsonModel}). To detect these conflicts, the conditions
that may cause the conflicts are required to be specified as
additional constraints on the policies. The occurrence of the
conflicts may also depend on the state of the system. Analysing all
these states to check for possible conflicts is often infeasible and
therefore run-time analysis is still necessary.

Once these conflicts are detected, it is necessary to resolve
them. Jajodia et al. suggested a few ways to handle the conflicts in
\cite{SJ97}. The simplest way is to do nothing but flag an error
condition. A better solution is to allow the positive authorisation
policy to override the negative authorisation policy or vice
versa. Often, the priority is given to the negative authorisation
policy based on the assumption that preventing actions would incur
less risk. Obviously this is not always true. For example, a positive
authorisation policy can be an exception to a more general negative
authorisation policy.

To alleviate this issue, priorities can be assigned to different
policies explicitly \cite{EL99}. When conflicts arise among policies,
the highest priority policy is enforced. However, the task of priority
assignment in itself is difficult. There is also a problem of breaking a
tie if there are two or more policies with the same level of
priority. This problem is exacerbated when there are multiple parties
involved in defining and assigning policies. Inconsistency can easily
arise as each party can have different preference. An alternative
approach is to define priority based on specificity of the policy
\cite{AH90}. To the other extreme, meta policies are also being
proposed as a way to define the precedence relationship among policies
\cite{EL99}. Whilst these resolution mechanisms provide more
flexibility, they also make the task of ensuring policy consistency
more complicated. There is still no known general mechanism that is
able to detect and resolve conflicts among policies when arbitrary
conditions are allowed.

As modern systems become more distributed, the distribution of the
analysis procedures across the system can be problematic. The system
can be organized in an unstructured order; each subsystem can be owned
by different domains. This makes the policy refinement process much
more complicated. In MANETs, subsystems can join, leave and rejoin at
any time. This dynamic behaviour can easily cause conflicts among the
policies.

\subsubsection{Summary}
\label{TopDownHierarchicalPolicyModel.Summary}
This section presents a top-down hierarchical policy model in which
policies are specified using high-level languages and then refined
into low-level policies. Various issues related to the policy
refinement process are discussed, including how conflicts among the
policies can arise, be detected and be resolved.

\section{Conclusion}
\label{SecurityPolicy.Conclusion}
This chapter first reviews the traditionally influential security
policies and models in the literature. Then it presents some recently
proposed risk based models which aim to provide more
flexibility. Lastly, it presents the top-down policy hierarchical
model which enables policy composition and refinement, with an
emphasis on the problems encountered in the refinement and conflict
analysis processes.


% ------------------------------------------------------------------------


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../thesis"
%%% End: 
