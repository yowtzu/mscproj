\chapter{Security Policy and Access Control} 
\graphicspath{{Chapter1/figures/}}
\label{SecurityPolicyAndAccessControl}

Security policy is defined in \cite{RS07} as
\begin{quote}
  a set of policy rules (or principles) that direct how a system (or
  an organization) provides security services to protect sensitive and
  critical system resources.
\end{quote}
Security policy must therefore specify \emph{all} necessary control
measures for ensuring the system security, including how
authentication should be done, what to response to a security
violation, etc.. However most security policies concentrate only on
specifying the access control of a system. Access control protects
resources of a system (objects) against unauthorised access by
restricting the use of system resources only to the authorised users
(subjects) according to the security policy of the system
\cite{RS07}. The access can be in many forms; the common ones include
reading, writing, appending and executing. The way in which a subject
can use objects in the system is often known as the ``privillege'' the
subject has. The set of high-level rules that specifies which access
is authorised and which is not is known as access control policy
\cite{PS01}. The study of access control policy has resulted various
useful access control models. Most models are formal and makes formal
analysis on the security objectives concerned possible. There are also
some informal models consist of only some informal, high-level
principles.

This chapter first reviews the traditionally influential security
policies and models in the literature. Then it presents two recently
proposed risk-based models which aim to provide more flexibility and
the top down policy hierarchical model which enables policy
composition and refinement. This chapter concludes with the research
issues in the securiy policy development we attempts to answer.

\section{Mandatory Access Control}
\label{MAC}
Multilevel security (MLS) system was first developed in the defence
community as a means to manage information with different
sensitivities. Each information is given a classification label that
represents its sensitivity; each user of the information system is
assigned a clearance level and on the same scale as the
classification. The clearance a user has depends on many factors based
upon background invistigation, e.g. rank, previous position,
etc.. Essentially, these factors are used to establish the
trustworthiness of the user and the information the user needs to know
and therefore determine what clearance a user should be granted
\cite{JPO04}.  Mandatory Access Control (MAC) policies enforce the
access control to the objects by comparing the classification labels
of the information (objects) with the clearance of the users
(subjects) \cite{DOD85}. This is typified by the Bell-LaPadula Model
\cite{DEB73}.

\subsection{Bell-LaPadula Model}
\label{BellLaPadulaModel}
Bell-LaPadula model is concerned with confidentiality of the objects
in an information system. This model views each entity in the system
is either a subject or object. Each entity is associated with a
security label of the form $<\mathrm{classification\ level,\ set\ of\
  categories}>$. The set of classification levels contains names that
form a $<$ relation base upon the sensitivity or clearance. An example
of classification levels can be $\{\mathrm{top\ secret,\ secret,\
  confidential,\ unclassified}\}$, where $\mathrm{unclassified <
  confidential < secret < top\ secret}$. The set of categories
contains names that form compartments which provides a means to the
creator of the object to control and restrict the ditribution of the
object. An example of categories can be ${\mathrm{investment\
    banking,\ equity,\ technology}}$ in a financial institute.

With such setting, a dominance ($\preceq$) relation can be defined on
security labels such that
\begin{equation}
  \mathrm{
    \forall a, b \in SecurityLabel: a \preceq b \Leftrightarrow
    classification(a) \leq classification(b) \wedge
    category(a) \subseteq category(b)
  }
\end{equation}
This relation form a partial order set (poset) on the security labels
and therefore can be visualised as a lattice using Hasse
Diagram. Using the example of classification levels and categories,
the lattice formed is depicted in Figure \ref{fig:HasseDiagram}.

\begin{figure}
\centering

\caption{The lattice formed}
\label{fig:HasseDiagram}
\end{figure}

Two properties are defined using this dominance relationship to ensure
the system remain secure with respects to confidentiality of the
objects in the systems:
\begin{enumerate}
\item The simple security property (no read up) --- no subject can
  read any object with higher security level than its own security
  level. Formally, this can be rewritten in a non-negated form as
  $\mathrm{\forall a \in Subject, b \in Object: a\ can\ read\
    b \Leftrightarrow a \succeq b}$.
\item The *-property (no write down) --- no subject can write to an
  object with lower security level thant its own,
  i.e. $\mathrm{\forall a \in Subject, b \in Object: a\ can\ write\ b
    \Leftrightarrow a \preceq b}$.
\end{enumerate}
In other words, Bell-LaPadula model restricts the information to flow
low confidentiality to high confidentially, but not vice versa. Later,
a tranquility property is added to explicitly state that security
labels of the entities in the system do not change during system
operation to rebute some criticisms received in \cite{JM85, JM90}.

Whilst MAC is often associated with Bell-LaPadula model, they are not
the same. MAC really mean that the security policy that govern the
system is enforced by the system itself, as implied by the term
``mandatory''. The subjects can no longer manipulate access control
attributes of the objects they own at their own discretion.

\subsection{Biba Model}
\label{BibaModel}
A closely related model is the Biba model \cite{KJB77}, which is
concerned with the integrity of object in the system. Essentially,
Biba is the inverse model of the Bell-LaPadula Model, i.e. the
information is restricted to flow from high-integrity to
low-integrity. The two properties defined to ensure integrity of the
system are:
\begin{enumerate}
\item The simple security property (no write up) --- $\mathrm{\forall a
  \in Subject, b \in Object: a\ can\ write\ b\ \Leftrightarrow a
  \preceq b}$.
\item The *-property --- $\forall a \subset subject, b \subset object:
  if a can read b, then a can have write access to some other object b
  only if fO(a) \preceq fO(b)$. Along with the first property, these
  two rules imply the no read down property, i.e.  $\mathrm{\forall a
    \in Subject, b \in Object: a\ can\ read\ b \Leftrightarrow a
    \succeq b}$. Often, this implication is viewed as the property
  because of its simplicity and the symetricity with the *-property in
  the Bell-LaPadula model.
\end{enumerate}

Biba model also introduced two new concepts: dynamic security level
and invocation operation. Dynamic security level relaxes the
constraint of static security classification that is assumed in
Bell-LaPadula model. This relaxes the two properties such that an
access that violates the two properties are permitted with the
condition that the security label of the subject and object that are
involved in the contact are reclassified to the lower level of the two
after the access. The new invocation operation enables subjects to
invoke other subjects (probably software processes) to access
objects. To remain consistent, the invocation property is defined such
that subjects are allowed to invoke only subjects at the lower
security levels\footnote{Ring property is an alternative property
  defined such that there is no restriction is set for read access,
  i.e. any subject can read any object regardless of their integrity
  levels, but write access is only allowed such that $level(object)
  \preceq level(subject)$ and subject $s_1$ can invoke subject $s_2$
  $\Leftrightarrow level(s1) \preceq level(s2)$. However this property
  is inconsistent with the other properties defined here. One must
  choose which is more appropriate to use depending on the
  application}.

\subsection{Chinese Wall model}
\label{ChineseWallModel}
The security models introduced so far are inspired from millitary
application. Chinese Wall model \cite{DFCB89} is a commercially
inspired model which is concerns with condidentialty. Chinese Wall
model is used to ensure information flow in the system does not cause
any conflict of interest. A classic scenario is the services offered
to different clients, some of which can be competitors of the others
by a financial institute. Conflict of interest can arise when an
analyst in the institute is involved in two companies in the same
market because the insider knowledge that the analyst gains on one
company may result unfair treatment to the other and vice versa.

Chinese Wall model groups all object related to a company in a company
dataset, and datasets with conflict of interest are grouped into the
same conflict class. The intuition is that until company datasets are
``sanitised'' into a dataset containing no critical information, no
one should be authorised to access more than one ``unsanitised''
dataset from the same conflict class.

As the conflict does not only depends on the current object to be
access but all other previously accessed objects, the access history
of each subject is required to be kept. This can be achieved by
keeping a two dimentional matrix of boolean values that records
whether a subject has ever accessed an object can be used.

Then, Chinese Wall policy defines two properties to ensure valid
access control: 
\begin{enumerate}
\item simple security property states that a subject is authorised to
  access an object only if the object is within a dataset current
  held, or an entirely different conflict class. However, simple
  security property does not prevent indirect information leakage. A
  subject can read information from one dataset and write to another
  dataset for other subjects to read. Therefore, *-property is
  defined, along with this property can prevent this violation.
\item *-property states that a subject is authorised to write an
  object only if the subject does not have read access to any other
  company datasets which are not sanitised. Dataset is said to be
  sanitised if the sensitive details within it has been
  removed. Therefore ``sanitised'' dataset is not subject to any
  access restriction. *-property ensures the unsanitised information
  flow is restricted within its own company dataset whereas sanitized
  information flow is not restricted throughout the system.
\end{enumerate}

In contrast to Bell-LaPadula model which assumes the access rights are
static, Chinese Wall policy views access rights are changed
dynamically and therefore must be reexamined during all state
transitions. The identification of the importance on access history in
Chinese Wall policy model also proliferates the research into
history-based access control and dynamic separation of duty.

\subsection{Clark-Wilson Model}
\label{ClarkWilsonModel}
Clark-Wilson model \cite{DDC87} is a commercially inspired model which
is concerned with integrity. The core of model is based upon the two
well established principles in commericial worlds: well-formed
transactions and separation of duty.

A well-formed transaction is a series of operations that will ensure
the system trasit from one valid state to another valid state. This is
to preserve the internal consistensy of the data in the system. The
principle of separation of duty requires that the entity that
certifies a transaction and the the entity that execute the
transaction to be different. Provided these entities do not conspire,
this principle should preserve the external consistency of the system,
i.e. the data in the system reflects the data it represents in the
real world.

In Clark-Wilson model, objects can be either constrained data items
(CDI) or unconstrained data items (UDI). Nice rules: five
certification rules and four enforcement rules are defined to
constrain how to validate integrity of CDI, how and who can change CDI
and how to change UDI to CDI.

\section{Discretionary Access Control}
\label{DAC}
Most MAC security models presented are very formal. This enables these
models to be verifiable for security purpose; but also makes these
models too restrictive and therefore not practical for many
purposes. Unlike MAC, Discretionary Access Control (DAC) policies
restrict access to objects based on the identity of the subjects
and/or the groups to which the subjects belong. The resource owners
can delegate the access privilleges to other subjects at their own
discretion; hence the name.

DAC policies can be represented using the access matrix model
introduced by Lampson \cite{BWL71}. An access matrix is a two
dimentional matrix, in which the rows correspond to subjects and
columns correspond to objects. An element in the matrix specifies the
privillege a subject has on a object. An example of access matrix is
depicted in Figure \ref{}.

Whilst access matrix provides a convenient way of expressing DAC
policies, an access matrix is likely too large and very sparse to be
stored efficiently in practice. Consequently, the access matrix is
usually stored either by columns or rows, resulting access control
lists (ACLs) and capability lists respectively.

Access control lists (ACLs) is list of ACL entries. Each entry stores
a column of the access matrix, along with the object which the column
corresponds to. Each entry specifies which subject is allowed to
access an object in what ways. This object-oriented decoupling makes
ACLs suites well in the operating environment with the protection is
central at the objects, e.g. operating systems. Conversely, if the
number of subjects in the operating environment is large and
constantly changing, ACLs becomes less suitable. The way ACLs stores
the information is not efficient in finding the all objects that a
particular subject has permission to access, a check on the ACLs of
all objects in the system is required.

Alternatively, access matrix can be stored by rows. This is known as
capabilities. The strength and weakness of capabilities are more or
less the opposite of ACLs. The decoupling is subject-orented; it is
easy to check what privillege a subject has but it is tedious to check
the privilleges granted for a particular object.

\section{Role-based Access Control}
\label{RBAC}
DAC however posts a challenge on system privillege adminstration
especially when the information system becomes large. An interesting
observation is found that the protected objects in the system often is
not owned by the users, but the organisation the users work for. The
decision of the access request is often determined by the
responsibilities of the roles the users hold \cite{DFF92}. This gives
rise to a new type of access control model --- Role-based access
control (RBAC) in which the access privilleges in the system are
defined in terms of the role of a subject has, rather the the subject
itself \cite{DFF92}.

The basic components in RBAC are: users, permissions, roles and
sessions. Two relations are defined: user assignment (UA) that
associates users with roles and permission asisgnment (PA) which
associates roles with permissions. Both relationship are many to many
mapping. Permissions are granted to users through roles. At anytime, a
user can choose to activate a subset of roles that he has been
assigned; the permissions available to the user are those associated
with those active roles in that session.

There are many extensions made to RBAC. Our discussion will focus on
the The American National Institute of Science and Technology (NIST)
RBAC reference model \cite{RS00} which later has been revised and
became the American National Standards Institute (ANSI) standard
(ANSI/INCITS 359-2004) \cite{ANSI04}.

The ANSI RBAC reference model consists of four components: Core RBAC,
Hierarchical RBAC, Static Separation of Duty Relations and Dynamic
Separation of Duty Relations. The Core RBAC defines the fundamental
elements in a RBAC system. This includes all the functional
capabilities of RBAC presented so far, i.e. user assignment and
permission assignment relations, session as well as support for
user-role review (the ability to determining which role is given to a
user and vice versa).

Hierarchical RBAC introduces the concept of role hierarchies. Role
hierarchy allows roles to inherit the permissions of other roles,
e.g. a senior role inherit all the permissions of a junior role. This
often improves admisntrative efficiency through the reduction in the
number of permission mapping. However, the permission inheritance
based upon seniority hierarchy in the real world is not always
suitable. In \cite{JDM98}, Moffett presented some examples how this
can be in conflict with some control principles such as separation of
duties, decentralisation, and supervision and review. Whilst various
ad-hoc methods such as the use of private roles \cite{RSS96} or
exceptions \cite{DJ96} can be introduced used to over this problem,
this defeats the original intend of making the adminstrative
efficient.

Static Separation of Duty Relations introduces the concept of
constraint on the user assignments. As the concept of constraint may
conflict with the concept of role hierarchy, this component introduces
the concept of constraint on the user assignment in both the presence
and absence of role hierarchies. Dynamic Separation of Duty Relations
introduces the concept of constraint on the role activation in a
session for users.

An common alternative standard reviewed in the literature is the
original NIST standard which defines four conceptual models: Flat
RBAC, Hierarchical RBAC, Constrained RBAC and Symmetric RBAC. Flat
RBAC is essentially same as the Core RBAC component; Hierarchical RBAC
is Flat RBAC with role hierarchy support, Constrained RBAC is
Hierarchical RBAC with constrain on the user assignments and role
activation in a session for users, Symmetric RBAC is Constrained RBAC
with support permission-role review, which is left as optional feature
in the ANSI standard specification. This is because not all RBAC
implement this feature because it can be intrisically difficulty to
implement in large distributed systems \cite{RS00}.

There are many other extensions proposed for RBAC. The extension on
the group or team concept is a common one. In the same way that role
is used to group privilleges, users can be grouped based upon the
group or team they belong to. Then, each team is associated with
roles. Team-based Access Control \cite{RT97}, and Coalition-based
Access Control \cite{EC02} are examples of this.

In \cite{EB00}, Temporal RBAC (TRBAC) is proposed to introduce the
concept of temporal constraint to RBAC. TRBAC allows the use of
temporal constraints to specify the periodic role activation and also
the dependancies between the role activation via role trigger
mechanisms.

The main benefit RBAC has is that it eases the adminstration task
\cite{DFF92, MN93}. The introduction of roles between users and
permissions. Once the role-permission mapping is established, it is
likely to remain constant. The adminstrative task of assigning role to
user is remarkable easier and less error prone than assigning
permissions to the user directly.

\section{Flexible  Access Control Models}
\label{FlexibleAccessControlModels}
Whilst DAC and RBAC provide more flexibility through the ability of
permission delegation and role abstraction, the permission assigned to
each user remains static. In practice, different entities may have
different protection requirements; these requirements can change over
time. This requires manual administration on the privilleges
assignments, which can easily become unmanagable, especially when the
operational environment is highly dynamic.

Here we review two access control models that aim to provide more
flexibility, namely FuzzyMLS model \cite{PCC07, PCC07A} and JASON
Economy-based model \cite{JPO04}. The intuition of these models are
based upon the observation that access control is governed by the risk
incurred and benefit of the organisation can gain from the access; the
access is authorised only if the benefit outweight or commensurate
with the risk. In the models presented so far, the risk-benefit
tradeoff assessment is implicitly encoded statically in the access
control. These two models advocate the use of an explicit risk model
to estimate these risk dynamically to make more informed decision.

\subsection{Fuzzy MLS Model}
\label{FuzzyMLSModel}
Fuzzy MLS is an adaptive extension on the read access aspect to the
traditional Bell-LaPadula model. In Bell-LaPadula model, a subject can
read an object only if security label of the subject dominates the
security label of the object, i.e. the sensitivitiy level of subject
($sl$) $\geq$ the sensitivity level of object ($ol$) and the category
set of subject ($sc$) $\supseteq$ the category set of object
($oc$). In other words, the subject is trustworthy enough and has the
legitimate ``need-to-know'' to access the object. Essentially, the
traditional Bell-LaPadula can be viewed as a non-adaptive, binary
access control decision model where accesses have been pre-classified
as having either acceptable or unacceptable risk and only accesses
with acceptable risk are allowed \cite{PCC07}.

The Fuzzy MLS continues to employ the risk based rationale, but
extends the model to be based on risk management rather than risk
avoidance inherent in the binary decision process \cite{JPO04}. Fuzzy
MLS takes a more flexible and sophisticated view and considers the
``gap'' between a subject's sensitivity label and an object's
sensitivity label. The Fuzzy MLS model is shown in figure
\ref{fig:riskscale}.

\begin{figure}[htb]
 \centering
% \includegraphics[width=0.8\textwidth]{RiskScale}
 \caption{Risk adaptive access control on a risk scale \cite{PCC07}}
 \label{fig:riskscale}
\end{figure}

The model is a risk scale divided into three regions; top, middle and
bottom. Each access corresponds to a point on the scale. An access
corresponding to a point in the top region is denied due to a high
level of risk, whereas an access corresponding to a point in the
bottom region is allowed. The middle region is further divided into
bands of risk such that each band is associated with a risk mitigation
measure; access located in this region is allowed only if the risk
mitigation measure associated with it can be applied to bring the risk
to the bottom region. The change of the binary discrete decision model
to the continuous model which uses a risk scale highlights
similarities with fuzzy control systems, thus giving rise to the name
``Fuzzy MLS'' \cite{PCC07}.

Cheng et al. also briefly discussed two alternative risk management
systems: the credit card system and economy-based system in
\cite{PCC07}. In the credit card system, each subject is given a risk
credit. When a user makes an exceptional access, the difference
between the risk and the soft boundary will be charged againsts the
risk credit of the user. Periodically, the returns on investments
(ROIs) will be evaluated on the risk credit charged and results
delivered by the users. Based upon the ROIs, the future distribution
of risk credit across the users is determined. Activities can also be
logged to allow periodic refinement of access control policy. The
provides a way to govern the long term behaviours of the users, yet
still maintain the flexibility provided by the risk credit. In the
economy-based system, the notion of pseudo currency is introduced in
place of risk credit. Each user is given an amount of the pseudo
currency which can be used to purchase risk units. Each information
access costs some risk units; more risky access costs more. As in the
credit card system, the future distribution of the amount of pseudo
currency depends on the ROIs of the users. An example of this the
JASON Economy-based model presented in Section
\ref{JASONEconomybasedModel}.

\subsubsection{Risk Computation}
\label{RiskComputation}
In \cite{PCC07}, the author defines the risk of a human user's read
access to information as:
\begin{equation}
\text{risk} = \text{value of information} \times \text{probability of unauthorised disclosure} 
\label{eq:risk}
\end{equation}
The value of information is normally quantified in terms of the damage
that would result from the disclosure of information to unauthorised
parties. Estimates of information values can be derived from the
traditional sensitivity label as these sensitivity labels correspond
to the magnitude of loss. Therefore, the paper focuses on deriving the
probability of unauthorised disclosure. While precise probability
calculation is impossible, the Fuzzy MLS has developed a way to assign
such probability that is commensurate with intuition from the
traditional MLS model.

The Bell-LaPadula MLS model can be viewed as estimating of the
probability of unauthorised disclosure, $P$, which is the sum of $P_1$
and $P_2$, where $P_1$ and $P_2$ are:
\begin{align*}
& P_1=
\begin{cases}
	0 & \text{if subject clearance level $\geq$ object sensitivity label} \\
	1 & \text{otherwise}
\end{cases} \\
& P_2=
\begin{cases}
	0 & \text{if subject category set $\supseteq$ object category set} \\
	1 & \text{otherwise}
\end{cases} \\
\end{align*}
\begin{equation}
\label{eq:P}
P = P_1 + P_2 - P_1P_2
\end{equation}
The Fuzzy MLS models also estimates these probabilities using the
formula \ref{eq:P}, but these probabilities are no longer binary, but
takes the value in the range $[0.0,1.0]$.

\paragraph{Probabilities computation}
\label{sec:probablilitycomputation}
As no one knows about the future, determining the accurate
probabilities $P$, $P_1$ and $P_2$ are impossible. However,
qualitative comparison can made between the likelihood of misuse in
the access operations on the information. With these qualitative
comparisons, risk indices can be formulated to represent the relative
comparison between the likelihood of misuse of different accesses
\cite{PCC07}. The higher the risk index, the higher the likelihood of
misuse. Thereafter, these risk indices can be used to map onto
probabilities based upon experience, intuition and threat assessment.

The risk indices step might seem redundant. However, the authors give
two important reasons based upon their experiences
\cite{PCC07A}. First, risk indices remove the constraints imposed by
the probability theory, e.g. the sum of probabilities of all possible
outcome must be 1. Moving away from the probability theory also allows
a finer-grained view to be taken on risk, e.g. the range of $[0,1]$ is
removed. Second, this indirect mapping makes the fine tuning task
easier in the future. Once the risk indices are determined, they can
be kept fixed. The mapping function can be fine tuned over time.

$P_1$ is defined as the probability that a subject fails to resist the
temptation of unauthorised information disclosure. In the traditional
MLS, a binary view on the temptation is taken: temptation happens if
subject sensitivity level ($sl$) $<$ object sensitivity level and
information disclosure always happens ($P_1 = 1$) if temptation
exists. In other words, no subject is able to overcome
temptation. This is the reason why the traditional MLS only allows
access when $sl \geq ol$.

In line with the thought of using index to derive probability, a
temptation index, $TI$ which represents the temptation level resulted
from an access is introduced in the process of deriving $P_1$. While
there are many different ways to relate $TI$ ti $sl$ and $ol$, the
formula must satisfy the following properties \cite{PCC07A}:

\begin{itemize}
\item As the sensitivity of the object increases, the temptation
  increases.
\item As the trustworthiness (clearance) of the subject increases, the
  temptation decreases.
\item There is always temptation faced by every subject, thus there is
  no $100\%$ trustworthy subject.
\item $TI$ is biased toward more sensitive objects.
\end{itemize}

A simple formula that satisfies the above requirements is given as an
example in the paper as follows:
\begin{equation}
{ TI(sl,ol) = \dfrac{\alpha^{-(sl-ol)}}{m-ol}}
\label{eq:TI}
\end{equation}
where $\alpha, m \in \mathbb{R}, \alpha > 1.0, m > max\{ol | ol \in
OL\}$, where $OL$ is the set of all possible $ol$. The $\alpha^{ol}$
represents the estimate loss (value) of the object and $\alpha^{sl}$
represents the trustworthiness of a human subjects. $TI$ approaches
infinity (temptation becomes very large and difficult to resist) as
$ol$ approaches $m$.

To relate $P_1$ to $TI$, a sigmoid function is chosen as follows:
\begin{equation}
 P_1 = \dfrac{1}{1 + exp((-k) \times (TI-mid))} 
\label{eq:P1}
\end{equation}
where $mid$ is the value of $TI$ when $P_1$ is $0.5$ and $k$ is the
slope of $P_1$ curve with regard to $TI$. Note that this sigmoid
function has no special reason but is plainly due to its similarity
with the step function in traditional MLS. Further research is
required to refine this mapping function.

While $P_1$ corresponds to the probability of information disclosure
due to a subject failing to resist temptation, $P_2$ corresponds to
the difference between the probability of unintentional disclosure and
the probability of disclosure which the organisation is willing to
accept as a subject access to an object. In the case that an object
being accessed belongs to multiple categories, a simplified assumption
is made such that object is a monolithic entity, in which the
difference for all the categories are computed and the maximum
difference is used as $P_2$

In traditional MLS, a subject with the highest security clearance is
not given access to all objects, instead access is only given to the
objects that the subject needs to accomplish tasks. The objects are
compartmentalised into different categories such that the only
subjects with legitimate needs are granted access to these categories
\cite{JPO04}. The ``need-to-know'' principle reduces the likelihood of
unintentional disclosure (Users cannot disclose information which they
do not know, and so keeping accessible information to the minimal
operationally justified reduces risk).

Instead of using binary value, Fuzzy MLS assigns a fuzzy membership
value to each subject to represent the needs of a subject for the
information object in each category. These fuzzy memberships can then
be used in place of subject and object sensitivity labels in equation
\ref{eq:TI} to compute willingness index, $WI$. This $WI$ can be then
used in place of $TI$ in equation \ref{eq:P1} to compute the
willingness of acceptance for an organisation when a subject accesses
an object, $W_c$. Finally, let $P_{id_c}$ be the probability of
unintentional disclosure for category c. $P_2$ can be computed as
follows:
\begin{equation}
\label{eq:P2}
 P_2 = max\{P_{id_c}(1-{W_c}) \mid c \text{ is a category}\}
\end{equation}

%\begin{equation}
% w_{c}(sm,om) = \dfrac{b^{-(om-sm)}}{m_{max}-sm}
%\end{equation}
%\begin{equation}
% P_{w_c} = \dfrac{1}{1 + exp((-k) \times (TI-mid))}
%\end{equation}

For computing risk for a particular access, the formula \ref{eq:risk},
which consists of the product of the value of information (object) and
the probability of unauthorised disclosure can be used. While the
value of the object can be estimated using its sensitivity label in
the current MLS system, the probability of unauthorised disclosure can
be computed using formula \ref{eq:P}, in which the $P_1$ and $P_2$ can
be computed using formula \ref{eq:P1} and formula \ref{eq:P2}
respectively.

\subsubsection{Review}
\label{FuzzyMLSModel.Review}
In this section, we will review the advantages and disadvantages of
the Fuzzy MLS in proposed. These include \cite{PCC07}:
\begin{enumerate}
 \item Risk quantification
 \item Greater flexibility
 \item Label uncertainty made possible
 \item Limited risk factors considered
 \item Risk aggregation problem
 \item Non engineering development of the index formula
\end{enumerate}

In Fuzzy MLS, risk is estimated and quantified with the application of
fuzzy set theory on traditional MLS system. Essentially, this changes
the access control model from risk avoidance to risk management and
allows trading off the risk and benefit constantly.

The Fuzzy MLS provides better flexibility compared to traditional MLS
system through the introduction of risk scale model. This model allows
the system to adapt to environmental changes in several ways
\cite{PCC07A}. Firstly, the boundaries between regions can be
dynamically adjusted to control the system's global risk
tolerance. Secondly, accesses previously denied under the traditional
model may now be allowed provided mitigation measures can be
taken. Thirdly, each point on the scale associated with an access can
be updated periodically to reflect the change of environment.

In a MLS system, there is an implicit assumption made on the
correctness of the subject and object labels. This makes information
sharing difficult because the labels are often set with a tendency
toward higher secrecy to minimise the operational risk. In order to
address this issue, the label can be made uncertain to include
uncertain factors \cite{PCC07}. While the traditional MLS system
cannot extend in this way, this is not a problem in the Fuzzy MLS
system.

So far, the Fuzzy MLS only uses one of the risk factor - the
trustworthiness of the subject represented in security labels to
estimate the risks. However, there are many other factors that can
affect the risk as outlined in the \cite{JPO04} such as the access
method (softcopy vs hardcopy), the operational environment and the
risk mitigation measures employed. The best way to take all these
factors into account remains a research topic.

While Fuzzy MLS seems to have significant achievement in improving the
traditional MLS, the risk aggregation problem remains unsolved. The
sensitivity of a piece of information provided to a subject does not
solely depend on itself, but also other information that the subject
can access \cite{PCC07}. Consequently, multiple accesses to less
sensitive data can be used to construct information that is more
sensitive than the individual items.

The temptation index $TI$ formula and willingness index $WI$ which are
used to calculate the probability of disclosure are done in a non
engineering, but rather ad hoc way. This makes the soundness and
robustness of the formula questionable. In \cite{PCC07}, the authors
claimed that the basis of the formula is based on the experience with
MLS. However, it seems that calculation of probabilities have been
tweaked to concur with their intuitive hypotheses. For examples, the
current MLS systems have only the three or four levels of security
labels, the index function is a step function, rather than an
exponential function. Indeed, the author states explicitly that ``MLS
also uses a step function to relate temptation to probability of
disclosure $P_1$'' \cite{PCC07}. In $P_2$ computation, the authors
also state that the formulation is only experimental and further
research is needed.

\subsubsection{Summary}
\label{FuzzyMLSModel.Summary}
Zadeh, the father of fuzzy set theory, suggested the process of
fuzzification should be regarded as a methodology to generalise any
discrete theory from discrete to continuous form \cite{GJK96}. Here,
fuzzy theory is used to generalise the binary access model used in the
traditional MLS, resulting in a multi-decision, risk-based multi
decision access control. The risk-benefit tradeoff can be constantly
controlled by managing the risk. Essentially, this model transforms
the access control problem to resource allocation. The risk is treated
as a finite resource. The paper specifies a model in which these
resources can be managed, but it still remains a question on how these
resources are to be distributed and allocated to the users. In the
next section, a possible solution using the economy-based model
proposed in \cite{JPO04} is presented.

\subsection{JASON Economy-based Model}
\label{JASONEconomybasedModel}
A risk based access control based upon the economic concept is
proposed by JASON in \cite{JPO04}. In the original paper, the idea was
proposed in three incremental phases. The first phase is the
preparatory phase, where the necessary components for the systems to
work are discussed. The following two phases introduce two models
based on economic concepts: the command economy system (also referred
as the push economy system) and the market economy system (also
referred as the pull economy system). The papers advocate a market
economy system but there appears to be interesting features and
tradeoffs made in both systems.

The organisation of this section is as follows: Section
\ref{sec:ebsdefinitionofriskharmanddamage} presents the definition of
risk, harm and damage. Section \ref{sec:ebsprinciples} describes the
guiding principles that are used to build systems. Section
\ref{sec:ebsriskmodel} describes the risk model which plays an
essential role in assigning risk value to the each
transaction. Sections \ref{sec:ebscommandeconomysystem} and
\ref{sec:ebsmarketeconomysystem} describe the push economy system and
the pull economy system respectively. Section \ref{sec:ebsreview}
describes the limitation and challenges of the systems proposed.

\subsubsection{Definition of risk, harm and damage}
\label{sec:ebsdefinitionofriskharmanddamage}
The risk definition used in JASON report differs from the one adopted in the Fuzzy MLS model in Section \ref{sec:FuzzyMLS}. In order to ease comparison, we will first clarify the difference. In Fuzzy MLS Model, risk is defined as follow:
\begin{equation}
\label{def:ebsrisk}
 \text{risk} = \text{value losses per accident} \times \text{probability of an accident} 
\end{equation}
In JASON report \cite{JPO04}, risk is defined as the unnormalised probability of a transaction that will make a loss. In addition, the report introduces two new terms: damage and harm. Damage is defined as the cost of a lost secret whereas harm is defined as the expected value of the cost of a transaction. These terms are related as follow:
\begin{equation}
\label{def:ebsharm}
 \text{harm} = \text{damage} \times \text{risk} 
\end{equation}
A careful examination on both equations allows us to establish a mapping between the terms: the harm in JASON report corresponds to the risk in Fuzzy MLS Model, the damage in the JASON report corresponds to the value losses per accident in Fuzzy MLS Model and the risk in JASON report corresponds to the probability of an accident in Fuzzy MLS Model. In the rest of this section, we will use the terms in the way they concur to the original report to allow easy referencing.

\subsubsection{Guiding principles for the system}
\label{sec:ebsprinciples}
The authors suggest that the new information protection system should be risk based and outline three principles that should be followed in building any new system. The three principles are as followed:

\begin{enumerate}
\item Measure risk. The risk factor of each transaction should be measured or estimated.
\item Mark an acceptable risk level. Setting the acceptable risk level to zero effectively stops all the transactions because every transaction has an inherent risk associated with it. The acceptable risk level is set to a value that optimises the long term benefits, knowing that today's security leaks may affect the future.
\item Maximise the information flow up to the acceptable level. In contrast to the current systems which try to minimise risk, information should flow to the greatest extent compatible with the acceptable risk level in order to optimise gain.
\end{enumerate}

\subsubsection{Risk model}
\label{sec:ebsriskmodel}
%The objective of phase 0 is to develop a risk model by measuring or estimating the transactional risk and the infrastructure required to support the transactions needed to be built. This transactional risk model will then be used to quantify the risk of different transactions in the following phases. The authors suggest that the risk model should include the following factors:
In order to be able to quantify the risk of transactions in the system, we need a risk model to measure or estimate the risk of each transaction. The following factors should be considered in building the risk model:

\begin{enumerate}
\item Individual factors - the role, security clearance, personal record, etc..
\item Type of transaction - the access method (softcopy vs. hardcopy), access duration, access is auditable, information can be redistribution, etc..
\item Situational factors - the operational environment, security of the technology used to implement, etc..
\item Technical factors - the software security, hardware security, etc..
\end{enumerate}

These factors have to be combined in a mathematical way to yield a formula that can be used to assign risk value to each transaction. The model should also be capable of handling different types of risk in terms of the temporal factor, e.g. the risk incurred by an unauthorised disclosure on amount of budget allocated for a small project is short term whereas the risk incurred by an unauthorised disclosure of a nation's secret weapon information is long term.

%In order to support of measuring and accounting risk on each transaction, new infrastructure must be developed. The most important prerequisites are summarized as follows:
%\begin{enumerate}
%Elaborate more?
%\item The protocol for displaying and transferring protected information  Protocol stacks for moving and displaying protected information. 
%\item The technology to control and restrict the use of information
%\item User authentication technologies
%\item Risk limitation and mitigation techniques in less controlled environments
%\item Another risk model for quantifying the acceptance of technical risk
%\end{enumerate}
%At this stage, the way in which these risk factors can be combined should also be determined. Risks can be categorized as different types based on their impact. For example, short term team formation secret vs long term strategic secret. The model should be able to handle this. Other requirements of the risk models include enumerating failure modes of interest. It should be able to distinguish among the different types of disclosure, whether it is an intentional or accidental one. The risk model should also distinguish between the various kinds of attack. 

\subsubsection{Command economy system}
\label{sec:ebscommandeconomysystem}
The concept of a risk token is introduced in the command economy system. A token has an exchange value and each transaction has a different cost. In a sense, tokens can be thought as currency and transactions can be thought as the service in the real world. In this system, the value of the token is pegged (associated value with) risk as follows \cite{JPO04}:
\begin{eqnarray}
\label{def:ebstoken}
 1 \text{ token} & = & \text{risk associated with one day, softcopy access} \\
& & \text{to a document by an individual who cleared to secret level.} \nonumber
\end{eqnarray}
In this example, the value of a token is associated with estimated risk incurred on the access duration, type of access and the security clearance of an individual. Note that the value of a token is only associated to the risk (probability of loss factor), but does not include the value (damage factor). By using the transactional risk model describe in Section \ref{sec:ebsriskmodel}, we can associate each transaction with a token cost. Riskier transactions are associated with higher cost. For example,

\begin{enumerate}
\item one day softcopy access to a document by an individual who is cleared to top secret level: 0.2 tokens
\item hardcopy access to a document by an individual who cleared to secret level with restriction on further distribution: 50 tokens
\end{enumerate}

The producer of the information is expected to set the total acceptable risk level in terms of tokens. As all the tokens are pegged to risk using the same baseline, different producers need to have different types of tokens to limit the risk exposed by controlling the amount of tokens associated with the information produced. For example, if a document may be viewed in softcopy as many as 500 times by individual cleared to secret level, 500 tokens will be created along with the production of the document. If the document is printed in hardcopy format for 10 times by an individual cleared to secret level with a restriction of no further distribution, the acceptable risk level is reached. The risk budget is considered spent.

Furthermore, a secondary market can be introduced to allow token exchange. This does not require any change on the systems because the risk associated on each transaction is controlled by the amount of tokens on created (other factors been taken care of by incurring higher cost for risky transactions)


%Every transaction is associated with some token cost. Given a budget to an individual, there may be many ways to spend it. However, a fixed budget constrains the total risk that the budget has. The number of tokens and budget serves to limit exposure.

In token distribution, the producer of information will create and distribute tokens to different organisations. Within the organisation, tokens are given to the manager and then to the employees. Annually, the distribution of the risk token will be evaluated based on the annual risks and return on investment function.

Furthermore, the utilisation fraction, which is the fraction of tokens distributed that are used to exchange for access, can be determined to provide a measure on the merit for information producer. If the utilisation fraction is near 100\%, it means the nation is almost reaping the full benefit of the information produced and vice-versa.

\subsubsection{Market economy system}
\label{sec:ebsmarketeconomysystem}
In market economy systems, there are only two types of tokens. The reason for having more than one type is that different kinds of secret require different protection profiles over time \cite{JPO04}. These are referred to as green and gold tokens (represents short term and long term risk respectively). The different types of tokens are collapsed into these two token types and this causes the producer's controls on the risk of information disappear. Consequently, some necessary changes are made on the way token value is defined and token distribution. 

By pegging the token value with the risk involved in a transaction, access to two pieces of information with different security classification levels by a cleared individual would have the same cost although the harm caused by an unauthorised information disclosure can be different (The one with higher security classification level is likely to cause larger harm). In the command economy system, this harm is implicitly controlled by limiting the amount of tokens given for each piece of information. With the collapse of token types, this is made impossible. Instead of associating token value with risk, we associate token with harm (the expected value), which is a composition of damage (the value) and risk (the probability of the loss) as defined in Section \ref{sec:ebsdefinitionofriskharmanddamage}. This also implies there is a need for a damage model to estimate the value of a piece of information in the same way as the risk model.

In token distribution, we need to introduce a new central authority entity which is responsible in creating and distributing tokens. The function of the central authority is similar to a central bank in the real world. Besides creating and distributing tokens, it monitors the health of the token by balancing demand and supply as well as controlling inflation and deflation rates.

\subsubsection{Review}
\label{sec:ebsreview}
The differences between the two models are summarised in the table
\ref{table:ebscomparison}.

%Comparison between phase 1 and phase 2 in a table
\begin{table}[htb]
\centering
\begin{tabular}{|p{3.5cm}|p{4cm}|p{4cm}|}
\hline
			&	Command economy system		&	Market economy system\\
\hline
Value of the token	&	Associated with risk		&	Associated with risk \& damage	\\
\hline
Model required		&	Risk model			&	Risk model and damage model\\
\hline
Type of the token	&	One per producer		&	Two types: short term risk \& long term risk\\
\hline
Creator of the token	&	Producer of the information	&	A central authority (central bank)\\
\hline
Control Method		&	Control by limiting the token amount	&	Control by demand \& supply equilibrium\\
\hline
\end{tabular}
\caption{Comparison between the command economy system and market economy system}
\label{table:ebscomparison}
\end{table}

Despite the paper asserting that the market economy system is better than the command economy system, we argue that this comparison is unfair. For example, token value association is different in the two systems. The command based system has been simplified deliberately to introduce new concepts and to make way for discussion on the more complicated market economy system. Furthermore, this can be compounded by an illusion in the real world that the market economy is better than command economy. In order to have a fair comparison, the damage model has to be added and therefore the token value is associated with damage in the command economy system. The fungibility of the token can be achieved in the second market in analogous to money exchange in the real world.

The only difference left is the remaining control the producer has on the token distribution in the command economy system. The producer can be dishonest by claiming that the sensitivity of a product is higher than its actual level and thus reduce the number of tokens created along with it. As the market demand of the product remains the same, the reduced supply will lead to an increase in the utilisation fraction of the product and consequently increases the merit of the producer. However, increasing utilisation fraction in this way may lead to market dislocation.

In the market economy system, a new central authority which acts as a central bank is introduced to take over the token distribution control. The credibility of the bank becomes the key factor for the smooth and proper operation of the systems. In other words, the authors make an assumption that a risk of central bank being compromised is lower than the risk of market dislocation. This assumption is not necessarily true, especially in a dynamic environment such as MANET. All the nodes are exposed to physical and logical attacks, i.e. there is no central trusted entity.

The advantages and disadvantages of the economy-based systems include:

\begin{enumerate}
 \item Greater flexibility
 \item Encourage good security behaviour
 \item Accountability
 \item Operations stop when no budget is left
 \item Assumption on rationale users
 \item Lack of risk model and damage model
 \item Implementation
\end{enumerate}

The second and third principles (mark an acceptable risk level and maximise the information distribution all the way to that level) \ref{sec:ebsprinciples} of building a system are great concepts. In the current practise, we have been trying to minimise the risk of every transaction in the hope that the total risks of all transactions is below the risk threshold limit of the system. This results in a sub-optimal system \cite{PCC07}. With these principles, we manage global risk, instead of minimising the local risk, in order to optimise the operational efficiency within the risk threshold limit. This "indirection" provides flexibility to the transactions performed. Information is made available to any individual who is willing to pay the cost, instead of a fixed group of people predefined by the access policy. 

By associating different costs with different access methods in order to access the same information, the system encourages the user to choose safer ways to gain this access. For example, soft copy access is used compared to hard copy. Moreover, these important principles can be enforced by giving an individual enough credits to do what is necessary. If the credit is spent elsewhere, this can be easily detected as the individual will then not be able to complete the duty assigned.

The risk model introduced makes trust a continuous variable rather than a binary one. Essentially, this has the effect of removing the fear of making negative decisions in a manager. There is a natural reluctance to take action with far reaching consequences, e.g. the removal of a user's clearance. Instead, the risk models helps to redefine the responsibility of a manager in term of operational and security duties. The operational duty is to ensure that the tokens are distributed wisely among the units while the security duty is to ensure that all information is passed into the risk model precisely. The manager will then be less likely to revoke the clearance of a unit because the incremental information input to risk model appears to be less daunting. On the other hand, the use of a risk model posts a problem in accountability. When something goes wrong, who is responsible for that? The risk model, the manager or the higher level organisation? There is no obvious answer. Without this accountability, accidental mistakes or even intentional ones are left unaccounted for, thus increasing the number of mistakes made by individuals due to a lack of fear.

From the operational perspective, controlling risk based upon token budget allocation can lead to some problems. Firstly, all transactions are disallowed once an individual has spent his entire budget. Consider a commander in a war who wants to call for reinforcement in this emergency circumstance. However, he is not allowed a call because he has spent his entire budget. More generally, consider the following cases:

\begin{enumerate}
 \item An individual who has been bad and intends to continue the same behaviour
 \item An individual who has been bad and intends to do good
 \item An individual who has been good and intends to do bad
 \item An individual who has been good and intends to continue the same behaviour
\end{enumerate}

The systems are good in cases 1 and 3, but not in cases 2 and 4 (the examples given above can be categorised into either cases 2 or 4). As periodic token distribution and token spending are not reversible, an individual who has spent his token budget can no longer do anything. In case 2, for an individual who has been bad in the past and thus who has spent all his tokens, he not only becomes useless, but he has also lost the chance to recover his profile by doing something good. He has to wait until the next distribution to receive tokens again. In addition to this unfortunate scenario, the individual receives a lesser amount of tokens in the next distribution. In case 4, the individual who has been good is prevented from doing more once his credit runs out. However, this is not a major problem in the present system as the exceptional access granting mechanism can be used to alleviate this problem. We conclude that the system is not general enough to be usable in all environments, especially where the availability of transactions are crucial to the system.

In using economic concept as the basis, the systems make an implicit assumption that the entities in the systems are rational. Thus they will make the best decision among the given choices. However, research results in the psychological and social domains suggest that human decision making is sub-optimal and irrational. In the attempt to explain this, Amos Tversky and Daniel Kahneman started the "heuristics and biases" programme with the central idea that judgement under uncertainty often rests on a limited number of simplified heuristics\footnote{heuristics are the simple yet efficient rules which humans use to make decision} rather than an extensive algorithmic processing \cite{AT74}. This programme resulted in the proposals of different psychological mechanisms in decision making.

One of the heuristics is the framing effect, which is used to explain that the phenomena of the formulation of problems can have influence on human decisions \cite{AT81}. For example, a problem represented as a gain ($30\%$ of the people will pass the examination) will be seen as either a risk aversion or as a loss ($70\%$ of the people will fail the examination). This can then lead to a risk-seeking effect in humans.

Furthermore, it is not uncommon that the relationship between people can have effect on the decision making process. An example would be a captain choosing to not report the misuse of authority among his soldiers. This may be to protect his soldiers from punishment or to preserve trust in the team. This can also happen in the system to prevent decrease of token budgets allocation. Other factors such as emotion, bias, mistake or incapability in judgement \cite{DK82} can also creep into the decision making processes and cause chaos in the system. For details on heuristics and biases, refer to \cite{DK82}.

While the architecture of the system is outlined, the report does not present the central component of the system - the risk model and the damage model. Firstly, the calculation and aggregation of the input factors are difficult problems. This is due to the interdependency between these factors. The situation is made worse by certain factors that are inherently difficult to measure. For example, how secure is the operation system? Furthermore, quantifying different types of risk for different information can also be difficult. For example, should an access to a secret document be considered a short term risk, a long term risk or both? If both, what is the proportion of each? 

On the other hand, the models are designed and the tokens are pegged with risk or damage in the same way as an access policy is statically written prior to the operation of the system. It is difficult to create a perfect model at the start. We agree with the authors that fine tuning on the model can be done over time. However, this task can be challenging due to continuous changes in input parameter (changing environments), weight on factors (fine tuning), as well as the composition of the factors. 

We have discussed on the limitation of the systems in terms of the design. Now we ask if the implementation of the system is feasible. First, the assumption made on the availability of risk model in phase 0 by the authors is questionable. The wide range of security prerequisites on the infrastructures needed to implement the system, ranging from network protocol to technologies on tamper proof hardware, are hard to be promised. Knowing that the security of a system is only as strong as its weakest component, breaching one of the requirements can easily lead to a security breach of the system.

\subsubsection{Summary}
\label{JASONEconomybasedModel.Summary}
With the above mentioned problems, in spite of the flexibility of the
systems, there is doubt on the success of the system, especially in
dynamic environments such as MANET. Indeed, the authors also comment
that ``[they] fully expect that much of what [they] suggest can be
proved unworkable, or no better than some different approach'' and
``that model may seem too extreme''. However, the innovative 3M
principles of information protection system: Measure risk, Mark the
acceptable risk and Maximise the information distribution to the
acceptable level are great findings.

\subsection{Top Down Hierarchical Policy Model}
\label{TopDownHierarchicalPolicyModel}
The models presented so far has the access control policy specified
in terms of its low level corresponding enforcement mechanism,
e.g. protection bits, capabilities and access control lists. Each
model specifies and implements a single specified policy; but does not
capture all the protection requirements of the system.

In \cite{TYCW92}, Woo et al. proposed a logic-based languages in which
the access control policies can be specified independently from the
implementation mechanism that enforces the policies and two
composition operators that can be used to combine multiple access
control policies sets. They also outline a list of requirements for
lanage to be suitable for specifying access control policy as follows:
\cite{TYCW92}:
\begin{enumerate}
\item the language should be declarative and semantically independent
  from the implementation mechanism.
\item the language should be sematic should be efficiently computable,
  hence allowing efficent authorisation evaluation.
\item the lanaguge should be able to express the intended security
  properties easily.
\item the language should be able to specify how to handle
  authorisation when policies are nonmontonic, inconsistent,
  incomplete (coverage) or composition.
\end{enumerate}

Although later it is found in \cite{SJ01} that the language they
proposed does not impose sufficient constraint to ensure the specified
policy is Turing decidable and therefore may not be implementable,
their work has served as the proxy for using high level languages to
abstract policy from the implementation mechanism. In \cite{SJ97,
  SJ97A}, the Authorisation Specification languages (ASL) which is
based upon stratified first order logic becomes the first complete and
computable logic-based language. There exists also other policy
languages proposed in the literature, e.g. Security Policy Language
(SPL) \cite{CNR01}, XACML \cite{SD03}, etc.. Refer \cite{MS02} for
detail.

In the network management research, policies have become increasing
popular as a means of managing distributed systems. Here the term
policies carries a much broader meaning; policies are ``rules
governing the choices in behaviour of a system (in general)''
\cite{MS94}. Therefore policies encompass not only security related
rules, but also management related rules. For examples, obligation
policies which have the form of event triggered condition-action rules
can be used to define adaptive management actions, e.g. change in the
Quality of Service provided, resource allocation, backup policy,
software installation, etc.. Having said that, this minor difference
in definition is not important in our discussions in this thesis. More
importantly, there is no reason to see why the results and claims made
in this thesis are not able to be generalised from security policies
to policies a whole.

To cope with the growth in the size and complexity of the large
distributed system, there is a trend towards automating many aspect of
management into distributed components. The concepts of viewing policy
as an object and policy hierarchy are first proposed in \cite{JDM91},
which are then further refined in \cite{JDM93, JDM93A}.

The concept of viewing policy as an object is about decoupling the
policy from the policy manager component that are responsible to
enforce it (implementation mechanism) and views it as a indepedent
reusable components \cite{JDM91}. This enables the behaviour of the
system to change by simplying changing the rules in the policy object.

The concept of policy hierarchy regconises that policies exist at
different levels of abstraction and suggests that the high level
policies can be derived from business goals and used as the basis from
which multiple low level policies are derived from \cite{JDM91,
  JDM93}. The ultimate objective is to develope a mechanism that
allows the specification of high-level policy can be authomatically
analysed and translated to lower level policies which can be executed
by the system.

There are many different models proposed in the literature, the number
of policy hierarchy levels vary from model to model. Yet all models
share the same intuition --- the high-level policies are refined to
form the low-level policies. Here we present the policy model that is
being proposed in the International Technology Alliance (ITA) Project
in Figure \ref{fig:ITAModel}.

\begin{figure}[htb]
 \centering
% \includegraphics[width=0.8\textwidth]{RiskScale}
 \caption{Risk adaptive access control on a risk scale \cite{ITA07}}
 \label{fig:ITAModel}
\end{figure}

ITA Policy model consists of four layers: Specification Layer,
Abstract Policy Layer, Concrete Policy Layer and Executable Policy
Layer \cite{ITA07}.  Policy Specification Layer consists of policy
authoring and policy analysis tools that support the specification of
high-level security policies in a constrained natural languages. These
policies are then refined into abstract policies. At the Abstract
Policy Layer, various formal method are used to check the correctness
and consistency of the abstract policies. The Concrete Policy Layer is
then responsible to refine the analysed policies into concret policies
that must be upheld by the different components of the distributed
system to meet the policy goals. The Executable Policy Layer
transforms the concrete policies into executable policies and
distributes these policies to the implementation devices that
responsible to enforces the policies. This layer also responsible to
report the status and also device discovery information back up to the
Concrete Policy Layer.

As indicated in Figure \ref{fig:ITAModel}, the order of specfication
decreases and flexibility increases from top layer to the bottom
layer.  In the following sections, we will discuss some of the issues
in the processes in refining high level policies into lower level
policies and analysing policies.

\subsubsection{Policy Refinement and Policy Conflict Analysis}
\label{PolicyRefinementAndPolicyConflictAnalysis}
Policy refinement is the process of transforming high-level security
goals into policies that can be enforced by the systems
\cite{JDM91}. These high level policies will goes through a serious
of refinement process to derive a more concrete, lower level
executable security policies. This refinement process also involves of
conflict and coverage analysis on the policies and determination of
the necessary resources to implement the policies \cite{JDM91}.

One widely accepted policy refinement approach is the goal refinement
approach proposed in \cite{RD97}. Goal refinement approach consists of
the process of identifying, recognising and instatitiating refinement
patterns. Once a refinement pattern has been identified and analysed
for completeness and conflict, any policy that matches this pattern
are certain to be complete and correct. Whilst it is desirable to have
a fully automated refinement process, Moffett et al. argued that it is
often feasible besides the most trivial scenario \cite{JDM93A}.

Policy conflict analysis is the process of verifying whether the
security policy is \emph{consistent} and \emph{complete}
\cite{MS04}. By consistent we mean that there is no conflict between
the rules in the policies and with the capabilities of the underlying
system. By complete we mean the policy implements all the high level
goals specified.

Conflict arises when the specified policies are inconsistent. This can
be modality conflict or sematic conflict. Modality conflict arises
when the rules in the security policies are inconsistent with one
another. Modality conflicts can be grouped into three categories based
upon the types of the rules that are in conflict as follows
\cite{EL99}:
\begin{enumerate}
\item Authorisation conflict --- conflict that arises because both
  positive and negative authorisation rules exists for a same action,
  subject and object tuple. In other words, a subject is authorised
  (by the positive authorisation rule) as well as forbidden (by the
  negative authorisation rule) to perform the same action on an
  object.
\item Obligation conflict --- conflict that arises because there are
  obligation policy and refrain (negative obligation) policy
  defined for an action that is obliged as well as refrained to
  perform on an object.
\item Unauthorised obligation conflicts --- conflict arises when there
  are both obligation rule and negative authorisation rule defined for
  an action that a subject is obliged but forbidden to perform on an
  object.
\end{enumerate}
A positive authorisation rule and refrain policy defined for a same
action for a subject and object is not a conflict.

Ill policy specification is not the only source of policy conflict. It
is common that the organisation goals are ambigious and conflicting in
nature, e.g., maximising resource utilisation versus maximising
resource availability. This will inevitably result conflicts among
policies that are derived from it.
 
To detect these conflicts, syntactic anlaysis can be done on the
policies to determine the overlap of the subjects, targets and actions
\cite{EL99}. However, the existence of overlap only reveals the
\emph{potential} modality conflict because other constraints might
limit the applicability of the rules such as time.

However, syntactic analysis does not detect all kinds of
conflict. Some conflicts arise due to the application specific
constraints which the policies are being used, e.g. separation of
duties principle \ref{ClarkWilsonModel}. To detect these conflicts,
the conditions that lead to the conflicts are required to be specfied
as additional constraints on the policies and then analyse policies to
detect if any conflict exists. The occurance of the conflicts may also
depend on the state of the systems such as time, location,
etc.. Analysing all system states for possible can be proned to be
infesiable and therefore run-time analysis is still necessary.

Once these conflicts are detected, there area required to be
resolved. Jajodia et al. suggested few ways to handle the conflicts in
\cite{SJ97}. The simplest way is not to resolve but flat an error
condition. A better solution is to allow positive authorisation policy
to override the negative authorisation policy or vice verca. The
strategy should be adopted depending on circumstance. Often, the
priority is given to the negative authoritsation policy based upon the
assumption that preventing actions would incur lesser amount of
risk. This is not necessary true. A positive authorisation can be an
exception to a more general negative authorisation.

To alleviate this issue, explicit priorities can be assigned to
different policies \cite{EL99}. When conflict arises among policies,
the one with the highest priority is enforced. However, there are few
issues with this approach. The task of priority assignment in itself
is hard. Also, there is a need to break the tie if there are two or
more policies with the same priority are applicable at the same. This
problem is exarberated when there are multiple parties are involved in
defining policies and assigning policies. Inconsistency can easily
arises as each party can have difference preference. An alternative
approach is to define priority based upon specificity of the policy
\cite{AH90}. To the other extreme, meta policies are also being
proposed as a way to define the precedence relationship among policies
\cite{EL99}. Whilst these resolution mechanisms provides more
flexibilitiy, they also render the task of ensuring consistency
between much more complicated. Although some progresses have been made
in policy analysis and refinement, there is still no general mechanism
that is able to detect and resolve conflicts among policies when in
aribtrary conditions are allowed.

As modern systems become more distributed, the distribution of the
analysis procedure across the system can be problematic. The system
can be organized in an unstructured order; each sub-system can be
owned by different domains. This can make the policy refinement
process much more complex. In the case of MANET, sub-system can join,
dimiss and rejoin at anytime. This dynamic behaviour can easily result
conflicts among policies.

\subsubsection{Summary}
\label{TopDownHierarchicalPolicyModel.Summary}
In this section we present a top down hierarchical policy model, in
which the policies can specified high-level languages and then be
refined into low level policies. Various issues related to the
policy refinement process is also discussed, including the ways in
which the conflicts among the policies can be detected and resolved.

\section{Conclusion}
\label{SecurityPolicy.Conclusion}
This chapter presents a brief overview on security policy and access
controls. It first presents some influential security models. Ir
proceeds to present some more recently proposed modern access
controls. Lastly, it presents the policy development process used in
the top down hierarchical policy model and the issues in the processes
of conflict analysis and refinement.

% ------------------------------------------------------------------------


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../thesis"
%%% End: 
