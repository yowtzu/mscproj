\chapter{Security Policy Models}
\graphicspath{{Chapter3/figures/}}
\label{SecurityPolicyModels}
A security policy is
\begin{quote}
  a set of rules~(or principles) that direct how a system~(or an
  organisation) provides security services to protect sensitive and
  critical system resources~\cite{RS07}.
\end{quote}
A security policy must therefore specify \emph{all} necessary control
measures for ensuring system security, including how authentication
should be done and what responses should be made to a security
violation, etc.

Access control specification is typically a major component of a
security policy. Access control protects the resources of a
system~(objects) against unauthorised access by restricting the use of
system resources only to the authorised users~(subjects) according to
the security policy of the system~\cite{RS07}. Access can be in many
modes; the common ones include read, write, append and execute. The
access mode that a subject has on the objects in the system is known
as the~``privilege'' the subject has. The set of high-level rules that
specifies which accesses are to be authorised and which are not is
known as the access control policy~\cite{PS01}. The study of access
control policies has resulted in various useful models. Most of these
models are formal, i.e., formal analysis can be carried out to prove
the models are secure with respect to the security objectives
concerned. There are also some models consisting of informal
high-level principles such as the Clark-Wilson model~\cite{DDC87}.

This chapter first reviews the traditionally influential security
policies and models in the literature. It then presents some recently
proposed risk-budget based models that aim to provide more
flexibility. Next, it introduces the top-down policy hierarchical
model that enables policy composition and refinement, with an emphasis
on the problems encountered in the refinement and conflict analysis
processes. Lastly, it summarises the current state of the art in
security policy development and reiterates the research objectives of
the thesis.

\section{Mandatory access control policy models}
\label{MAC}
The Multi-Level Security~(MLS) system was first developed in the
defence community as a means to manage information with different
sensitivities. In the system, each object such as a file is given a
classification label that represents its sensitivity and each user is
assigned a clearance level which is on the same scale as the
classification. The clearance level a user has depends on the user's
background, e.g., rank and previous positions. Essentially, these
factors are used to establish the trustworthiness of the user and the
information the user needs to know. The clearance level of the user is
then subsequently determined and granted. Mandatory Access
Control~(MAC) policies enforce access control to objects by comparing
the classification labels of the information~(objects) with the
clearance levels of the users~(subjects)~\cite{DOD85}. This is
typified by the Bell-LaPadula Model~\cite{DEB73}.

\subsection{Bell-LaPadula model}
\label{BellLaPadulaModel}
The Bell-LaPadula model is concerned with the confidentiality of
objects in an information system. In this model, each entity in the
system is either a subject or an object. Each entity is associated
with a security label of the form~$\langle$classification level,
category set$\rangle$. The set of classification levels consists of
names that form a greater than~($>$) relation based on the sensitivity
or the clearance. An example of classification levels can be~$\{$top
secret, secret, confidential, unclassified$\}$, where top secret~$>$
secret~$>$ confidential~$>$ unclassified. The set of categories
contains names that form compartments which provide a means to the
creators of the objects to control and restrict the distribution of
the objects. An example of categories can be~$\{$investment banking,
equity, technology$\}$ in a financial institute.

With such setting, a dominance,~$\succeq$ relation can be defined on
security labels as follows:
\newtheorem*{theorem}{Dominance,
  $\succeq$}
\begin{theorem}
  Let~$\langle s_{a},c_{a} \rangle$ and~$\langle s_{b},c_{b} \rangle$
  be the security labels of~$a$ and~$b$, $\operatorname{label}(a)
  \succeq \operatorname{label}(b) \Leftrightarrow (s_a \geq s_b)
  \wedge (c_a \supseteq c_b)$.
\end{theorem}
This relation forms a partial order set~(poset) on the security
labels. Two properties are defined to ensure the system remains secure
with respect to the confidentiality of the objects:
\begin{enumerate}
\item The simple security property~(no read up) --- no subject can
  read any object with a higher security label than its own security
  label. This can be rewritten in a non-negated form as~$\forall s \in
  \textit{Subject}, o \in \textit{Object}: s \text{ can read } o
  \Leftrightarrow \operatorname{label}(s) \succeq
  \operatorname{label}(o)$.
\item The *-property~(no write down) --- no subject can write to any
  object with a lower security label than its own. Formally, this can
  be written as~$\forall s \in \textit{Subject}, o \in
  \textit{Object}: s \text{ can write } o \Leftrightarrow
  \operatorname{label}(s) \preceq \operatorname{label}(o)$.
\end{enumerate}
In other words, the Bell-LaPadula model restricts information to flow
from low confidentiality to high confidentiality, but not vice
versa. Later, a tranquillity property is added to explicitly state
that security labels of the entities in the system cannot change
during system operation to rebut some criticisms received
in~\cite{JM85,JM90}.~(If security labels can change arbitrarily under
system operation, then clearly security can be compromised. Consider a
system in which the security labels of all subjects are changed to the
maximum possible levels allowing all files to be read by everyone.)

Whilst MAC is often associated with the Bell-LaPadula model, they are
not the same. MAC really means that the security policy which governs
the system is enforced by the system itself, as implied by the
term~``mandatory''. The subjects cannot manipulate access control
attributes of the objects they own at their own discretion. The
Bell-LaPadula model is just an instance of MAC.

\subsection{Biba model}
\label{BibaModel}
A model that is closely related to the Bell-LaPadula model is the Biba
model~\cite{KJB77}, which is concerned with the integrity of the
objects in a system. It is essentially the inverse model of the
Bell-LaPadula model, i.e., the information is restricted to flow from
high integrity to low integrity, but not vice versa. Two properties
are defined to ensure integrity of the system:
\begin{enumerate}
\item The simple security property~(no write up) ---~$\forall s \in
  \textit{Subject}, o \in \textit{Object}: s \text{ can write } o
  \Leftrightarrow \operatorname{label}(s) \succeq
  \operatorname{label}(o)$.
\item The *-property~(no read down) ---~$\forall s \in
  \textit{Subject}, o \in \textit{Object}: s \text{ can read } o
  \Leftrightarrow \operatorname{label}(s) \preceq
  \operatorname{label}(o)$. %Often, this implication is taken as the
                            %property because of its simplicity and
                            %symetricity with the *-property in the
                            %Bell-LaPadula model.
\end{enumerate}

% An access that violates the two properties is permitted with the
% condition that the security label of the subject and object which
% are involved in the contact are reclassified to the lower label of
% the two after the access.
The Biba model also introduced two new concepts: dynamic security
label and invocation operation. The dynamic security label relaxes the
constraint of static security classification in the Bell-LaPadula
model. An access to a low integrity object by a subject operating at
high integrity causes the operation of the subject to be dynamically
downgraded to low integrity. The new invocation operation enables
subjects to invoke other subjects~(probably software processes) to
access objects. To remain consistent, the invocation property is
defined such that subjects are only allowed to invoke other subjects
with lower or equal security labels\footnote{The ring property is an
  alternative property defined such that there is no restriction set
  for all read accesses, i.e., any subject can read any object
  regardless of their security labels, but a subject~$s_1$ can write
  an object~$o_1 \Leftrightarrow \operatorname{label}(s_1) \succeq
  \operatorname{label}(o_1)$ and a subject~$s_1$ can invoke a
  subject~$s_2 \Leftrightarrow \operatorname{label}(s_1) \preceq
  \operatorname{label}(s_2)$. However this property is inconsistent
  with the other properties defined here. One must choose which is
  more appropriate to use depending on the application.}.

\subsection{Chinese wall model}
\label{ChineseWallModel}
The security models introduced so far are inspired from military
applications. The Chinese wall model~\cite{DFCB89} is a commercially
inspired model which is concerned with confidentiality by ensuring
that information flow in the system does not have any conflict of
interest. A classic scenario example is the services offered by a
financial institution to different clients, some of which are
competitors to the others. A conflict of interest can arise when an
analyst in the institution is involved with two companies in the same
market because the insider knowledge that the analyst gains in one
company may result in an unfair treatment of the other and vice versa.

The Chinese wall model groups all objects related to a company in a
company dataset. Datasets with conflicts of interest are grouped under
the same conflict class. If necessary, company datasets can
be~``sanitised'' into a dataset containing no critical information. No
one should be authorised to access more than one~``unsanitised''
dataset from the same conflict class. As the conflict depends not only
on the current object to be accessed but also all other previously
accessed objects, the access history of each subject must be kept.
%This can be achieved by keeping a 2-D Boolean matrix that
% records whether a subject has ever accessed an object.

Two properties are defined to ensure valid access control:
\begin{enumerate}
\item The simple security property --- a subject can access an object
  only if the object is within a currently held dataset, or an
  entirely different conflict class. However, this property in itself
  does not prevent indirect information leakage. A subject can read
  information from one dataset and write in another dataset for other
  subjects to read. Therefore the *-property is defined to prevent
  this kind of violation.
\item The *-property --- a subject can write an object only if the
  subject does not have read access to any other company datasets
  which are not~``sanitised''. This property ensures that the
  unsanitised information flow is restricted within its own company
  dataset whereas the sanitised information flow is not restricted
  throughout the system.
\end{enumerate}

In contrast to the Bell-LaPadula model which assumes that access
rights are static, the Chinese wall model assumes that access rights
are dynamic and therefore have to be reexamined during all state
transitions. The identification of the importance of access history
also proliferates the research into history based access control.

\subsection{Clark-Wilson model}
\label{ClarkWilsonModel}
The Clark-Wilson model~\cite{DDC87} is a commercially inspired model
which is concerned with integrity. Unlike other models, the emphasis
of this model is not on what a subject can access, but how the access
is done.  The core of the model is based on the two well established
principles in the commercial world: well-formed transactions and
separation of duty.

A well-formed transaction is a series of operations which changes the
data in the system from one valid state to another. This is to
preserve the internal consistency of data in the system.  The
separation of duty principle requires that the entity that certifies a
transaction and the entity that executes the transaction to be
different. Provided that these entities do not conspire, this
principle should preserve the external consistency of the system,
i.e., the data in the system reflects the data it represents in the
real world.

The objects in the Clark-Wilson model are divided into either
constrained data items~(CDI) or unconstrained data items~(UDI). Five
certification rules and four enforcement rules are defined to
constrain how to validate integrity of CDI, how and who can change CDI
and how to change UDI to CDI.

\section{Discretionary access control policy models}
\label{DAC}
Unlike MAC, Discretionary Access Control~(DAC) policies restrict
access to objects based on the identity of the subjects and/or the
groups to which the subjects belong. The resource owners can delegate
the access privileges to other subjects at their own discretion; hence
the name.

DAC policies can be represented using an access control
matrix~\cite{BWL71}. An access control matrix is a two dimensional
matrix, in which the rows correspond to subjects and the columns
correspond to objects. An element in the matrix specifies the
privileges a subject has on an object. Let~$r$,~$w$ and~$x$ represent
read, write and execute access respectively. Then, an example access
control matrix is depicted in Figure~\ref{fig:AccessControlMatrix}.
\begin{figure}[htbp]
 \centering
 \begin{tabular}{ | l | l | l | l |} \hline
             & File 1 & File 2 & Device \\ \hline
   Alice     & $rwx$    & $rwx$    & $rwx$    \\ \hline
   Bob       & $r$      & $r$      & $rwx$    \\ \hline
   Charles   & $rw$     & $rw$     & $-$      \\ \hline
  \end{tabular}
 \caption{An access control matrix example.}
 \label{fig:AccessControlMatrix}
\end{figure}

Whilst the access matrix provides a convenient way of expressing DAC
policies, it is likely to be too large and also too sparse to be
stored efficiently in practice. Consequently, it is usually stored
either by columns or rows, resulting in access control lists~(ACLs)
and capability lists respectively.

ACLs store the access matrix by columns. Each entry in an ACL stores
the access privileges an subject has on the objects in the system.
This object-centred decoupling makes ACLs suitable for operating
environments where the protection is central to the objects, e.g.,
operating systems. Conversely, if the number of subjects in an
operating environment is large and constantly changing, ACLs become
less suitable. The way ACLs store information is inefficient when one
needs to find all the objects that a particular subject has permission
to access, since a check on the ACLs of all objects in the system is
required.

Capability lists store the access matrix by rows. The strengths and
weaknesses of capability lists are more or less the opposite of
ACLs. The decoupling is subject-centred; it is easy to check what
privileges a subject has but it is tedious to check the privileges
granted on a particular object.

\section{Role based access control policy models}
\label{RBAC}
DAC policy models, however, pose several challenges to the privilege
administrations, especially when the information system becomes
large. An interesting observation is that the objects in the system
are often not owned by the users themselves, but the organisations
they work for. The access control decisions to the objects are often
determined by the responsibilities of the roles the users
hold~\cite{DFF92}. This gives rise to the role based access
control~(RBAC) in which the access privileges in the system are
defined in terms of the role a subject has, rather than the identity
of the subject itself~\cite{DFF92}.

The basic components of RBAC are: users, permissions, roles and
sessions. Two relations are defined: user assignment~(UA) that
associates users with roles, and permission assignment~(PA) that
associates roles with permissions. Both relationships are many-to-many
mappings. Permissions are granted to users through roles. At any time,
a user can choose to activate a subset of roles that he has been
assigned; the permissions then available to the user are those
associated with the roles activated in that session.

There have been many extensions made to RBAC. The focus of discussion
here is on the American National Institute of Science and
Technology~(NIST) RBAC reference model~\cite{RS00} which has later
been revised to become the American National Standards
Institute~(ANSI) standard~(ANSI/INCITS 359-2004)~\cite{ANSI04}.

The ANSI RBAC reference model consists of four components: Core RBAC,
Hierarchical RBAC, Static Separation of Duty Relations and Dynamic
Separation of Duty Relations. The Core RBAC defines the fundamental
elements in a RBAC system. These include all the functional
capabilities of RBAC presented so far, i.e., user assignment and
permission assignment relations, session as well as support for
user-role review~(the ability to determine which role is given to a
user and vice versa).

Hierarchical RBAC introduces the concept of role hierarchies, which
allows roles to inherit the permissions of other roles, e.g., a senior
role inherits all the permissions of a junior role. This often
improves administrative efficiency through the reduction in the number
of permission mappings. However, the permission inheritance based on
the seniority hierarchy in the real world is not always
suitable. In~\cite{JDM98}, Moffett presented some examples of how this
can be in conflict with some control principles such as the separation
of duty principle, decentralisation, supervision and review. Whilst
various ad-hoc methods such as the use of private roles~\cite{RSS96}
or exceptions~\cite{DJ96} can be introduced to overcome this problem,
these methods defeat the original intent of improving the
administrative efficiency.

Static Separation of Duty Relations introduce the concept of
constraints on user assignments. As this concept may conflict with the
concept of role hierarchies, it is specified in both the presence and
absence of the concept of role hierarchies. Dynamic Separation of Duty
Relations introduce the concept of constraints on the role activation
in a session for users.

A common alternative reviewed in the literature is the original NIST
standard which defines four conceptual models: Flat RBAC, Hierarchical
RBAC, Constrained RBAC and Symmetric RBAC. Flat RBAC is essentially
the same as the Core RBAC component; Hierarchical RBAC is Flat RBAC
with role hierarchy support; Constrained RBAC is Hierarchical RBAC
with constraints on the user assignments and role activation in a
session for users; Symmetric RBAC is Constrained RBAC with support for
permission-role review. In the ANSI standard specification, the
support for permission-role review is left as an optional feature
because it is intrinsically difficult to implement in large
distributed systems~\cite{RS00}.

The main advantage of RBAC is that it eases the administration
task~\cite{DFF92,MN93}. Once the role-permission mapping is
established, it is likely to remain constant. The administrative task
of assigning roles to users is very much easier and less prone to
error as compared to assigning permissions to the users directly.

There have been many other extensions proposed for RBAC. The extension
to the group or team concept is a common one. In the same way that
roles are used to group privileges, users can be grouped based upon
the group or team they belong to. Each team then is associated with
roles. Team based access control~\cite{RT97} and coalition based
access control~\cite{EC02} are examples of this. Temporal RBAC~(TRBAC)
is proposed in~\cite{EB00} to introduce the concept of temporal
constraints to RBAC. It allows the use of temporal constraints to
specify the periodic role activation and also the dependencies between
the role activation via role trigger mechanisms.

%X Why would i want these? manage macro global risk, local risk provide flexibiltiy at low level
\section{Flexible  access control policy models}
\label{FlexibleAccessControlModels}
Whilst DAC and RBAC policy models provide better flexibility through
permission delegation and role abstraction, the permission assignments
to the users remain static. In practice, the permission assignments
and the protection requirements of the objects may change over
time. The task of administering the access control policy can easily
become unmanageable, especially when the operational environment is
highly dynamic.

Here we review some access control models that aim to provide more
flexibility, namely the Fuzzy MLS model introduced
in~\cite{PCC07,PCC07A} and the economics based models introduced
in~\cite{JPO04}. The intuition of these models is based upon the
observation that access control is governed by the risk incurred and
the benefit an organisation can gain from the access. An access is
authorised only if the benefit outweighs the risk incurred. The
risk-benefit tradeoff assessment of the models presented so far is
implicitly and statically encoded in the models. These two models
advocate the use of an explicit model to dynamically estimate the risk
to make better informed decisions.

\subsection{Fuzzy MLS model}
\label{FuzzyMLSModel}
The Fuzzy MLS model is an adaptive extension of the read access aspect
of the Bell-LaPadula model. In the latter model, a subject can read an
object if and only if the security label of the subject dominates the
security label of the object, i.e., the sensitivity level of the
subject~($sl$) is greater than the sensitivity level of the
object~($ol$) and the category set of the subject~($sc$) is a superset
of the category set of the object~($oc$). This can be interpreted
informally as a subject can read an object if and only if the subject
is trustworthy enough and has the legitimate~``need-to-know'' to
access the object. The policy encoded in this model essentially
divides each access as either having an acceptable amount of risk or
an unacceptable amount of risk; only the accesses with acceptable
amount of risk are authorised~\cite{PCC07}.

The Fuzzy MLS model continues to employ this risk based rationale, but
it changes the access control from a risk avoidance system~(inherent
in the binary decision-making process) to a risk management system by
computing the~``quantified risk'' estimated by the~``gap'' between the
security labels of the subject and object.

The model consists of a risk scale that is divided into three parts:
top, middle and bottom, as shown in
Figure~\ref{fig:FuzzyMLSModel}. Each access is mapped to a point on
the scale. An access that is mapped to a point in the top region is
denied because the risk is too high; an access that is mapped to a
point in the bottom region is authorised. The middle region is further
divided into multiple risk bands such that each band is associated
with a risk mitigation measure; an access that is mapped to this
region is authorised only if the associated risk mitigation measure
can be applied to reduce the risk level to the bottom region. The
change of the binary decision model to this continuous model, which
uses a risk scale is very similar to the intuition in fuzzy logic, thus
the name~``Fuzzy MLS''~\cite{PCC07}. (However, the model is not based
on fuzzy logic concept at all. In fact, this is the only similarity
between the model and the fuzzy logic.)

\begin{figure}[htbp]
 \centering
 \includegraphics[width=0.8\textwidth]{RiskScale}
 \caption{The Fuzzy MLS model~\cite{PCC07}.}
 \label{fig:FuzzyMLSModel}
\end{figure}

Two alternative risk management systems, the credit card system and
economics based system, are also discussed in~\cite{PCC07}. In the
credit card system, each subject is given a risk credit. When a
subject makes an exceptional access, the difference between the risk
and the soft boundary will be charged to the risk credit of the
user. Periodically, the return on investment~(ROI) of each user is
evaluated to determine the future risk credit of the user, based on
the risk credit charged and the result delivered by the
user. Activities can also be logged to periodically refine the access
control policy. This provides a way of governing the long-term
behaviours of users, yet still maintaining sufficient flexibility as
provided by the use of risk credit. In the economics based system, the
notion of pseudo-currency is introduced in place of risk credit. Each
user is given an amount of pseudo-currency which can be used to
purchase information accesses. Riskier accesses cost more. Similar to
the credit card system, the amount of pseudo-currency allocated to a
user in the future depends on the ROI of the user. This is very
similar to the economics based models that will be reviewed in
Section~\ref{JASONEconomicsBasedModel}.

\subsubsection{Risk computation}
\label{RiskComputation}
The Fuzzy MLS model defines risk of a read access as the expected
value of damage caused by unauthorised disclosure of information:
\begin{equation}
  \text{risk}=(\text{value of damage, } V) \times (\text{probability of incurring the damage, } P) 
\label{eq:risk}
\end{equation}
The value of~$V$ can be estimated from~$ol$. As~$ol$ typically
corresponds to the order of damage,~$V$ is defined as an exponential
function of~$ol$:
\begin{equation}
  V=a^{ol}, a > 1
\end{equation}
The value of~$P$ can be estimated by quantifying two~``gaps'': one
between the sensitivity levels of the subject and the object, and the
other between the category sets of the subject and the object. In the
Bell-LaPadula model,~$P$ can be viewed as:
\begin{equation}
P=P_1 + P_2 - P_1P_2
\label{eq:P}
\end{equation}
where $P_1$ and $P_2$ are:
\begin{align*}
  & P_1=
  \begin{cases}
    0 & \text{if $sl \geq ol$} \\
    1 & \text{otherwise}
  \end{cases} \\
  & P_2=
  \begin{cases}
    0 & \text{if $sc \supseteq oc$} \\
    1 & \text{otherwise}
  \end{cases}
\end{align*}
The Fuzzy MLS model continues to use~\eqref{eq:P} to estimate these
probabilities, but allows these probabilities to take real values
in~$[0,1]$ instead of only being expressed as binary values.

To determine the probabilities~$P$,~$P_1$ and~$P_2$ precisely is
impossible as no one knows the future for certain. However, risk
indices can be formulated by having an assessment on the likelihood of
misuse in different access operations. The higher the likelihood of
misuse, the higher the risk index. Thereafter, these risk indices can
be mapped onto probabilities based on previous experiences and
intuitions. The use of risk indices is doubly useful. Firstly, it
removes the constraints imposed by the probability theory, e.g., the
sum of probabilities of all possible outcomes must be equal to
one. This provides a more fine-grained view on risk. Secondly, it
makes the fine tuning task easier in the future. Risk indices, once
determined, can be kept fixed; only the mapping function is required
to be tuned over time.

$P_1$ is defined as the probability of a subject failing to resist the
temptation of unauthorised information disclosure. The Bell-LaPadula
model can be viewed as taking a binary view on temptation: temptation
happens if the sensitivity level of subject~($sl$) is less than the
sensitivity level of the object~($ol$) and information disclosure
always happens~($P_1=1$) if temptation exists.

To formulate~$P_1$ for Fuzzy MLS Model, the temptation index~$TI$ is
first derived. In the understanding that there are many different ways
to relate~$TI$ to~$sl$ and~$ol$, the relation must satisfy the
following properties~\cite{PCC07A}:
\begin{itemize}
\item As the sensitivity level of an object increases, the temptation
  increases.
\item As the sensitivity level of a subject increases, the
  temptation decreases.
\item Every subject faces temptation, i.e., there is no~$100\%$
  trustworthy subject.
\item $TI$ is biased towards more sensitive objects.
\end{itemize}

A simple formula~\cite{PCC07} that satisfies these properties is:
\begin{equation}
  TI(sl,ol)=\dfrac{a^{-(sl - ol)}}{m - ol}
\label{eq:TI}
\end{equation}
where~$a$,~$m \in \mathbb{R}$, $a > 1.0$,~$m > \max\{ol \mid ol \in
OL\}$, where~$OL$ is the set consisting of each possible~$ol$ in the
system. Here~$a^{ol}$ represents the estimated value of an object
and~$a^{sl}$ represents the trustworthiness of a subject. $TI$
approaches infinity~(temptation becomes very large and difficult to
resist) as~$ol$ approaches~$m$.

To relate~$P_1$ to~$TI$, a sigmoid function:
\begin{equation}
  P_1=\dfrac{1}{1 + \exp((-k) \times (TI-n))} 
 \label{eq:P1}
\end{equation}
is derived. Here~$n$ is the value of~$TI$ that makes~$P_1=0.5$;~$k$
controls the slope of the~$P_1$ curve with regard to~$TI$. This
function is chosen because of its similarity with the step function in
the Bell-LaPadula model.

$P_2$ corresponds to the difference between the probability of
unintentional disclosure and the probability of disclosure which the
organisation is willing to accept for an access of a subject to an
object. In the case that an object being accessed belongs to multiple
categories, a simplified assumption is made such that the object is a
monolithic entity, in which the differences among all the categories
are computed and the maximum difference is used as~$P_2$. Instead of a
binary value, a fuzzy membership value is assigned to each subject to
represent the~``need-to-know'' level of a subject for the object in
each category.

The willingness index,~$WI$ can be computed using~\eqref{eq:TI} with
the fuzzy memberships in place of the sensitivity levels. Then the
willingness of acceptance for an organisation when a subject accesses
an object,~$W_c$ can be computed using~\eqref{eq:P1} with~$WI$ in
place of~$TI$. Let~$P_{id_c}$ be the probability of unintentional
disclosure for category~$c$. Then,~$P_2$ is defined as follows:
\begin{equation}
\label{eq:P2}
P_2 = \max\{P_{id_c}(1 - W_c) \mid c \text{ is a category}\}
\end{equation}

Finally, the risk of a read access is computed using~\eqref{eq:risk}.

\subsubsection{Review}
\label{FuzzyMLSModel.Review}
The Fuzzy MLS model draws inspiration from fuzzy set theory to
estimate and quantify risk in the traditional Bell-LaPadula
model. This model continues to employ the risk based rationale, but it
changes the access control model from a risk avoidance system to a
risk management system by estimating the risk of each access with a
risk scale.

This risk scale allows the model to adapt to environmental changes in
several ways. Firstly, the boundaries between regions can be
dynamically adjusted to control the system's global risk
tolerance. Secondly, accesses that would have been denied under the
traditional model may now be allowed if the associated mitigation
measures can be provided. Thirdly, the risk function that maps each
access to a point on the risk scale can be updated periodically to
reflect the changes in the operational environment.

In practice, the security labels of the objects in a system are often
set with a tendency towards higher secrecy to minimise the operational
risk. Consequently, information sharing becomes more difficult. This
over-classification problem can be addressed by making the label take
uncertainty into account~\cite{PCC07}. This is not possible in the
traditional Bell-LaPadula model.

The Fuzzy MLS model however has some shortcomings; it only uses the
security labels to estimate risk. As outlined in~\cite{JPO04}, there
are many other factors that can affect the risk of an access, e.g.,
the access method~(softcopy vs.\ hardcopy), the operational
environment and the risk mitigation measures employed. The best
way to identify, quantify and aggregate these factors remains an open
research topic. Risk aggregation can be tricky as the sensitivity of a
piece of information provided to a subject does not solely depend on
itself, but also on other information that the subject can
access~\cite{PCC07}. Additionally, accesses to multiple pieces of low
sensitivity information may allow a subject to infer information that
is far more sensitive.

%\subsubsection{Summary}
%\label{FuzzyMLSModel.Summary}
%The Fuzzy MLS model uses fuzzy set theory concept to generalise the
%traditional Bell-LaPadula model in estimating and quantifying the risk
%of each access with a risk scale. This changes the access control
%model from a risk avoidance system to a more flexible risk management
%system.

\subsection{Economics based models}
\label{JASONEconomicsBasedModel}
The idea of managing risk in access control using economic concepts is
proposed in~\cite{JPO04}. Each user in an organisation is allocated a
number of risk tokens, which can be spent for operational needs. The
number of risk tokens a user will get in the future depends on the
return of investment of the user. Essentially, risk is viewed as a
type of limited resource in an organisation and the access control
problem is transformed into a resource allocation problem. Two
economics based models are introduced: one based on the command
economic system and the other based on the market economic system.

% The proposal is done in three incremental phases. The first phase is
% the preparatory phase, where the necessary components in making the
% system work are discussed. The following two phases introduce two
% models: the command economy system~(also known as the push economy
% system) and the market economy system~(also known as the pull economy
% system).

\subsubsection{Definition of risk, damage and harm}
\label{sec:ebsdefinitionofriskharmanddamage}
New definitions for risk and two new terms,~``damage'' and~``harm''
are introduced in~\cite{JPO04}. Risk is defined as the unnormalised
probability of an access which can cause the loss of a secret, damage
is defined as the cost of the loss, and harm is defined as the
expected cost of the loss. These terms are related as follows:
\begin{equation}
  \text{harm} = \text{damage} \times \text{risk} 
\label{eq:ebsharm}
\end{equation}
The definition of risk is different from the one in the Fuzzy MLS
model~\eqref{eq:risk}, which is restated as follows for ease of
reference:
\begin{equation*}
  \text{risk} = (\text{value of damage, }V) \times (\text{probability of incurring the damage, }P) 
\end{equation*}

A careful examination of both equations allows us to establish a
mapping between the terms: the term~``harm'' here corresponds to the
term~``risk'' in the Fuzzy MLS model; the term~``damage'' holds the
same meaning in both cases; and the term~``risk'' here corresponds to
the term~``probability of incurring a damage'' in the Fuzzy MLS
model. In this thesis, the terms are used in the sense of the original
report for ease of reference.

\subsubsection{Three guiding principles}
\label{sec:ebsprinciples}
The author suggests that the new information protection systems should
be risk based and outlines three principles that should be followed in
building them. These principles are as follows:
\begin{enumerate}
\item Measure risk --- The amount of risk associated with each
  access should be measured or at least estimated.
\item Mark an acceptable risk level --- Risk avoidance~(setting the
  acceptable risk level to zero) effectively stops all the information
  accesses because every access has an inherent amount of risk
  associated with it. The acceptable risk level should be set to a
  value that optimises the long-term benefit.
\item Maximise the information flow up to the acceptable level --- In
  contrast to current systems which attempt to minimise the total
  risk, information in the system should flow to the greatest extent
  compatible with the acceptable risk level in order to optimise gain.
\end{enumerate}

\subsubsection{Risk model}
\label{sec:ebsriskmodel}
A risk model is required to estimate the risk of each access. The
following factors should be considered in building this model:
\begin{description}
\item [Individual factors] --- User roles, security clearances,
  previous positions, etc.
\item [Situational factors] --- Operational environment,
  access time, etc.
\item [Technical factors] --- Hardware/software security measures,
  etc.
\item [Types of accesses] --- Access method~(softcopy vs.\ hardcopy),
  access duration, whether access is auditable, whether information
  can be redistributed, etc.
\item [Temporal effects of consequences] --- Leaking the information
  on the budget allocated for a small project may result in a
  short-term risk but leaking the information on a national secret
  weapon may result in a long-term risk.
\end{description}
These factors have to be combined in a mathematical way to yield a
formula that can be used to assign a risk value to each information
access.

\subsubsection{Model based on command economic system}
\label{sec:ebscommandeconomysystem}
In this model, the value of a token is pegged to
risk~\cite{JPO04}. For example,
\begin{quote}
  $1$ token is pegged to the risk associated with softcopy access for
  a day to a document by an individual who is cleared to the secret
  level.
\label{def:ebstoken}
\end{quote}
The value of the token is associated with the estimated risk incurred
in the access, including the type and duration of the access and the
security clearance of the individual. Yet, it does not consider the
value of the document~(the damage factor).

Using the risk model presented in Section~\ref{sec:ebsriskmodel}, each
access can be associated with a certain number of risk tokens. Higher
risk accesses cost more. For example,
\begin{itemize}
\item Softcopy access for a day to a document by an individual who is
  cleared to top secret level costs~$0.2$ token.
\item Hardcopy access to a document with a restriction on further
  distribution by an individual who is cleared to secret level
  costs~$50$ tokens.
\end{itemize}
When a piece of information is being produced, the producer will
create the number of tokens that is commensurate with the acceptable
risk level of the piece of information. For example, the production of
a document that may be viewed in softcopy for~$500$ times by an
individual who is cleared to secret level is always accompanied by the
creation of~$500$ tokens. If the~$500$ tokens are spent by an
individual who is cleared to secret level to print the document in
hardcopy format for $10$ times with a restriction of no further
distribution, the acceptable risk level of the document would still be
considered reached.

Additionally, the use of different types of tokens is necessary for
different types of information. This is because all tokens are pegged
using the same baseline. More sensitive information has less tolerable
risk level and therefore has fewer tokens created with it.

To increase the liquidity of the market, a secondary market can be
introduced to allow token exchange. This does not require any change
of the model because the tolerable risk of the information has been
controlled by the number of tokens created with it and other risk
factors have been taken care of in the cost associated to each
information access.

To distribute the risk tokens, the information producers create and
distribute the risk tokens to different organisations based on their
needs. Within an organisation, risk tokens are pushed down through the
management hierarchy. Periodically, the distribution is reviewed based
on the return on investment function. Other metrics can also be used
to adjust the distribution of the risk tokens. An example of such
metric is the utilisation function that measures the fraction of
tokens that have been spent to purchase information accesses. This
function can also serve as a measure on the merits of the information
producers. If the utilisation fraction is near $100\%$, it means the
organisation is almost reaping the full benefit of the information
produced and vice versa.

\subsubsection{Model based on market economic system}
\label{sec:ebsmarketeconomysystem}
The main aspect that differentiates this model from the model based on
command economic system is the collapse of information specific tokens
into two general types. This removes the controls that the producers
have in setting the tolerable risk associated with the
information~(via manipulation of the number of tokens created). The
reason for having more than one type of token is that different types
of information require different protection profiles over time. This
change requires the value of a risk token and the token distribution
mechanism to be redefined.

In the model based on command economic system, accessing to any
information, regardless of its sensitivity level, would cost the same
number of token for all individuals with the same clearance
level. This is because the risk of an information access is only
associated with the probability of causing unauthorised disclosure of
the information. However, the amount of damages caused by unauthorised
disclosure of information with different sensitivity levels are likely
to be different. More sensitive information are likely to cause more
damage. To control the amount of damage, the information producer can
limit the number of tokens created along with an information. With the
change from information-specific tokens to generic tokens, this is no
longer possible.

To overcome this problem, the value of a token in this new model is
changed to be associated with harm~($\text{damage} \times
\text{risk}$) as defined in~\eqref{eq:ebsharm}. To calculate harm, an
additional damage model is required. For risk token creation and
distribution, a new central authority that plays a similar role to the
central bank in the real world is introduced. This central authority
is also responsible for monitoring the health of the tokens by
balancing demand and supply, and controlling the inflation and
deflation rates.

\subsubsection{Review}
\label{sec:ebsreview}
Although the author advocates that the model based on the market economic
system as being better than the model based on the command economic
system, we think that there are interesting features and tradeoffs in
both models. As shown in Table~\ref{tbl:EBSComparison}, the value of a
token is defined in different ways. The model based on the command
economic system has been deliberately simplified to introduce the new
concept and to make way for the model based on the market economic
system. This advocation may also be compounded by an implicit
assumption that the market economy is better than the command economy
in the real world.
\begin{table}
\centering
\begin{tabular}{|p{0.2\textwidth}|p{0.35\textwidth}|p{0.35\textwidth}|}
  \hline
                   & Command economic system   & Market economics system\\
  \hline
  Token value      & pegged with risk          & pegged with harm\\
  \hline
  Token type       & information-specific      & two generic types: short-term and long-term\\
  \hline
  Token creator    & information producer      & central authority~(central bank)\\
  \hline
  Model required   & a risk model only         & a risk model and a damage model\\
  \hline
  Information risk & managed by limiting the number of tokens created with information & managed by maintaining the equilibrium of the information market\\
  \hline
\end{tabular}
\caption{The differences between the model based on command economic system and the model based on market economic system.}
\label{tbl:EBSComparison}
\end{table}

To have a fair comparison, the value of a token in the model based on
the command economic system is associated with the amount of
damage. The only remaining difference now is the controls the
producers have in setting the tolerable damage associated with
information in the model based on the command economic system. The
information producers can be dishonest in their claims of the
sensitivity levels of information by manipulating the number of tokens
created with them. This may result in market dislocation. The model
based on the market economic system is proposed to alleviate this
problem by the introduction of a central bank, thus making the
credibility of the central bank a key factor for this new model to
operate properly. In other words, the author assumes that the risk of
the central bank in being compromised is smaller than the risk of
market dislocation caused by the dishonest behaviours of the
information producers. This assumption may not hold true in certain
operational environments, e.g., MANETs do not have a central trusted
node and all nodes are exposed to security attacks.

Having said that, the three guiding principles in building a
protection system as outlined in Section~\ref{sec:ebsprinciples} are
inspiring. Current protection systems always attempt to minimise the
risk incurred in each access in the hope that the total risk of all
accesses is below the acceptable risk threshold limit. These
principles recognise that risk is inevitably incurred in each access
and thus advocate managing the global risk. The acceptable risk
threshold limit is first determined and information flow is encouraged
all the way up to the acceptable limit to maximise the gain. This
provides greater short-term flexibility in the access
control. Information is made available to any user who is willing to
pay the cost, yet the long-term behaviours of users remain under
control as the token distribution is subject to the return on
investment of each user.

The distribution of risk tokens based on the return on investment also
encourages each user to opt to access information in safer ways so as
to reduce expenses. A stricter enforcement on using safer access
methods can be achieved by reducing the number of tokens given to the
individual. If the tokens are spent in the usage of a
riskier~(expensive) way to access information, the individual may not
have sufficient tokens to accomplish other duties assigned.

There is a natural reluctance for human users to make decisions that
have far reaching consequences, e.g., revoking the clearance of a
user. The risk model helps by redefining the responsibilities of a
human user in terms of security and operational duties. The security
duty encompasses ensuring the integrity of the information entered to
the risk model. This incremental information input to the risk model,
which gradually changes the trust levels of a user, becomes less
daunting in comparison to the immediate revocation of the clearance of
a user. The operational duty is to ensure that the tokens are used or
distributed wisely in the organisation/team, e.g., a manager may make
an economic decision in distributing the tasks to his employees.
However, the use of the risk model leads to an accountability issue:
who is going to be responsible when something goes wrong? The risk
model, the user or the higher level organisation?  There is no obvious
answer. Without accountability, the number of misuses is likely to
increase.

In economics based models, the availability of information access is
tightly linked to the risk tokens. A user who has spent all his budget
is rendered useless until the next token distribution cycle. This can
happen due to the use of an imperfect risk model, an imbalanced
distribution of risk tokens or misbehaviours of users. In the former
two cases, continual refinements have to be employed in a timely
manner to avoid causing market dislocation. If it is due to the
misbehaviours of users, simply denying the user's access request can
be a logical answer but inappropriate in certain scenarios. For
example, denying an information access to a front-line commander in a
battlefield who has no budget left may result in fatal casualty.

Both models also assume that entities are rational and therefore will
make the best decision among given choices. However, psychological and
social research suggests otherwise; the human decision-making process
is often suboptimal and irrational. For example, the~``heuristics and
biases'' programme was started to investigate the idea of whether the
decision-making process under uncertainty often rests on a limited
number of simplified heuristics\footnote{Heuristics are the simple yet
  efficient informal rules that humans use to make decisions.} or a
complicated algorithm~\cite{AT74}. One of the results was the framing
effect, which showed that the way a problem is formulated can have
influence on the decision-making process~\cite{AT81}. A problem can
emphasize on a gain~($30\%$ of the people will pass the examination)
or on loss~($70\%$ of the people will fail the examination). The
former case generally leads to risk aversion behaviour while the
latter case generally leads to risk seeking behaviour. Relationship
among people can also have effects on the decision-making process. For
example, a captain may choose not to report the misuse of authority
among his soldiers to protect his soldiers from punishment or to
preserve the reputation of his team. Other factors such as emotion,
bias, mistake or incapability in judgement~\cite{DK82} can also creep
into the decision-making process and cause chaos in the system.

Whilst the general view of the system architecture and factors to be
considered are outlined in~\cite{JPO04}, it does not present any
example of core components, e.g., the models to calculate risk and
damage. These models are inherently complicated to design and
build. The contributing factors are difficult to measure, quantify,
calculate and aggregate, e.g., how secure is an operating system?
Should an access to a secret document be considered a short-term risk,
a long-term risk or both? If both, what is the proportion of each
risk? Even if building such models is possible, the task of fine
tuning these models in a timely manner can be
challenging. Furthermore, other security prerequisites on the
infrastructures required to implement the system, as discussed
in~\cite{JPO04}, ranging from network protocol to technologies on
tamper proof hardware, are difficult to have. The security of a system
is only as strong as its weakest component; breaching just one
requirement can easily lead to a security breach of the system.

%\subsubsection{Summary}
%\label{JASONEconomybasedModel.Summary}
In summary, the use of economic concepts may provide greater
flexibility to protect information systems. However, there are doubts
arising from its implementation and also with regard to some practical
issues of the system. Indeed, the author also commented that~``(they)
fully expect that much of what~(they) suggest can be proved
unworkable, or no better than some different approach'' and~``(this)
model may seem too extreme''~\cite{JPO04}. Further research is
required to further investigate this idea. Having said that, the $3$M
principles of building an information protection system: measure risk,
mark the acceptable risk and maximise the information distribution to
the acceptable level are inspiring thoughts.

\subsection{Top-down hierarchical models}
\label{TopDownHierarchicalPolicyModel}
The models presented so far have access control policies which are
specified in terms of the low-level corresponding enforcement
mechanisms, e.g., protection bits, capabilities and access control
lists. Each model implements a single specified policy but does not
often capture all the protection requirements of a system.

\subsubsection{The requirements of the policy languages}
In~\cite{TYCW92}, Woo et al.\ proposed a logic based language that
allows access control policies to be specified independently from the
implementation mechanisms and two composition operators that can be
used to combine multiple access control policies. They also outlined a
list of requirements for a language to be suitable for specifying
access control policy. The language should:
\begin{enumerate}
\item be declarative and semantically independent from the
  implementation mechanisms.
\item be efficiently computable, hence allowing efficient
  authorisation evaluation.
\item allow the intended security properties to be easily specified.
\item allow the ways to handle authorisation be easily specified when
  policies are non-monotonic, inconsistent, incomplete~(coverage) or
  combined together.
\end{enumerate}

Although it has been found later in~\cite{SJ01} that the language
proposed does not impose sufficient constraints to ensure that the
specified policy is Turing decidable and therefore may not be
implementable, their work has pioneered the use of high-level
languages to specify abstract policies independently from the
implementation mechanisms. In~\cite{SJ97,SJ97A}, the Authorisation
Specification Language~(ASL), which is based on stratified first order
logic, became the first complete and computable policy specification
language. Other policy specification languages also exist in the
literature, e.g., Security Policy Language~(SPL)~\cite{CNR01} and
XACML~\cite{SD03}. Refer to~\cite{MS02} for detail.

\subsubsection{Policy hierarchy}
In network management research, policies have become increasingly
popular as a means of managing distributed systems. Here the
term~``policies'' carries a much broader meaning; policies are~``rules
governing the choices in behaviour of a system~(in
general)''~\cite{MS94}. Therefore, policies encompass not only
security-related rules, but also management rules. For example,
obligation policies which have the form of event triggered
condition-action rules can be used to define adaptive management
actions, e.g., change in the quality of service provided, resource
allocation and backup policy and software installation. This
difference is not important in the discussion of this thesis.

To cope with the growth in size and complexity of large distributed
systems, there is a trend towards automating many aspects of
management into distributed components. The concepts of viewing policy
as an object and of policy hierarchy are first proposed
in~\cite{JDM91} and refined further in~\cite{JDM93,JDM93A}. The
concept of viewing a policy as an object is about decoupling the
policy from the components that are responsible for enforcing it~(the
implementation mechanisms) and viewing the policy as an independent
reusable component~\cite{JDM91}. This enables the behaviour of the
system to change by simply changing the rules in the policy.

The concept of policy hierarchy recognises that policies exist at
different levels of abstraction. It suggests that high-level policies
can be derived from business goals and form the basis of multiple
low-level policies~\cite{JDM91,JDM93}. The ultimate objective is to
develop a mechanism that allows the specification of a high-level
policy to be analysed and translated automatically to low-level
policies which can then be executed by the system. The number of
policy hierarchy levels may vary among different models, yet the
intuition remains the same. The high-level policies are refined to
form low-level policies.

As an example, the policy model proposed in the International
Technology Alliance~(ITA) project is shown in
Figure~\ref{fig:ITAPolicyModel}~\cite{KS08}. The model consists of
four layers: specification layer, abstract layer, concrete layer and
executable layer. The specification layer consists of authoring and
analysis tools that support the specification of high-level security
policies in constrained natural languages. These policies are then
refined into abstract policies. At the next layer, various formal
methods are used to check the correctness and consistency of these
abstract policies. The concrete layer is then responsible for refining
the analysed policies into concrete policies which are then upheld by
different components to meet the policy goals. The executable layer
transforms these concrete policies into executable policies and
distributes them to the implementation devices that are responsible
for enforcing the policies. This bottom layer is also responsible for
reporting the status and device discovery information back up to the
concrete policy layer.

\begin{figure}[htbp]
 \centering
 \includegraphics[width=\textwidth]{ITAPolicyModel}
 \caption{The ITA policy model~\cite{KS08}.}
 \label{fig:ITAPolicyModel}
\end{figure}
% In the following sections, we will discuss some of the issues in the
% processes in refining high-level policies into lower-level policies
% and analysing policies. 

\subsubsection{Policy refinement and policy conflict analysis}
\label{PolicyRefinementAndPolicyConflictAnalysis}
Policy refinement is the process of transforming high-level security
goals into low-level policies that can be enforced by a
system~\cite{JDM91}.  The refinement process involves the analysis of
policy conflict, policy coverage and the determination of resources
required to implement the policies~\cite{JDM91}.

One widely accepted policy refinement approach is the goal refinement
approach proposed in~\cite{RD97}. The goal refinement approach
consists of the process of identifying, recognising and instantiating
refinement patterns. Once a refinement pattern has been identified and
analysed for completeness and conflict, any policy that matches this
pattern is certain to be complete and correct. Whilst it is desirable
to have a fully automated refinement process, Moffett et al.\ argued
that it is often infeasible to do this in many situations other than
the most trivial scenarios~\cite{JDM93A}.

Policy conflict analysis is the process of verifying whether the
security policy is \emph{consistent} and
\emph{complete}~\cite{MS94}. By consistent we mean that there is no
conflict between the rules in the policies and with the capabilities
of the underlying system. By complete we mean the policy implements
all the high-level goals specified.

There are two categories of conflicts: modality conflicts and semantic
conflicts. Modality conflicts arise when the rules in the security
policies are inconsistent with one another. Modality conflicts can be
divided into the following three categories based on the types of
rules that are in conflict~\cite{EL99}:
\begin{enumerate}
\item Authorisation conflicts --- conflicts that arise because both
  positive and negative authorisation rules exist for the same action,
  subject and object tuple. In other words, a subject is
  authorised~(by the positive authorisation rule) as well as
  forbidden~(by the negative authorisation rule) to perform the same
  action on an object.
\item Obligation conflicts --- conflicts that arise because there is
  an obligation rule and a refrain~(negative obligation) rule defined
  for an action that a subject is obligated to perform as well as
  refrained from performing on an object.
\item Unauthorised obligation conflicts --- conflicts that arise
  when there are an obligation rule and a negative authorisation rule
  defined for an action that a subject is obligated but forbidden to
  perform on an object.
\end{enumerate}
Having a positive authorisation rule and a refrain rule defined for
the same action for a subject and an object is not considered as a
conflict.

Poor policy specification is not the only cause of policy
conflict. Organisation goals may be ambiguous and conflicting in
nature, e.g., maximising resource utilisation vs.\ maximising resource
availability. This will inevitably result in conflicts among policies
that are derived from it.
 
To detect these conflicts, syntactic analysis can be applied to the
policies to determine the overlap of subjects, targets and
actions~\cite{EL99}. However, the existence of overlap only reveals
the \emph{potential} modality conflict because other constraints, such
as time, might limit the applicability of the rules. Moreover,
syntactic analysis is unable to detect application-specific conflicts,
e.g., the separation of duty principle described in
Section~\ref{ClarkWilsonModel}. To detect these conflicts, the
conditions that may cause the conflicts are required to be specified
as additional constraints on the policies. The occurrence of the
conflicts may also depend on the state of the system. Analysing all
these states to check for possible conflicts is often infeasible and
therefore run-time analysis is still necessary.

Once these conflicts are detected, it is necessary to resolve
them. Jajodia et al.\ suggested a few ways to handle the conflicts
in~\cite{SJ97}. The simplest way is to do nothing but flag an error
condition. A better solution is to allow the positive authorisation
policy to override the negative authorisation policy or vice
versa. Often, the priority is given to the negative authorisation
policy based on the assumption that preventing actions would incur
less risk. Obviously this is not always true. For example, a positive
authorisation policy can be an exception to a more general negative
authorisation policy.

To alleviate this issue, priorities can be assigned to different
policies explicitly~\cite{EL99}. When conflicts arise among policies,
the highest priority policy is enforced. However, the task of priority
assignment in itself is difficult. There is also a problem of breaking
a tie if there are two or more policies with the same level of
priority. This problem is exacerbated when there are multiple parties
involved in defining and assigning policies. Inconsistency can easily
arise as each party can have different preferences. An alternative
approach is to define priority based on specificity of the
policy~\cite{AH90}. At the other extreme, meta policies are also being
proposed as a way to define the precedence relationship among
policies~\cite{EL99}. Whilst these resolution mechanisms provide more
flexibility, they also make the task of ensuring policy consistency
more complicated.  There is still no known general mechanism that is
able to detect and resolve conflicts among policies when arbitrary
conditions are allowed.

% As modern systems become more distributed, the distribution of the
% analysis procedures across the system can be problematic. The system
% can be organised in an unstructured order; each subsystem can be owned
% by different domains. This makes the policy refinement process much
% more complicated. In MANETs, subsystems can join, leave and rejoin at
% any time. This dynamic behaviour can easily cause conflicts among the
% policies.

%\subsubsection{Summary}
%\label{TopDownHierarchicalPolicyModel.Summary}
%This section presents a top-down hierarchical policy model in which
%policies are specified using high-level languages and then refined
%into low-level policies. Various issues related to the policy
%refinement process are discussed, including how conflicts among the
%policies can arise, be detected and be resolved.

\section{Summary}
\label{Review}
Recent research~\cite{JPO04} suggests that current static security
policy models are not appropriate for many modern systems, especially
when the operational environment is highly dynamic. Some models that
provide more flexibility have been
proposed~\cite{PCC07,PCC07A,JPO04}. These models are different from
the static ones in two important aspects. Firstly, the risk-benefit
tradeoff assessment on an information access request is no encoded in
the security policy itself. Instead, an explicit risk model is used in
these models to dynamically estimate the risk of an information access
request to make better informed decisions. Secondly, the new model
attempts to manage the total risk of a system as a whole, as opposed
to the risk of each access individually in the traditional
models. Users are allocated with an initial budget of risk tokens,
which they may use on their discretion to access different
information. The budget distribution is reviewed periodically based on
the benefit gained from information access of each user. However, the
models proposed are rather abstract. Many aspects of the models
require further investigation. These include the way to allocate
initial budget, the type of the market, the cost of the access, etc.

In the network management research, the top-down policy refinement
approach has received much attention recently. The idea of this
approach is to refine business goals to high-level security policies,
which in turn are refined into low-level policies
automatically. Whilst this conceptual idea is great, the current
policy conflict resolution mechanisms are still rather
primitive. There is currently no general mechanism that is able to
detect and resolve conflicts among policies when arbitrary conditions
are allowed. As modern systems become more distributed, the
distribution of the analysis procedures across the system can be
problematic. The system can be organised in an unstructured order;
each subsystem can be owned by different domains. This makes the
policy refinement process much more complicated.  In MANETs,
subsystems can join, leave and rejoin at any time. This dynamic
behaviour can easily cause conflicts among the policies.

The way we choose to approach the problem is a radical one. In this
thesis, we investigate how a specific set of decisions may be
generalised into an applicable security policy using EAs. A developed
policy inference system could be doubly useful. The generated policy
rules can be used on it own or used to verify the correctness of
existing policies. In a highly dynamic operational environment like
MANETs, where the risk factors are constantly changing, the inference
techniques must be able to dynamically update the policies inferred to
maintain their optimality. Here we explore the potential of EAs in
dynamically updating security policies with new decision
examples. Additionally, we observe that the risk-budget based policy
models reviewed in Section~\ref{FlexibleAccessControlModels} are
really families of policies. Each instance in a policy family
constrains the system and therefore affects the operational behaviour
and effectiveness of the system in its own way. We introduce the
notion of mission-specific policy and demonstrate how EAs can be used
to search for the~(near) optimal policies that fit a specific set of
missions using simulation runs~(instead of a set of decision
examples).

\section{Conclusions}
\label{SecurityPolicy.Conclusion}
This chapter summarises various influential security policies and
models in the literature. It then introduces the top-down hierarchical
policy model in which allows policies to be specified using high-level
languages and then refined into low-level policies. Various issues
related to the policy refinement and conflict analysis process are
discussed. Lastly, it reviews the current state of the art in security
policy development and reiterates the research objectives of the
thesis.


% ------------------------------------------------------------------------


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../thesis"
%%% End: 
